{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va6WMSN1RhfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f28a16-68c0-4c3f-9de6-a38938a77d4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "vT3h2KD2TZsb",
        "outputId": "b3fa4f4e-50ae-45f5-a1a0-1463db0efa11"
      },
      "source": [
        "pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.7\n",
            "  Downloading numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 73 kB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.1 which is incompatible.\n",
            "tensorflow 2.5.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.1 six-1.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzAOAJcKr8kf"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "### Import libs\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, TimeDistributed, Layer\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLkX_zFbsoU0"
      },
      "source": [
        "#### Config setting\n",
        "class Config:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Tamaños de anchores\n",
        "        self.anchor_box_scales = [32, 64, 128]\n",
        "\n",
        "        # Ratios de anchores\n",
        "        self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "        # Tamaño a redimensionar la dimension más pequeña de la imagen\n",
        "#        self.im_size = 600\n",
        "\n",
        "        # numero de ROIs procesados simultáneamente\n",
        "        self.num_rois = 4\n",
        "\n",
        "        # stride para el modelo RPN (modelo base VGG16)\n",
        "        self.rpn_stride = 16\n",
        "\n",
        "        # scaling the stdev\n",
        "        self.std_scaling = 4.0\n",
        "        self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "        # threshold para el modelo RPN\n",
        "        self.rpn_min_overlap = 0.3\n",
        "        self.rpn_max_overlap = 0.7\n",
        "\n",
        "        # threshold para el clasificador final\n",
        "        self.classifier_min_overlap = 0.1\n",
        "        self.classifier_max_overlap = 0.5\n",
        "\n",
        "        # codificación de las clases\n",
        "        self.class_mapping = None\n",
        "        self.model_path = None\n",
        "\n",
        "# From https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
        "    # initialize the dimensions of the image to be resized and\n",
        "    # grab the image size\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if both the width and height are None, then return the\n",
        "    # original image\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "\n",
        "    # check to see if the width is None\n",
        "    if width is None:\n",
        "        # calculate the ratio of the height and construct the\n",
        "        # dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "\n",
        "    # otherwise, the height is None\n",
        "    else:\n",
        "        # calculate the ratio of the width and construct the\n",
        "        # dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "\n",
        "    # resize the image\n",
        "    resized = cv2.resize(image, dim, interpolation = inter)\n",
        "\n",
        "    # return the resized image\n",
        "    return resized\n",
        "\n",
        "#### Parser los datos del ficheros de anotaciones\n",
        "def get_data(input_path):\n",
        "    all_imgs = {} # informacion de las imagenes extraida del fichero de anotaciones y agrupada por imagen\n",
        "    classes_count = {} # cantidad de objetos de cada clase\n",
        "    class_mapping = {} # codificacion del nombre de cada clase\n",
        "    filename_path = \"/content/drive/MyDrive/TFM/TrainFasterRCNN/\" # Use this as prefix if different from None\n",
        "\n",
        "    i = 1\n",
        "    with open(input_path,'r') as f:\n",
        "        for line in f:\n",
        "            sys.stdout.write('\\r'+'idx=' + str(i))\n",
        "            i += 1\n",
        "\n",
        "            line_split = line.strip().split(',')\n",
        "            # Una misma imagen puede contener varias clases y anotaciones\n",
        "            (filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "            x1 = int(x1)\n",
        "            x2 = int(x2)\n",
        "            y1 = int(y1)\n",
        "            y2 = int(y2)\n",
        "\n",
        "            if class_name not in classes_count:\n",
        "                classes_count[class_name] = 1\n",
        "            else:\n",
        "                classes_count[class_name] += 1\n",
        "\n",
        "            if class_name not in class_mapping: # evitar clase con nombre 'bg'\n",
        "                class_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "            img = None\n",
        "\n",
        "            if filename not in all_imgs:\n",
        "                all_imgs[filename] = {}\n",
        "\n",
        "                img = cv2.imread(filename if filename_path is None else os.path.join(filename_path, filename))\n",
        "                \n",
        "                if img is not None:   \n",
        "                  img_shape = img.shape[:2]\n",
        "\n",
        "                  # Reshape image size if it is larger than 1920x1080\n",
        "                  if img_shape[0] > 1080 or img_shape[1] > 1920:\n",
        "                    reshape_img = image_resize(img, 1920, 1080)\n",
        "\n",
        "                    reshaped_img_shape = reshape_img.shape[:2]\n",
        "\n",
        "                    scale = np.flipud(np.divide(reshaped_img_shape, img_shape))\n",
        "\n",
        "                    x1, y1 = np.multiply((x1, y1), scale)\n",
        "                    x2, y2 = np.multiply((x2, y2), scale)\n",
        "\n",
        "                    x1 = int(x1)\n",
        "                    x2 = int(x2)\n",
        "                    y1 = int(y1)\n",
        "                    y2 = int(y2)\n",
        "\n",
        "                    img = reshape_img\n",
        "\n",
        "                  (rows,cols) = img.shape[:2]\n",
        "                  all_imgs[filename]['filepath'] = filename if filename_path is None else os.path.join(filename_path, filename)\n",
        "                  all_imgs[filename]['width'] = cols\n",
        "                  all_imgs[filename]['height'] = rows\n",
        "                  all_imgs[filename]['bboxes'] = []\n",
        "\n",
        "                  # cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                  # cv2_imshow(img)\n",
        "\n",
        "            if img is not None:\n",
        "              all_imgs[filename]['bboxes'].append({'class': class_name, 'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2})\n",
        "\n",
        "        all_data = []\n",
        "        for key in all_imgs:\n",
        "            all_data.append(all_imgs[key])\n",
        "\n",
        "        return all_data, classes_count, class_mapping\n",
        "\n",
        "#### Definicion ROI Pooling Convolutional Layer\n",
        "class RoiPoolingConv(Layer):\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "        self.dim_ordering = K.image_data_format()\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        assert(len(x) == 2)\n",
        "\n",
        "        # x[0] is image with shape (rows, cols, channels)\n",
        "        img = x[0]\n",
        "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
        "        rois = x[1]\n",
        "\n",
        "        outputs = []\n",
        "        for roi_idx in range(self.num_rois):\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            # Resized roi of the image to pooling size (7x7)\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "\n",
        "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
        "        # Might be (1, 4, 7, 7, 3)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size, 'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "#### Vgg-16 modelo base\n",
        "\n",
        "# dimensiones del feature map\n",
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)\n",
        "\n",
        "# modelo base\n",
        "def nn_base(input_tensor=None):\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=(None, None, 3))\n",
        "    else:\n",
        "        img_input = input_tensor\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "####  modelo RPN\n",
        "def rpn_layer(base_layers, num_anchors):\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]\n",
        "\n",
        "####  modelo clasificador final\n",
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes):\n",
        "    pooling_regions = 7\n",
        "\n",
        "    # TimeDistributed layers se utiliza para procesar ROIs de forma independiente.\n",
        "    # Se indica el número de ROIs de entrada añadiendo una dimensión mas (num_rois)\n",
        "    # out_roi_pool es una lista de 4 RoI (7x7x512)\n",
        "    # out_roi_pool.shape = (1, num_rois, pool_size, pool_size, channels)\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    # Flatten out_roi_pool y conectar a 2 Fully-Connected y 2 dropout layers\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    # out_class: prediccion de la clase del objeto\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # out_regr: prediccion de las coordenadas de los bboxes\n",
        "    out_regr = TimeDistributed(Dense(4*(nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "\n",
        "    return [out_class, out_regr]\n",
        "\n",
        "#### Calculo IoU (Intersection of Union)\n",
        "def union(au, bu, area_intersection):\n",
        "    area_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "    area_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "    area_union = area_a + area_b - area_intersection\n",
        "    return area_union\n",
        "\n",
        "def intersection(ai, bi):\n",
        "    x = max(ai[0], bi[0])\n",
        "    y = max(ai[1], bi[1])\n",
        "    w = min(ai[2], bi[2]) - x\n",
        "    h = min(ai[3], bi[3]) - y\n",
        "    if w < 0 or h < 0:\n",
        "        return 0\n",
        "    return w*h\n",
        "\n",
        "def iou(a, b):\n",
        "    if a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "        return 0.0\n",
        "\n",
        "    area_i = intersection(a, b)\n",
        "    area_u = union(a, b, area_i)\n",
        "    return float(area_i) / float(area_u + 1e-6)\n",
        "\n",
        "#### Calcula propuesta de anchores 'foreground' and 'bg' de la imagen para el entrenamiento del modelo RPN\n",
        "#def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "def calc_rpn(C, img_data, width, height, img_length_calc_function):\n",
        "    # Por cada punto del feature map obtiene los 9 (3 tamaños*3 ratios) anchores correspondientes en la imagen\n",
        "    # Por cada anchor calcula el IoU con cada ground-truth bbox, y guarda el mejor anchor con cada gt bbox\n",
        "    # Del mejor anchor en cada momento con cada gt bbox se almacena:\n",
        "    #     best_x_for_gt_bbox: coordenadas (x1,x2,y1,y2) del anchor\n",
        "    #     best_dx_for_gt_bbbox: deltas (diferencias) entre el anchor y el gt bbox\n",
        "    #     best_iou_for_gt_bbox: IoU del mejor anchor\n",
        "    #     best_anchor_for_gt_bbox: su punto (x,y) correspondiente en el feature map, tamaño y ratio del anchor\n",
        "    # Cada mejor anchor se clasifica como 'pos' (IoU>0.7), 'neutral' o 'neg' (IoU<0.3), y se crean las estructuras:\n",
        "    #     y_rpn_overlap (_x_x9): indica si el anchor se superpone con algún gt bbox de la imagen (si IoU>0.7)\n",
        "    #     y_is_box_valid (_x_x9): indica si el anchor es 'pos' o 'neg' (se considera objeto o 'bg')\n",
        "    #     y_rpn_regr (_x_x36): almacena los deltas (tx,ty,tw,th) de los anchores 'pos'\n",
        "    # Si para un gt bbox no hay 'pos' anchor se selecciona el mejor de los existentes (sea cual sea su IoU)\n",
        "    #\n",
        "    # De las estructuras \"y_is_box_valid\" e \"y_rpn_overlap\" se extraen anchores 'pos' y 'neg'. Se limitan a un máximo\n",
        "    # de 256 entre ambos, de forma balanceada, rechazando algunos si necesario y actualizando \"y_is_box_valid\"\n",
        "    # Finalmente devuelve una propuesta de regiones que incluyen objetos ('pos') y background ('neg'):\n",
        "    #    y_rpn_cls (18x_x_) = [y_is_box_valid (9x_x_) + y_rpn_overlap (9x_x_)]\n",
        "    #    y_rpn_regr (72x_x_) = [(y_rpn_overlap * 4) (36x_x_) + y_rpn_regr (36x_x_)]\n",
        "    #    num_pos, cantidad de anchores positivos\n",
        "    downscale = float(C.rpn_stride)\n",
        "    anchor_sizes = C.anchor_box_scales   # tamaños de los anchores\n",
        "    anchor_ratios = C.anchor_box_ratios  # ratios de los anchores\n",
        "    num_anchors = len(anchor_sizes) * len(anchor_ratios)\n",
        "\n",
        "    # calcula tamaño del feature map para la imagen\n",
        "#    (output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "    (output_width, output_height) = img_length_calc_function(width, height)\n",
        "\n",
        "    n_anchratios = len(anchor_ratios)\n",
        "\n",
        "    # crea e inicializa las estructuras necesarias\n",
        "    y_rpn_overlap = np.zeros((output_height, output_width, num_anchors)) # si anchor se superpone con gt bbox\n",
        "    y_is_box_valid = np.zeros((output_height, output_width, num_anchors)) # si anchor incluye un objecto\n",
        "    y_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "    num_gt_bboxes = len(img_data['bboxes']) # cantidad de gt bboxes en la imagen\n",
        "    num_anchors_for_gt_bbox = np.zeros(num_gt_bboxes).astype(int) # cantidad anchores con IoU>0.7 con cada gt box\n",
        "    best_anchor_for_gt_bbox = -1*np.ones((num_gt_bboxes, 4)).astype(int) # punto (x,y) en el feature map, tamaño y ratio\n",
        "    best_iou_for_gt_bbox = np.zeros(num_gt_bboxes).astype(np.float32) # IoU del mejor anchor\n",
        "    best_x_for_gt_bbox = np.zeros((num_gt_bboxes, 4)).astype(int) # coordenadas (x1,x2,y1,y2) del anchor\n",
        "    best_dx_for_gt_bbox = np.zeros((num_gt_bboxes, 4)).astype(np.float32) # deltas entre el anchor y el gt bbox\n",
        "\n",
        "    # adecuar las coordenadas de los gt bboxes, considerando el redimensionamiento de la imagen\n",
        "    gta = np.zeros((num_gt_bboxes, 4))\n",
        "    for bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "        gta[bbox_num, 0] = bbox['x1'] #* (resized_width / float(width))\n",
        "        gta[bbox_num, 1] = bbox['x2'] #* (resized_width / float(width))\n",
        "        gta[bbox_num, 2] = bbox['y1'] #* (resized_height / float(height))\n",
        "        gta[bbox_num, 3] = bbox['y2'] #* (resized_height / float(height))\n",
        "\n",
        "    # Por cada punto del feature map calcula los 9 anchores correspondientes en la imagen\n",
        "    # Para cada uno de los diferentes tipos de anchor\n",
        "    for anchor_size_idx in range(len(anchor_sizes)):\n",
        "        for anchor_ratio_idx in range(n_anchratios):\n",
        "            anchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "            anchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\n",
        "\n",
        "            # para cada uno de los puntos del feature map\n",
        "            for ix in range(output_width):\n",
        "                # coordenadas x1 y x2 del anchor en la imagen\n",
        "                x1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "                x2_anc = downscale * (ix + 0.5) + anchor_x / 2\n",
        "\n",
        "                # ignora bboxes que salen de la imagen\n",
        "#                if x1_anc < 0 or x2_anc > resized_width:\n",
        "                if x1_anc < 0 or x2_anc > width:\n",
        "                    continue\n",
        "\n",
        "                for jy in range(output_height):\n",
        "                    # coordenadas y1 e y2 del anchor en la imagen\n",
        "                    y1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "                    y2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\n",
        "                    # ignora bboxes que salen de la imagen\n",
        "#                    if y1_anc < 0 or y2_anc > resized_height:\n",
        "                    if y1_anc < 0 or y2_anc > height:\n",
        "                        continue\n",
        "\n",
        "                    # Initializa bbox a 'negativo'\n",
        "                    bbox_type = 'neg'\n",
        "                    # The best IOU for the (x,y) coord and the current anchor\n",
        "                    best_iou_for_loc = 0.0\n",
        "\n",
        "                    # Cada anchor lo comparo con cada gt bbox de la imagen\n",
        "                    for bbox_num in range(num_gt_bboxes):\n",
        "                        # IOU of the current gt box and the current anchor box\n",
        "                        curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\n",
        "                        if curr_iou > best_iou_for_gt_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "                            # calculo los centros de gravedad del anchor y gt bbox\n",
        "                            cx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "                            cy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "                            cxa = (x1_anc + x2_anc)/2.0\n",
        "                            cya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "                            # calculo los deltas, que son codificados según el autor del Faster:\n",
        "                            # tx=(xgt-xan)/width_an, ty=(ygt-yan)/height_an, tw=ln(width_gt/width_an), th=ln(height_gt/height_an)\n",
        "                            tx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "                            ty = (cy - cya) / (y2_anc - y1_anc)\n",
        "                            tw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "                            th = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\n",
        "                        if img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "                            # Cada gt bbox debe ser abarcado por un anchor, buscamos el mejor anchor\n",
        "                            if curr_iou > best_iou_for_gt_bbox[bbox_num]:\n",
        "                                # guardamos datos del anchor: (jy,ix) son coordenadas en el feature map, tamaño y ratio\n",
        "                                best_anchor_for_gt_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "                                best_iou_for_gt_bbox[bbox_num] = curr_iou # IoU entre el anchor y el gt box\n",
        "                                best_x_for_gt_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc] # coordenadas del anchor\n",
        "                                best_dx_for_gt_bbox[bbox_num,:] = [tx, ty, tw, th] # deltas entre anchor y gt box\n",
        "\n",
        "                            # si IOU >threshold el anchor incluye un objeto\n",
        "                            # (no importa si hay otro bbox mejor, solo refleja superposicion)\n",
        "                            if curr_iou > C.rpn_max_overlap:\n",
        "                                bbox_type = 'pos'\n",
        "                                num_anchors_for_gt_bbox[bbox_num] += 1\n",
        "                                # actualizamos los deltas si el IoU es el mejor hasta ahora\n",
        "                                if curr_iou > best_iou_for_loc:\n",
        "                                    best_iou_for_loc = curr_iou\n",
        "                                    best_regr = (tx, ty, tw, th)\n",
        "\n",
        "                            # es ambiguo, no se sabe si incluye o no un objeto\n",
        "                            if C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "                                if bbox_type != 'pos':\n",
        "                                    bbox_type = 'neutral'\n",
        "\n",
        "                        # actualiza las estructuras en funcion del tipo de anchor\n",
        "                        if bbox_type == 'neg':\n",
        "                            y_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "                            y_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "                        elif bbox_type == 'neutral':\n",
        "                            y_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "                            y_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "                        elif bbox_type == 'pos':\n",
        "                            y_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "                            y_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "                            start = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "                            y_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "    # aseguramos que cada gt bbox tiene al menos un anchor que la solapa\n",
        "    for idx in range(num_anchors_for_gt_bbox.shape[0]):\n",
        "        if num_anchors_for_gt_bbox[idx] == 0:  # cantidad de anchors que tienen IoU>0.7 con cada gt box\n",
        "            # si no hay anchor con IoU>0.7, selecciono el mejor de los existentes en best_anchor_for_gt_bbox\n",
        "            if best_anchor_for_gt_bbox[idx, 0] == -1: # no hay bbox con IoU>0\n",
        "                continue\n",
        "            y_is_box_valid[best_anchor_for_gt_bbox[idx,0], best_anchor_for_gt_bbox[idx,1],\n",
        "                           best_anchor_for_gt_bbox[idx,2] + n_anchratios * best_anchor_for_gt_bbox[idx,3]] = 1\n",
        "            y_rpn_overlap[best_anchor_for_gt_bbox[idx,0], best_anchor_for_gt_bbox[idx,1],\n",
        "                          best_anchor_for_gt_bbox[idx,2] + n_anchratios * best_anchor_for_gt_bbox[idx,3]] = 1\n",
        "            start = 4 * (best_anchor_for_gt_bbox[idx,2] + n_anchratios * best_anchor_for_gt_bbox[idx,3])\n",
        "            y_rpn_regr[best_anchor_for_gt_bbox[idx,0], best_anchor_for_gt_bbox[idx,1], start:start+4] = best_dx_for_gt_bbox[idx, :]\n",
        "\n",
        "    y_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "    y_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "    y_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "    y_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "    y_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "    y_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "    # pos_locs almacena las coordenadas de los anchors que contienen objeto y overlap con gt bbox\n",
        "    pos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "    neg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "    num_pos = len(pos_locs[0])\n",
        "    num_neg = len(neg_locs[0])\n",
        "\n",
        "    # la propuesta de regiones debe ser balanceada y limitada a 256 regiones\n",
        "    num_regions = 256\n",
        "\n",
        "    # hay mas regiones positivas que negativas\n",
        "    if len(pos_locs[0]) > num_regions/2:\n",
        "        # selecciona aleatoriamente tantos anchores positivos como los que exceden de num_regions/2\n",
        "        val_locs = random.sample(range(num_pos), num_pos - num_regions/2)\n",
        "        # los anchores seleccionados se marcan como neutrales (antes eran positivos)\n",
        "        y_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "        num_pos = num_regions/2\n",
        "    # hay mas regiones negativas que positivas\n",
        "    if num_neg + num_pos > num_regions:\n",
        "        # selecciona aleatoriamente tantos anchores negativos como los que exceden de num_pos\n",
        "        val_locs = random.sample(range(num_neg), num_neg - num_pos)\n",
        "        # los anchores seleccionados se marcan como neutrales (antes eran negativos)\n",
        "        y_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "    y_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "    y_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "    return np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos\n",
        "\n",
        "#### Calcula el nuevo tamaño de la imagen redimensionada\n",
        "#def get_new_img_size(width, height, img_min_side=300):\n",
        "#    if width <= height:\n",
        "#        f = float(img_min_side) / width\n",
        "#        resized_height = int(f * height)\n",
        "#        resized_width = img_min_side\n",
        "#    else:\n",
        "#        f = float(img_min_side) / height\n",
        "#        resized_width = int(f * width)\n",
        "#        resized_height = img_min_side\n",
        "#\n",
        "#    return resized_width, resized_height\n",
        "\n",
        "#### Funcion GENERADORA que devuelve los ground_truth anchors\n",
        "def get_anchor_gt(all_img_data, C, img_length_calc_function):\n",
        "    while True:\n",
        "\n",
        "        for img_data in all_img_data:\n",
        "            try:\n",
        "                # lee imagen\n",
        "                x_img = cv2.imread(img_data['filepath'])\n",
        "                (width, height) = (img_data['width'], img_data['height'])\n",
        "                (rows, cols, _) = x_img.shape\n",
        "                assert cols == width\n",
        "                assert rows == height\n",
        "\n",
        "                # calcula tamaño de la imagen redimensionada\n",
        "#                (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "                # redimensiona la imagen\n",
        "#                x_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "                try:\n",
        "#                    y_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "                    y_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data, width, height, img_length_calc_function)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                # Preprocesa imagen\n",
        "                x_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
        "                # adecua la imagen para la entrada en la funcion train del modelo RPN\n",
        "                x_img = np.expand_dims(x_img, axis=0)\n",
        "                # codifica los deltas con la varianza para normalizar los valores\n",
        "                y_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "                y_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "                y_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "                yield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data, num_pos\n",
        "\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                continue\n",
        "\n",
        "#### Define las funciones de pérdida (loss functions) para cada salida de los modelos\n",
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4\n",
        "\n",
        "def rpn_loss_regr(num_anchors):\n",
        "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "        # x is the difference between true value and predicted vaue\n",
        "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "        x_abs = K.abs(x) # absolute value of x\n",
        "        # If x_abs <= 1.0, x_bool = 1\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "        return lambda_rpn_regr * K.sum(\n",
        "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "    return rpn_loss_regr_fixed_num\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\n",
        "        return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\n",
        "    return rpn_loss_cls_fixed_num\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "    def class_loss_regr_fixed_num(y_true, y_pred):\n",
        "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "    return class_loss_regr_fixed_num\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))\n",
        "\n",
        "# Algoritmo NMS para evitar duplicidades en los bboxes delimitando un mismo objeto\n",
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "    # codigo extraido de: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "    # Explicacion del proceso:\n",
        "    #   Paso 1: Ordenar la lista de probabilidades\n",
        "    #   Paso 2: Seleccionar la probabilidad más alta y copiarla en una lista aparte\n",
        "    #   Paso 3: Calcular el IoU entre el bbox de la probabilidad seleccionada con el resto de bboxes en la lista\n",
        "    #           Si (IoU > overlap_threshold) eliminar el bbox y probabilidad de su lista correspondiente\n",
        "    #   Paso 4: Repetir los pasos 2 y 3 hasta vaciar la lista de probabilidades\n",
        "\n",
        "    # si no hay bboxes devuelve una lista vacia\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # captura las coordenadas de todos los bboxes\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    np.testing.assert_array_less(x1, x2)\n",
        "    np.testing.assert_array_less(y1, y2)\n",
        "\n",
        "    # las coordenadas de los bboxes son convertidas a floats para las divisiones\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # lista de indices seleccionados\n",
        "    pick = []\n",
        "\n",
        "    # calculo de las areas de todos los bboxes\n",
        "    area = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "    # ordena las probabilidades (scores) de los bboxes en orden ascendente\n",
        "    # el score más alto está el último\n",
        "    idxs = np.argsort(probs)\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        # añade el último index (el de mayor score) de la lista \"idx\" a la lista \"pick\"\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # busca las coordenadas más grandes (xmin,ymin) del top-left de cada bbox y\n",
        "        # las más grandes (xmax,ymax) del bottom-right de cada bbox\n",
        "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "        # calcular el ancho y alto de cada bbox\n",
        "        ww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "        hh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "        # calcula la interseccion y la union\n",
        "        area_int = ww_int * hh_int\n",
        "        area_union = area[i] + area[idxs[:last]] - area_int\n",
        "        # calcula el IoU\n",
        "        overlap = area_int/(area_union + 1e-6)\n",
        "\n",
        "        # elimina los indices de la lista \"idx\" con IoU > overlap_thresh, y el último index tambien\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "        if len(pick) >= max_boxes:\n",
        "            break\n",
        "\n",
        "    # devuelve aquellos bboxes seleccionados, cuyos index están almacenados en la lista \"pick\"\n",
        "    boxes = boxes[pick].astype(\"int\")\n",
        "    probs = probs[pick]\n",
        "    return boxes, probs\n",
        "\n",
        "# aplica la correccion de los deltas predichos por el modelo RPN\n",
        "def apply_regr_rpn(X, T):\n",
        "    # corrige las coordenadas (x,y,w,h) del anchor según los deltas (tx,ty,tw,th)\n",
        "    # Segun se indica en el paper original:\n",
        "    # tx=(cx_gt-cx_anchor)/w_anchor, ty=(cy_gt-cy_anchor)/h_anchor, tw=log(w_gt/w_anchor), tw=log(h_gt/h_anchor)\n",
        "    # Nota: np.exp() permite trabajar con arrays, mientras que math.exp() sólo con escalares\n",
        "    try:\n",
        "        x = X[0, :, :]\n",
        "        y = X[1, :, :]\n",
        "        w = X[2, :, :]\n",
        "        h = X[3, :, :]\n",
        "\n",
        "        tx = T[0, :, :]\n",
        "        ty = T[1, :, :]\n",
        "        tw = T[2, :, :]\n",
        "        th = T[3, :, :]\n",
        "\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "\n",
        "        w1 = np.exp(tw.astype(np.float64)) * w\n",
        "        h1 = np.exp(th.astype(np.float64)) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "\n",
        "        x1 = np.round(x1)\n",
        "        y1 = np.round(y1)\n",
        "        w1 = np.round(w1)\n",
        "        h1 = np.round(h1)\n",
        "        return np.stack([x1, y1, w1, h1])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return X\n",
        "\n",
        "# Selecciona las predicciones del modelo RPN para entrenar el modelo clasificador final\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "    # adecua las coordenadas de los gt bboxes, considerando el redimensionamiento de la imagen\n",
        "    bboxes = img_data['bboxes']\n",
        "#    (width, height) = (img_data['width'], img_data['height'])\n",
        "    # tamaño de la imagen redimensionada\n",
        "#    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "    gta = np.zeros((len(bboxes), 4))\n",
        "    for bbox_num, bbox in enumerate(bboxes):\n",
        "#        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "#        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "#        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "#        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "        gta[bbox_num, 0] = int(round(bbox['x1'] / C.rpn_stride))\n",
        "        gta[bbox_num, 1] = int(round(bbox['x2'] / C.rpn_stride))\n",
        "        gta[bbox_num, 2] = int(round(bbox['y1'] / C.rpn_stride))\n",
        "        gta[bbox_num, 3] = int(round(bbox['y2'] / C.rpn_stride))\n",
        "\n",
        "    x_roi = [] # almacena coordenadas bbox seleccionadas\n",
        "    y_class_num = [] # codificación de la clase ([1 0]='dorsal', [0 1]='bg')\n",
        "    y_class_regr_coords = [] # almacena deltas del bbox seleccionado, sólo si clase es 'dorsal'\n",
        "    y_class_regr_label = [] # almacena clase del bbox seleccionado\n",
        "\n",
        "    # Para cada prediccion calcula el IoU con los gt bboxes de la imagen\n",
        "    for ix in range(R.shape[0]): # R.shape[0]: cantidad de predicciones del modelo RPN (=300 si NMS)\n",
        "        (x1, y1, x2, y2) = R[ix, :]\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        x2 = int(round(x2))\n",
        "        y2 = int(round(y2))\n",
        "\n",
        "        best_iou = 0.0\n",
        "        best_bbox = -1\n",
        "        # Itera sobre los gt bboxes, calculando el IoU y buscando el gt bbox con mayor iou\n",
        "        for bbox_num in range(len(bboxes)):\n",
        "            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\n",
        "            if curr_iou > best_iou:\n",
        "                best_iou = curr_iou\n",
        "                best_bbox = bbox_num\n",
        "\n",
        "        if best_iou < C.classifier_min_overlap:\n",
        "            continue\n",
        "        else:\n",
        "            # si el IoU es mayor que el threshold selecciono la prediccion para entrenar el clasificador final\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_roi.append([x1, y1, w, h])\n",
        "\n",
        "            # preparo clase y bbox de la prediccion seleccionada para entrenar el clasificador final\n",
        "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "                # clase='bg', no hace falta bbox\n",
        "                cls_name = 'bg'\n",
        "            elif C.classifier_max_overlap <= best_iou:\n",
        "                # clase = la del gt bbox\n",
        "                cls_name = bboxes[best_bbox]['class']\n",
        "                # calcula deltas como diferencias entre gt bbox (el de mayor IoU) y la prediccion\n",
        "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "                cx = x1 + w / 2.0\n",
        "                cy = y1 + h / 2.0\n",
        "\n",
        "                tx = (cxg - cx) / float(w)\n",
        "                ty = (cyg - cy) / float(h)\n",
        "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "            else:\n",
        "                print('roi = {}'.format(best_iou))\n",
        "                raise RuntimeError\n",
        "\n",
        "        # codificación de la clase ([1 0]='dorsal', [0 1]='bg')\n",
        "        class_num = class_mapping[cls_name]\n",
        "        class_label = len(class_mapping) * [0]\n",
        "        class_label[class_num] = 1\n",
        "        y_class_num.append(copy.deepcopy(class_label))\n",
        "\n",
        "        # crea listas de 4 huecos para almacenar las coordenadas y la clase\n",
        "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
        "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
        "        if cls_name != 'bg':\n",
        "            label_pos = 4 * class_num\n",
        "            # normalizo deltas\n",
        "            sx, sy, sw, sh = C.classifier_regr_std\n",
        "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "            # codifico la clase\n",
        "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "            # almacena clase y deltas del bbox seleccionado\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "        else:\n",
        "            # los deltas son irrelevantes si la clase es 'bg', se ponen a nulo\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "    if len(x_roi) == 0:\n",
        "        return None, None, None\n",
        "\n",
        "    # predicciones del modelo RPN con IoU > threshold\n",
        "    X = np.array(x_roi)\n",
        "    # codificacion de la clase para las predicciones seleccionadas 'x_roi'\n",
        "    Y1 = np.array(y_class_num)\n",
        "    # clase y deltas de las predicciones seleccionadas 'x_roi'\n",
        "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)], axis=1)\n",
        "\n",
        "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0)\n",
        "\n",
        "# define los ROIs a partir de las predicciones de scores y deltas de cada anchor por el modelo RPN\n",
        "def rpn_to_roi(out_rpn_cls, out_rpn_regr, C, max_boxes=300, overlap_thresh=0.9):\n",
        "    # Pasos:\n",
        "    #   1. Calcula los bboxes de los ROIs: obtiene coordenadas de los anchores de cada punto del feature map\n",
        "    #   2. Cada anchor es corregido por los deltas predichos por el modelo RPN\n",
        "    #   3. Recorta aquellos bboxes que sobresalgan de la imagen\n",
        "    #   4. Aplica NMS sobre los bboxes\n",
        "    # Devuelve las coordenadas de los bboxes seleccionados (no los scores)\n",
        "\n",
        "    # Decodificación deltas (deltas = deltas*0.25) - p.e. x=(x_gt-x_anc)/(w_anc*var) y w=ln(w_gt/w_anc)/var\n",
        "    out_rpn_regr = out_rpn_regr / C.std_scaling\n",
        "\n",
        "    anchor_sizes = C.anchor_box_scales   # (son 3)\n",
        "    anchor_ratios = C.anchor_box_ratios  # (son 3)\n",
        "\n",
        "    assert out_rpn_cls.shape[0] == 1\n",
        "    (rows, cols) = out_rpn_cls.shape[1:3]\n",
        "\n",
        "    # A.shape = (4, feature_map.height, feature_map.width, num_anchors) = (4,18,25,9) si la imagen es 400x300\n",
        "    # A almacena las coordenadas de los 9 anchores por cada punto del feature map => 18x25x9=4050 anchores\n",
        "    A = np.zeros((4, out_rpn_cls.shape[1], out_rpn_cls.shape[2], out_rpn_cls.shape[3]))\n",
        "\n",
        "    curr_anchor = 0 # indica un anchor en el rango 0~8 (9 anchores)\n",
        "    for anchor_size in anchor_sizes:\n",
        "        for anchor_ratio in anchor_ratios:\n",
        "            # ancho y alto del anchor en el feature map = (ancho * escala) / 16\n",
        "            anchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "            anchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\n",
        "            # regr almacena los deltas del current_anchor en todas las posiciones del feature map\n",
        "            regr = out_rpn_regr[0, :, :, 4 * curr_anchor:4 * curr_anchor + 4] # shape => (18, 25, 4)\n",
        "            regr = np.transpose(regr, (2, 0, 1)) # shape => (4, 18, 25)\n",
        "\n",
        "            # Grid del mismo tamaño que el feature map\n",
        "            X, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\n",
        "            # Calcula coordenadas (x,y,w,h) del current_anchor en todas las posiciones del feature map\n",
        "            A[0, :, :, curr_anchor] = X - anchor_x/2\n",
        "            A[1, :, :, curr_anchor] = Y - anchor_y/2\n",
        "            A[2, :, :, curr_anchor] = anchor_x\n",
        "            A[3, :, :, curr_anchor] = anchor_y\n",
        "\n",
        "            # corrige coordenadas (x,y,w,h) del anchor con deltas (tx,ty,tw,th) predecidos por el modelo RPN\n",
        "            A[:, :, :, curr_anchor] = apply_regr_rpn(A[:, :, :, curr_anchor], regr)\n",
        "\n",
        "            # Evita bboxes con altura o anchura menor que 1 (redondea a 1)\n",
        "            A[2, :, :, curr_anchor] = np.maximum(1, A[2, :, :, curr_anchor])\n",
        "            A[3, :, :, curr_anchor] = np.maximum(1, A[3, :, :, curr_anchor])\n",
        "\n",
        "            # Convierte (x, y , w, h) => (x1, y1, x2, y2)\n",
        "            A[2, :, :, curr_anchor] += A[0, :, :, curr_anchor]\n",
        "            A[3, :, :, curr_anchor] += A[1, :, :, curr_anchor]\n",
        "\n",
        "            # Recorta aquellos bboxes que sobresalgan de la imagen (o del feature map)\n",
        "            A[0, :, :, curr_anchor] = np.maximum(0, A[0, :, :, curr_anchor])\n",
        "            A[1, :, :, curr_anchor] = np.maximum(0, A[1, :, :, curr_anchor])\n",
        "            A[2, :, :, curr_anchor] = np.minimum(cols-1, A[2, :, :, curr_anchor])\n",
        "            A[3, :, :, curr_anchor] = np.minimum(rows-1, A[3, :, :, curr_anchor])\n",
        "\n",
        "            curr_anchor += 1\n",
        "\n",
        "    # almacena la informacion en forma de listas\n",
        "    all_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  # shape => (4050, 4)\n",
        "    all_probs = out_rpn_cls.transpose((0, 3, 1, 2)).reshape((-1))                 # shape => (4050,)\n",
        "\n",
        "    x1 = all_boxes[:, 0]\n",
        "    y1 = all_boxes[:, 1]\n",
        "    x2 = all_boxes[:, 2]\n",
        "    y2 = all_boxes[:, 3]\n",
        "\n",
        "    # Elimina bboxes con coordenadas erróneas\n",
        "    idxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "    all_boxes = np.delete(all_boxes, idxs, 0)\n",
        "    all_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "    # Non_max_suppression. Solo capturamos los bboxes, no necesitamos los scores\n",
        "    result = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "    return result"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiOBEs-Yw-OR"
      },
      "source": [
        "##########\n",
        "# TRAINING\n",
        "##########\n",
        "\n",
        "%cd /content/drive/MyDrive/TFM/TrainFasterRCNN/\n",
        "\n",
        "base_path = './'\n",
        "train_path = 'annotateTest.csv' # Training data (annotation file)\n",
        "output_weight_path = os.path.join(base_path, 'model/model_frcnn_vgg.hdf5')\n",
        "record_path = os.path.join(base_path, 'model/record.csv') # Record data (almacena diversos parametros tras cada epoch)\n",
        "base_weight_path = os.path.join(base_path, '../VGG16_Weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "config_output_filename = os.path.join(base_path, 'model/model_vgg_config.pickle')\n",
        "\n",
        "num_rois = 4 # Numero de RoIs a procesar a la vez\n",
        "\n",
        "# Crea objeto config\n",
        "C = Config()\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "C.base_net_weights = base_weight_path\n",
        "\n",
        "print('\\nCargando datos de anotaciones... ')\n",
        "train_imgs, classes_count, class_mapping = get_data(train_path)\n",
        "\n",
        "# incorpora codificación para la clase 'bg'\n",
        "if 'bg' not in classes_count:\n",
        "    classes_count['bg'] = 0\n",
        "    class_mapping['bg'] = len(class_mapping)\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "print('\\nDistribuion de las imagenes de entrenamiento por clase:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num clases (incluyendo bg) = {}'.format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "# Almacena archivo de configuracion\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "    pickle.dump(C,config_f)\n",
        "    print('Config ha sido almacenado en {}, y debe ser cargado para obtener resultados correctos de test'.format(config_output_filename))\n",
        "\n",
        "# Aleatoriza las imagenes de train\n",
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "print('Num. imagenes de entrenamiento: {}'.format(len(train_imgs)))\n",
        "\n",
        "# LA FUNCION GENERADORA ES EJECUTADA LLAMANDO AL METODO NEXT() DEL GENERADOR\n",
        "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrGaxX9Lypxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6f996c-8b53-461e-ccc8-ae7cf7fac69c"
      },
      "source": [
        "#### Build the model\n",
        "\n",
        "# capa Input del modelo VGG (Imagenes RGB)\n",
        "img_input = Input(shape=(None, None, 3))\n",
        "# capa Input del modelo RoI Pooling\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "# define la red base (VGG16)\n",
        "shared_layers = nn_base(img_input)\n",
        "\n",
        "# define el modelo RPN\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "# define el modelo clasificador final\n",
        "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n",
        "\n",
        "# Creamos los modelos\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "# modelo completo englobando RPN y clasificador final, con la finalidad de almacenar un solo archivo de pesos\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "# we need to save the model and load the model to continue training\n",
        "if not os.path.isfile(C.model_path):\n",
        "    # Si comienza el entrenmamiento, carga los pesos del modelo preentrenado VGG16\n",
        "    try:\n",
        "        print('This is the first time of your training')\n",
        "        print('loading weights from {}'.format(C.base_net_weights))\n",
        "        model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
        "        model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
        "    except:\n",
        "        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
        "            https://github.com/fchollet/keras/tree/master/keras/applications')\n",
        "\n",
        "    # Crea dataframe para almacenar losses, accuracy, etc\n",
        "    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss'])\n",
        "else:\n",
        "    # Si continua un entrenmamiento previo, carga los pesos guardados del modelo Faster entrenado hasta entonces\n",
        "    print('Continue training based on previous trained model')\n",
        "    print('Loading weights from {}'.format(C.model_path))\n",
        "    model_rpn.load_weights(C.model_path, by_name=True)\n",
        "    model_classifier.load_weights(C.model_path, by_name=True)\n",
        "\n",
        "    # Carga los valores registrados de losses, accuracy, etc almacenados en el archivo\n",
        "    record_df = pd.read_csv(record_path)\n",
        "\n",
        "    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "    r_class_acc = record_df['class_acc']\n",
        "    r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "    r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "    r_loss_class_cls = record_df['loss_class_cls']\n",
        "    r_loss_class_regr = record_df['loss_class_regr']\n",
        "    r_curr_loss = record_df['curr_loss']\n",
        "\n",
        "optimizer = Adam(lr=1e-5)\n",
        "optimizer_classifier = Adam(lr=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')\n",
        "\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method RoiPoolingConv.call of <__main__.RoiPoolingConv object at 0x7fc3d2101710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method RoiPoolingConv.call of <__main__.RoiPoolingConv object at 0x7fc3d2101710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "Continue training based on previous trained model\n",
            "Loading weights from ./model/model_frcnn_vgg.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH3090RZzhlB"
      },
      "source": [
        "epoch_length = 1489 # cantidad de imagenes de training en cada epoch\n",
        "num_epochs = 5 # cantidad de epochs\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = [] # predicciones del RPN con IoU>threshold con objetos\n",
        "rpn_accuracy_for_epoch = []\n",
        "\n",
        "# fija el valor más pequeño de las perdidas totales, para saber cuando almacenar los pesos del modelo en disco\n",
        "if len(record_df)==0:\n",
        "    best_loss = np.Inf\n",
        "else:\n",
        "    best_loss = np.min(r_curr_loss)\n",
        "\n",
        "print(\"Cantidad de registros en el dataframe (Epochs previos): {}\".format(len(record_df)))\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "    progbar = Progbar(epoch_length)\n",
        "    r_epochs += 1\n",
        "    print('Epoch {}/{}'.format(r_epochs, total_epochs))\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "\n",
        "            # X es la imagen resized\n",
        "            # Y incluye estructuras que indican los anchores seleccionados como 'pos' y 'neg' (max 256)\n",
        "            #    y_rpn_cls (18x_x_) = [y_is_box_valid (9x_x_) + y_rpn_overlap (9x_x_)]\n",
        "            #    y_rpn_regr (72x_x_) = [(y_rpn_overlap * 4) (36x_x_) + y_rpn_regr (36x_x_)]\n",
        "            # debug_num_pos indica la cantidad de anchores positivos\n",
        "            X, Y, img_data, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Entrena modelo rpn y obtiene valores de perdida global y de cada salida [loss, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Prediccion del modelo RPN P_rpn = [rpn_cls, rpn_regr] = [scores (_x_x9), deltas (_x_x36)]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # Corrige los anchores con las predicciones delta del modelo RPN y selecciona bboxes mediante NMS\n",
        "            # R.shape = (300, 4)\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, overlap_thresh=0.7, max_boxes=300)\n",
        "\n",
        "            # Selecciona las predicciones del modelo RPN para entrenar el modelo clasificador final\n",
        "            # X2: predicciones del modelo RPN con IoU > threshold con los gt bboxes\n",
        "            # Y1: codificacion de la clase para las predicciones seleccionadas en X2 ([1 0]='dorsal', [0 1]='bg')\n",
        "            # Y2: clase y deltas de las predicciones seleccionadas en X2\n",
        "            X2, Y1, Y2 = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # si X2 esta vacio saltamos a la siguiente iteracion\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "\n",
        "            # Busca predicciones positivas ('dorsal') y negativas ('bg')\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            # pasa la estructura neg_samples y pos_samples de tupla a array\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            # acumula las predicciones del RPN con IoU>threshold con objetos\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # Si numero de predicciones positivas es mayor que 4//2 = 2, seleccionamos 2 aleatoriamente\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "\n",
        "                # Seleccionamos aleatoriamente (num_rois - num_pos) predicciones negativas (`bg`)\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    if len(neg_samples)==0:\n",
        "                      continue\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "\n",
        "                # Almacenar las predicciones positivas y negativas\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # En el caso que num_rois = 1, seleccionamos una prediccion pos o neg aleatoriamente\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            #  X                     => img_data imagen redimensionada\n",
        "            #  X2[:, sel_samples, :] => num_rois (4) bboxes que contienen pos y neg seleccionados\n",
        "            #  Y1[:, sel_samples, :] => codificacion para num_rois bboxes seleccionados en X2\n",
        "            #  Y2[:, sel_samples, :] => clase y deltas para num_rois bboxes seleccionados en X2\n",
        "            # Entrena clasificador final y devuelve valor de perdida global e individual [loss, loss_cls, loss_regr, accuracy_cls]\n",
        "            print(X.shape)\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            # almacena las perdidas obtenidas (modelo rpn y clasificador final)\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                        ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                if curr_loss < best_loss:\n",
        "                    print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3),\n",
        "                            'class_acc':round(class_acc, 3),\n",
        "                            'loss_rpn_cls':round(loss_rpn_cls, 3),\n",
        "                            'loss_rpn_regr':round(loss_rpn_regr, 3),\n",
        "                            'loss_class_cls':round(loss_class_cls, 3),\n",
        "                            'loss_class_regr':round(loss_class_regr, 3),\n",
        "                            'curr_loss':round(curr_loss, 3)}\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "                break # salir del while true y empezar otro epoch\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqRXKKLdz86n"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
        "plt.title('mean_overlapping_bboxes')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
        "plt.title('class_acc')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
        "plt.title('loss_rpn_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
        "plt.title('loss_rpn_regr')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "plt.title('loss_class_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
        "plt.title('loss_class_regr')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "plt.title('total_loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}