{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UseDeeplabCustomModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH7MFGWIvy4R"
      },
      "source": [
        "# Usage of Deeplab + LIP model and extracion of ROI "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEsjy-ccwIa_"
      },
      "source": [
        "In this notebook, the segmentation of the desired images are done, followed by a contour processing to reduce the impact of noise and segmentation errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNMXjXG_whRI"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5QaI5ft_dv0"
      },
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPef1973wtpK"
      },
      "source": [
        "## Mount Google Drive storage\n",
        "In case you need it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5viQ7RWRBycX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9kg4Xko188W"
      },
      "source": [
        "## Path definitions - change to your own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7MjpjS11-op"
      },
      "source": [
        "MODEL_INFER_GRAPH = \"/content/drive/MyDrive/TFM/exported_model_8k/frozen_inference_graph.pb\"\n",
        "VIS_IMAGES = \"/content/drive/MyDrive/TFM/BibNumberTestPeopleImg\"\n",
        "EXPORT_CROP = \"/content/drive/MyDrive/TFM/BibNumberTestSegResultsBase2\"\n",
        "\n",
        "USING_ANNOTATIONS = True\n",
        "VIS_IMAGES_ANNOTATIONS = \"/content/drive/MyDrive/TFM/BibNumberTestPeopleImg/annotateTest.csv\" \n",
        "ANNOTATION_COLUMNS = [\"filename\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class\"]\n",
        "NEW_ANNOTATIONS = pd.DataFrame(columns=ANNOTATION_COLUMNS) if not os.path.exists(os.path.join(EXPORT_CROP, 'annotateTest.csv')) else pd.read_csv(os.path.join(EXPORT_CROP, 'annotateTest.csv'), header=None, names=ANNOTATION_COLUMNS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N_VkOsaidgq"
      },
      "source": [
        "NEW_ANNOTATIONS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uioTYmbgxETk"
      },
      "source": [
        "## Deeplab model class to perform the segmentation and visualize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTELfw8_hno"
      },
      "source": [
        "class DeepLabModel(object):\n",
        "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "  def __init__(self, frozen_graph):\n",
        "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "    self.graph = tf.Graph()\n",
        "\n",
        "    f = open(frozen_graph, \"rb\")\n",
        "    graph_df = tf.GraphDef.FromString(f.read())\n",
        "\n",
        "    if not os.path.isfile(frozen_graph) or graph_df is None:\n",
        "      raise RuntimeError('Cannot find inference graph.')\n",
        "\n",
        "    with self.graph.as_default():\n",
        "      tf.import_graph_def(graph_df, name='')\n",
        "\n",
        "    self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "  def run(self, image):\n",
        "    \"\"\"Runs inference on a single image.\n",
        "\n",
        "    Args:\n",
        "      image: A PIL.Image object, raw input image.\n",
        "\n",
        "    Returns:\n",
        "      resized_image: RGB image resized from original input image.\n",
        "      seg_map: Segmentation map of `resized_image`.\n",
        "    \"\"\"\n",
        "    batch_seg_map = self.sess.run(\n",
        "        self.OUTPUT_TENSOR_NAME,\n",
        "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(image)]}\n",
        "    )\n",
        "    \n",
        "    seg_map = unify_labels(batch_seg_map[0])\n",
        "    \n",
        "\n",
        "    return image, seg_map\n",
        "\n",
        "\n",
        "def unify_labels(seg_map):\n",
        "  \"\"\"Unifies certains labels from LIP in the segmentation map.\n",
        "\n",
        "    Args:\n",
        "      seg_map: Segmentation map from DeeplabModel run(sel, image) method\n",
        "\n",
        "    Returns:\n",
        "      seg_map: Segmentation map with unified labels.\n",
        "    \"\"\"\n",
        "\n",
        "  # Dress and Coat will be appear as UpperClothes\n",
        "  seg_map = np.where(seg_map==6, 5, seg_map) # UpperClothes == Dress\n",
        "  seg_map = np.where(seg_map==7, 5, seg_map) # UpperClothes == Coat\n",
        "  \n",
        "  # Fuse left and right arm in a single instance\n",
        "  seg_map = np.where(seg_map==14, 15, seg_map) \n",
        "\n",
        "  # Fuse left and right leg in a single instance\n",
        "  seg_map = np.where(seg_map==16, 17, seg_map)\n",
        "\n",
        "  # Fuse left and right shoe in a single instance\n",
        "  seg_map = np.where(seg_map==18, 19, seg_map) \n",
        "\n",
        "  return seg_map\n",
        "\n",
        "def create_pascal_label_colormap():\n",
        "  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n",
        "\n",
        "  Returns:\n",
        "    A Colormap for visualizing segmentation results.\n",
        "  \"\"\"\n",
        "  colormap = np.zeros((256, 3), dtype=int)\n",
        "  ind = np.arange(256, dtype=int)\n",
        "\n",
        "  for shift in reversed(range(8)):\n",
        "    for channel in range(3):\n",
        "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
        "    ind >>= 3\n",
        "\n",
        "  return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "  \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "  Args:\n",
        "    label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "  Returns:\n",
        "    result: A 2D array with floating type. The element of the array\n",
        "      is the color indexed by the corresponding element in the input label\n",
        "      to the PASCAL color map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If label is not of rank 2 or its value is larger than color\n",
        "      map maximum entry.\n",
        "  \"\"\"\n",
        "  if label.ndim != 2:\n",
        "    raise ValueError('Expect 2-D input label')\n",
        "\n",
        "  colormap = create_pascal_label_colormap()\n",
        "\n",
        "  if np.max(label) >= len(colormap):\n",
        "    raise ValueError('label value too large.')\n",
        "\n",
        "  return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map, body_color, pants_color):\n",
        "  \"\"\"Visualizes input image, segmentation map, segmentation overlay, blob overlay and biggest blob overlay view.\"\"\"\n",
        "  plt.figure(figsize=(30, 5))\n",
        "  grid_spec = gridspec.GridSpec(1, 6, width_ratios=[6, 6, 6, 6, 6, 1])\n",
        "\n",
        "  plt.subplot(grid_spec[0])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title('input image')\n",
        "\n",
        "  plt.subplot(grid_spec[1])\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation map')\n",
        "\n",
        "  plt.subplot(grid_spec[2])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(seg_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation overlay')\n",
        "\n",
        "  plt.subplot(grid_spec[3])\n",
        "  blob_image, biggest_blobs, _ = get_contours_with_colors(seg_image, body_color, pants_color)\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(blob_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('blob overlay')\n",
        "\n",
        "  plt.subplot(grid_spec[4])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(biggest_blobs, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('biggest blob overlay')\n",
        "\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(grid_spec[5])\n",
        "  plt.imshow(FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right()\n",
        "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "  plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0)\n",
        "  plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'Background', 'Hat', 'Hair', 'Glove', 'Sunglasses', 'UpperClothes', 'Dress', 'Coat',\n",
        "    'Socks', 'Pants', 'Jumpsuits', 'Scarf', 'Skirt', 'Face', 'Left-Arm', 'Arm',\n",
        "    'Left-leg', 'Leg', 'Left-shoe', 'Shoe'\n",
        "])\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)\n",
        "\n",
        "MODEL = DeepLabModel(MODEL_INFER_GRAPH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCT9-TKtMEr"
      },
      "source": [
        "BODY_COLOR = FULL_COLOR_MAP[5]\n",
        "PANTS_COLOR = FULL_COLOR_MAP[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If6g8BmfCNo3"
      },
      "source": [
        "## Functions definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE3SHk4CG6ry"
      },
      "source": [
        "def save_annotation(original_annotations, object_detection):\n",
        "  global NEW_ANNOTATIONS\n",
        "\n",
        "  if NEW_ANNOTATIONS is not None and original_annotations is not None:\n",
        "    df_ann = pd.read_csv(original_annotations, header=None)\n",
        "    df_ann.columns = [\"filename\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class\"]\n",
        "    df_ann = df_ann[df_ann['filename'].str.endswith(os.path.basename(object_detection['filename']))]\n",
        "\n",
        "    for index, row in df_ann.iterrows():\n",
        "      x_min = row['x_min'] - object_detection['x']\n",
        "      y_min = row['y_min'] - object_detection['y']\n",
        "      x_max = (object_detection['x2'] - object_detection['x']) - (object_detection['x2'] -  row['x_max'])\n",
        "      y_max = (object_detection['y2'] - object_detection['y']) - (object_detection['y2'] -  row['y_max'])\n",
        "\n",
        "      if (x_min >= 0 and y_min >= 0 and x_max >= 0 and y_max >= 0) and (x_min <= (object_detection['x2'] - object_detection['x']) and y_min <= (object_detection['y2'] - object_detection['y']) and x_max <= (object_detection['x2'] - object_detection['x']) and y_max <= (object_detection['y2'] - object_detection['y'])):\n",
        "        NEW_ANNOTATIONS = NEW_ANNOTATIONS.append({\n",
        "            'filename': object_detection['filename'],\n",
        "            'x_min': x_min,\n",
        "            'y_min': y_min,\n",
        "            'x_max': x_max,\n",
        "            'y_max': y_max,\n",
        "            'class': row['class']\n",
        "        }, ignore_index=True)\n",
        "        print(NEW_ANNOTATIONS.tail().iloc[:, 1:5])\n",
        "      else:\n",
        "        print('Not valid annotation placing', x_min, y_min, x_max, y_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR0p84kAMpCv"
      },
      "source": [
        "def biggest_contours(contours_body, contours_pants):\n",
        "  \"\"\"Finds the contours with highest area with body and pants label.\n",
        "\n",
        "    Args:\n",
        "      contours_body: Contours found labeled as body\n",
        "      contours_pants: Contours found labeled as pants\n",
        "\n",
        "    Returns:\n",
        "      biggest_body: Index of the highest-area body contour\n",
        "      biggest_pants: Index of the highest-area pants contour\n",
        "  \"\"\"  \n",
        "  pants_centroid = None\n",
        "  biggest_pants = 0\n",
        "\n",
        "  for index, pants in enumerate(contours_pants):\n",
        "    if cv2.contourArea(pants) > cv2.contourArea(contours_pants[biggest_pants]):\n",
        "      M = cv2.moments(pants)\n",
        "      cx = int(M[\"m10\"] / M[\"m00\"]) if int(M[\"m00\"]) > 0 else 0\n",
        "      cy = int(M[\"m01\"] / M[\"m00\"]) if int(M[\"m00\"]) > 0 else 0\n",
        "      pants_centroid = (cx, cy)\n",
        "      biggest_pants = index\n",
        "\n",
        "  biggest_body = None\n",
        "\n",
        "  for index, body in enumerate(contours_body):\n",
        "    M = cv2.moments(body)\n",
        "\n",
        "    cx = int(M[\"m10\"] / M[\"m00\"]) if int(M[\"m00\"]) > 0 else 0\n",
        "    cy = int(M[\"m01\"] / M[\"m00\"]) if int(M[\"m00\"]) > 0 else 0\n",
        "    body_centroid = (cx, cy)\n",
        "\n",
        "    if body_centroid[0] == 0 and body_centroid[1] == 0:\n",
        "      continue\n",
        "\n",
        "    if pants_centroid != None and body_centroid[1] < pants_centroid[1]:\n",
        "      if biggest_body == None or cv2.contourArea(body) > cv2.contourArea(contours_body[biggest_body]):\n",
        "        biggest_body = index\n",
        "    \n",
        "    if pants_centroid == None:\n",
        "       if biggest_body == None or cv2.contourArea(body) > cv2.contourArea(contours_body[biggest_body]):\n",
        "        biggest_body = index\n",
        "\n",
        "  return biggest_body, biggest_pants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JEEkUwd5lf"
      },
      "source": [
        "def crop_roi(im, seg_map, body_color, pants_color):\n",
        "  \"\"\"Crops the image to the ROI (body + pants).\n",
        "\n",
        "    Args:\n",
        "      im: Image to crop\n",
        "      seg_map: Segmentation map of the image to crop\n",
        "      body_color: Body color in the segmentation map\n",
        "      pants_color: Pants color in the segmentation map\n",
        "\n",
        "    Returns:\n",
        "      out: Cropped image within the ROI\n",
        "  \"\"\"\n",
        "  img = cv2.imread(im)\n",
        "\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "\n",
        "  _, _, contours = get_contours_with_colors(seg_image, body_color, pants_color)\n",
        "  i_body, i_pants = biggest_contours(contours[0], contours[1])\n",
        "\n",
        "  out = img\n",
        "\n",
        "  height, width = img.shape[:2]\n",
        "\n",
        "  if contours[0] !=  None and len(contours) > 0 and len(contours[0]) > 0 and i_body != None:\n",
        "    xb, yb, wb, hb = cv2.boundingRect(contours[0][i_body])\n",
        "\n",
        "    # If no pants are found, upper bound should be calculated with the body\n",
        "    xp = xb\n",
        "    yp = yb\n",
        "    wp = wb\n",
        "    hp = hb\n",
        "\n",
        "    if contours[1] !=  None and len(contours) > 1 and len(contours[1]) > 1:\n",
        "      xp, yp, wp, hp = cv2.boundingRect(contours[1][i_pants])\n",
        "\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    cv2.drawContours(mask, contours[0], i_body, (255,255,255), -1)\n",
        "    if contours[1] !=  None and len(contours) > 1 and len(contours[1]) > 1:\n",
        "      cv2.drawContours(mask, contours[1], i_pants, (255,255,255), -1)\n",
        "\n",
        "    out = np.zeros_like(img)\n",
        "\n",
        "    out[mask == 255] = img[mask == 255]\n",
        "    out[mask == 0] = img[mask == 0]\n",
        "\n",
        "    (top_y, top_x) = (yb, min(xb, xp))\n",
        "    (bottom_y, bottom_x) = (yp + hp, max(xb + wb, xp + wp))\n",
        "\n",
        "    # Check if x-y coordinates are ok - else use the whole image \n",
        "    # semantic segmentation went wrong\n",
        "\n",
        "    if top_y < bottom_y and top_x < bottom_x: \n",
        "      out = out[top_y:bottom_y+1, top_x:bottom_x+1]\n",
        "\n",
        "      if USING_ANNOTATIONS:\n",
        "        save_annotation(VIS_IMAGES_ANNOTATIONS, {\n",
        "            'filename': im, \n",
        "            'x': top_x, \n",
        "            'y': top_y, \n",
        "            'x2': bottom_x, \n",
        "            'y2': bottom_y\n",
        "            })\n",
        "    else:\n",
        "      print('Segmentation went wrong. Using whole image')\n",
        "      out = img\n",
        "\n",
        "      if USING_ANNOTATIONS:\n",
        "        save_annotation(VIS_IMAGES_ANNOTATIONS, {\n",
        "            'filename': im, \n",
        "            'x': 0, \n",
        "            'y': 0, \n",
        "            'x2': width, \n",
        "            'y2': height\n",
        "            }) \n",
        "  else:\n",
        "    # Upper body segmentation not found: Save the annotation like the original\n",
        "    if USING_ANNOTATIONS:\n",
        "      print('Body segmentation not found')\n",
        "      save_annotation(VIS_IMAGES_ANNOTATIONS, {\n",
        "          'filename': im, \n",
        "          'x': 0, \n",
        "          'y': 0, \n",
        "          'x2': width, \n",
        "          'y2': height\n",
        "          }) \n",
        "\n",
        "  return cv2.cvtColor(out, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajZigb0vuQgC"
      },
      "source": [
        "def crop_roi_bottom(im, seg_map, body_color):\n",
        "  \"\"\"Crops the image to the ROI (body + bottom-image).\n",
        "\n",
        "    Args:\n",
        "      im: Image to crop\n",
        "      seg_map: Segmentation map of the image to crop\n",
        "      body_color: Body color in the segmentation map\n",
        "\n",
        "    Returns:\n",
        "      out: Cropped image within the ROI\n",
        "  \"\"\"\n",
        "  img = cv2.imread(im)\n",
        "\n",
        "  height, width = img.shape[:2]\n",
        "\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "\n",
        "  _, _, contours = get_contours_with_colors(seg_image, body_color, None)\n",
        "  i_body, _ = biggest_contours(contours[0], [])\n",
        "\n",
        "  out = img\n",
        "\n",
        "  height, width = img.shape[:2]\n",
        "\n",
        "  if contours[0] !=  None and len(contours) > 0 and len(contours[0]) > 0 and i_body != None:\n",
        "    xb, yb, wb, hb = cv2.boundingRect(contours[0][i_body])\n",
        "\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    cv2.drawContours(mask, contours[0], i_body, (255,255,255), -1)\n",
        "    out = np.zeros_like(img)\n",
        "\n",
        "    out[mask == 255] = img[mask == 255]\n",
        "    out[mask == 0] = img[mask == 0]\n",
        "\n",
        "    (top_y, top_x) = (yb, xb)\n",
        "    (bottom_y, bottom_x) = (height, width)\n",
        "    out = out[top_y:bottom_y+1, top_x:bottom_x+1]\n",
        "\n",
        "    if USING_ANNOTATIONS:\n",
        "      save_annotation(VIS_IMAGES_ANNOTATIONS, {\n",
        "          'filename': im, \n",
        "          'x': top_x, \n",
        "          'y': top_y, \n",
        "          'x2': bottom_x, \n",
        "          'y2': bottom_y\n",
        "          }) \n",
        "  else:\n",
        "    # Upper body segmentation not found: Save the annotation like the original\n",
        "    if USING_ANNOTATIONS:\n",
        "      print('Body segmentation not found')\n",
        "      save_annotation(VIS_IMAGES_ANNOTATIONS, {\n",
        "          'filename': im, \n",
        "          'x': 0, \n",
        "          'y': 0, \n",
        "          'x2': width, \n",
        "          'y2': height\n",
        "          }) \n",
        "\n",
        "  return cv2.cvtColor(out, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwAYuhWZt0_Q"
      },
      "source": [
        "def get_contours_with_colors(seg_map, body_color, pants_color):\n",
        "  \"\"\"Get contours of the ROI (body + pants).\n",
        "\n",
        "    Args:\n",
        "      seg_map: Segmentation map of the image\n",
        "      body_color: Body color in the segmentation map\n",
        "      pants_color: Pants color in the segmentation map\n",
        "\n",
        "    Returns:\n",
        "      seg_map: Segmentation map with the contours drawn\n",
        "      seg_map_biggest_blobs: Segmentation map with the highest-area contours drawn\n",
        "      [contours_body, contours_pants]: List of the contours found\n",
        "  \"\"\" \n",
        "  seg_map_body = np.copy(seg_map)\n",
        "  seg_map_pants = np.copy(seg_map)\n",
        "  seg_map_biggest_blobs = np.copy(seg_map)\n",
        "\n",
        "  seg_map_body[seg_map_body == body_color] = 255\n",
        "  seg_map_pants[seg_map_pants == pants_color] = 255\n",
        "\n",
        "  imgray_body = cv2.cvtColor(seg_map_body, cv2.COLOR_BGR2GRAY)\n",
        "  imgray_pants = cv2.cvtColor(seg_map_pants, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  _, thresh_body = cv2.threshold(imgray_body, 254, 255, cv2.THRESH_BINARY)\n",
        "  _, thresh_pants = cv2.threshold(imgray_pants, 254, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  contours_body, _ = cv2.findContours(thresh_body, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours_pants, _ = cv2.findContours(thresh_pants, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  biggest_body, biggest_pants = biggest_contours(contours_body, contours_pants)\n",
        "\n",
        "  cv2.drawContours(seg_map, contours_body, -1, (0,255,0), 3)\n",
        "  cv2.drawContours(seg_map, contours_pants, -1, (255,255,0), 3)\n",
        "\n",
        "  if biggest_body != None:\n",
        "    cv2.drawContours(seg_map_biggest_blobs, contours_body, biggest_body, (0,255,0), 3)\n",
        "  if biggest_pants != None:\n",
        "    cv2.drawContours(seg_map_biggest_blobs, contours_pants, biggest_pants, (255,255,0), 3)\n",
        "\n",
        "  return seg_map, seg_map_biggest_blobs, [contours_body, contours_pants]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNypR7leCYD7"
      },
      "source": [
        "## Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvYL_sH4CHFj"
      },
      "source": [
        "image_list_siani = os.listdir(VIS_IMAGES)\n",
        "image_picker_siani = widgets.Dropdown(options=image_list_siani, value=image_list_siani[0], disabled=False)\n",
        "image_picker_siani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hs-lbRoCssN"
      },
      "source": [
        "### Segmentation and blobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZvFyTPLpXY"
      },
      "source": [
        "def run_visualization_siani(file):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    original_im = Image.open(os.path.join(VIS_IMAGES, file))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check file: ' + os.path.join(VIS_IMAGES, file))\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % file)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  vis_segmentation(resized_im, seg_map, BODY_COLOR, PANTS_COLOR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxo95bSHp8bw"
      },
      "source": [
        "run_visualization_siani(image_picker_siani.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGHo9BEuCw-T"
      },
      "source": [
        "### Cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0mEoAocvZa"
      },
      "source": [
        "def run_crop_siani(file):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    original_im = Image.open(os.path.join(VIS_IMAGES, file))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check file: ' + os.path.join(VIS_IMAGES, file))\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % file)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  return resized_im, crop_roi(os.path.join(VIS_IMAGES, file), seg_map, BODY_COLOR, PANTS_COLOR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-wvPkeyxAC8"
      },
      "source": [
        "def run_crop_bottom(file):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    original_im = Image.open(os.path.join(VIS_IMAGES, file))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check file: ' + os.path.join(VIS_IMAGES, file))\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % file)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  return resized_im, crop_roi_bottom(os.path.join(VIS_IMAGES, file), seg_map, BODY_COLOR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtzG8AQhqAjg"
      },
      "source": [
        "img, crop = run_crop_siani(image_picker_siani.value)\n",
        "\n",
        "print(f'\\nOriginal image: ({img.size[1]}, {img.size[0]})')\n",
        "print(f'Cropped image: {crop.shape}\\n')\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "fig.add_subplot(1,2,2)\n",
        "plt.imshow(Image.fromarray(crop))\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScY7T9QuGaUH"
      },
      "source": [
        "## Crop and save all images in a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGQclpYIMla"
      },
      "source": [
        "%mkdir {EXPORT_CROP}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lScJWm3Pl3lH"
      },
      "source": [
        "### Format 1: A single directory with all the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pjEodkZGfVm"
      },
      "source": [
        "skip_existing_imgs = True\n",
        "total = len(glob.glob1(VIS_IMAGES, \"*.jpg\"))\n",
        "count = 0\n",
        "\n",
        "for filename in glob.glob(VIS_IMAGES + '/*.jpg'):\n",
        "  if skip_existing_imgs and os.path.exists(os.path.join(EXPORT_CROP, os.path.basename(filename))):\n",
        "    print(f'Skipping image {os.path.join(EXPORT_CROP, os.path.basename(filename))}')\n",
        "  else:\n",
        "    _, crop = run_crop_siani(os.path.join(VIS_IMAGES, filename))\n",
        "    cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "    if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "      NEW_ANNOTATIONS.to_csv(os.path.join(EXPORT_CROP, 'annotateTest.csv'), header=None, index=False)\n",
        "  count = count + 1\n",
        "  print(f'Image {count}/{total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJHAr1BPu8jF"
      },
      "source": [
        "### Format 1.1: A single directory with all the images - Ignore images with bad annotation crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMGfNXj2u5XN"
      },
      "source": [
        "total = len(glob.glob1(VIS_IMAGES, \"*.jpg\"))\n",
        "count = 0\n",
        "annotations_count = 0\n",
        "\n",
        "for filename in glob.glob(VIS_IMAGES + '/*.jpg'):\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    annotations_count = len(NEW_ANNOTATIONS.index)\n",
        "\n",
        "  _, crop = run_crop_siani(os.path.join(VIS_IMAGES, filename))\n",
        "\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    df_ann = pd.read_csv(VIS_IMAGES_ANNOTATIONS, header=None)\n",
        "    df_ann.columns = [\"filename\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class\"]\n",
        "    df_ann = df_ann[df_ann['filename'].str.endswith(os.path.basename(filename))]\n",
        "\n",
        "    if len(df_ann.index) == 0 or (len(df_ann.index) > 0 and len(NEW_ANNOTATIONS) > annotations_count):\n",
        "      cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "  else:\n",
        "    cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    NEW_ANNOTATIONS.to_csv(os.path.join(EXPORT_CROP, 'annotateTest.csv'), header=None, index=False)\n",
        "    \n",
        "  count = count + 1\n",
        "  print(f'Image {count}/{total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asRzMdxuwt5s"
      },
      "source": [
        "### Format 1.2: A single directory with all the images - Upper body to bottom image crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfHtxv0Kw7Er"
      },
      "source": [
        "total = len(glob.glob1(VIS_IMAGES, \"*.jpg\"))\n",
        "count = 0\n",
        "annotations_count = 0\n",
        "\n",
        "for filename in glob.glob(VIS_IMAGES + '/*.jpg'):\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    annotations_count = len(NEW_ANNOTATIONS.index)\n",
        "\n",
        "  _, crop = run_crop_bottom(os.path.join(VIS_IMAGES, filename))\n",
        "\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    df_ann = pd.read_csv(VIS_IMAGES_ANNOTATIONS, header=None)\n",
        "    df_ann.columns = [\"filename\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class\"]\n",
        "    df_ann = df_ann[df_ann['filename'].str.endswith(os.path.basename(filename))]\n",
        "\n",
        "    if len(df_ann.index) == 0 or (len(df_ann.index) > 0 and len(NEW_ANNOTATIONS) > annotations_count):\n",
        "      cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "  else:\n",
        "    cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  if USING_ANNOTATIONS and NEW_ANNOTATIONS is not None:\n",
        "    NEW_ANNOTATIONS.to_csv(os.path.join(EXPORT_CROP, 'annotateTest.csv'), header=None, index=False)\n",
        "\n",
        "  count = count + 1\n",
        "  print(f'Image {count}/{total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdO9NvxWmA6j"
      },
      "source": [
        "### Format 2: A directory with multiple directories with images in each of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2_eSPvqo3oV"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for root, subdirs, files in os.walk(VIS_IMAGES):\n",
        "  if len(subdirs) == 0:\n",
        "    dir = os.path.join(EXPORT_CROP, os.path.basename(root))\n",
        "    try:\n",
        "      os.mkdir(dir)\n",
        "      print(f'[+] Directory {dir} created') \n",
        "    except FileExistsError:\n",
        "      pass\n",
        "\n",
        "    for file in files:\n",
        "      file_path = os.path.join(os.path.join(VIS_IMAGES, os.path.basename(root)), file)\n",
        "      _, crop = run_crop_siani(file_path)\n",
        "      cv2.imwrite(os.path.join(dir, file), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "      count = count + 1\n",
        "      print(f'Image {count}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}