{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UseDeeplabCustomModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH7MFGWIvy4R"
      },
      "source": [
        "# Usage of Deeplab + LIP model and extracion of ROI "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEsjy-ccwIa_"
      },
      "source": [
        "In this notebook, the segmentation of the desired images are done, followed by a contour processing to reduce the impact of noise and segmentation errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNMXjXG_whRI"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5QaI5ft_dv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1846b56-4dc4-4ed7-b5c0-1f49ecc068aa"
      },
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import ipywidgets as widgets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9kg4Xko188W"
      },
      "source": [
        "## Path definitions - change to your own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7MjpjS11-op"
      },
      "source": [
        "MODEL_INFER_GRAPH = \"/content/drive/MyDrive/TFM/model_19_60k/frozen_inference_graph.pb\"\n",
        "VIS_IMAGES = \"/content/drive/MyDrive/TFM/TGC_places/TGC_places/Ayagaures\"\n",
        "EXPORT_CROP = \"/content/drive/MyDrive/TFM/crop_results\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPef1973wtpK"
      },
      "source": [
        "## Mount Google Drive storage\n",
        "In case you need it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5viQ7RWRBycX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b929feba-95af-49e4-f0b5-122dd8f7dff2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uioTYmbgxETk"
      },
      "source": [
        "## Deeplab model class to perform the segmentation and visualize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTELfw8_hno"
      },
      "source": [
        "class DeepLabModel(object):\n",
        "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "  def __init__(self, frozen_graph):\n",
        "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "    self.graph = tf.Graph()\n",
        "\n",
        "    f = open(frozen_graph, \"rb\")\n",
        "    graph_df = tf.GraphDef.FromString(f.read())\n",
        "\n",
        "    if not os.path.isfile(frozen_graph) or graph_df is None:\n",
        "      raise RuntimeError('Cannot find inference graph.')\n",
        "\n",
        "    with self.graph.as_default():\n",
        "      tf.import_graph_def(graph_df, name='')\n",
        "\n",
        "    self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "  def run(self, image):\n",
        "    \"\"\"Runs inference on a single image.\n",
        "\n",
        "    Args:\n",
        "      image: A PIL.Image object, raw input image.\n",
        "\n",
        "    Returns:\n",
        "      resized_image: RGB image resized from original input image.\n",
        "      seg_map: Segmentation map of `resized_image`.\n",
        "    \"\"\"\n",
        "    batch_seg_map = self.sess.run(\n",
        "        self.OUTPUT_TENSOR_NAME,\n",
        "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(image)]}\n",
        "    )\n",
        "    \n",
        "    seg_map = unify_labels(batch_seg_map[0])\n",
        "    \n",
        "\n",
        "    return image, seg_map\n",
        "\n",
        "\n",
        "def unify_labels(seg_map):\n",
        "  \"\"\"Unifies certains labels from LIP in the segmentation map.\n",
        "\n",
        "    Args:\n",
        "      seg_map: Segmentation map from DeeplabModel run(sel, image) method\n",
        "\n",
        "    Returns:\n",
        "      seg_map: Segmentation map with unified labels.\n",
        "    \"\"\"\n",
        "\n",
        "  # Dress and Coat will be appear as UpperClothes\n",
        "  seg_map = np.where(seg_map==6, 5, seg_map) # UpperClothes == Dress\n",
        "  seg_map = np.where(seg_map==7, 5, seg_map) # UpperClothes == Coat\n",
        "  \n",
        "  # Fuse left and right arm in a single instance\n",
        "  seg_map = np.where(seg_map==14, 15, seg_map) \n",
        "\n",
        "  # Fuse left and right leg in a single instance\n",
        "  seg_map = np.where(seg_map==16, 17, seg_map)\n",
        "\n",
        "  # Fuse left and right shoe in a single instance\n",
        "  seg_map = np.where(seg_map==18, 19, seg_map) \n",
        "\n",
        "  return seg_map\n",
        "\n",
        "def create_pascal_label_colormap():\n",
        "  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n",
        "\n",
        "  Returns:\n",
        "    A Colormap for visualizing segmentation results.\n",
        "  \"\"\"\n",
        "  colormap = np.zeros((256, 3), dtype=int)\n",
        "  ind = np.arange(256, dtype=int)\n",
        "\n",
        "  for shift in reversed(range(8)):\n",
        "    for channel in range(3):\n",
        "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
        "    ind >>= 3\n",
        "\n",
        "  return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "  \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "  Args:\n",
        "    label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "  Returns:\n",
        "    result: A 2D array with floating type. The element of the array\n",
        "      is the color indexed by the corresponding element in the input label\n",
        "      to the PASCAL color map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If label is not of rank 2 or its value is larger than color\n",
        "      map maximum entry.\n",
        "  \"\"\"\n",
        "  if label.ndim != 2:\n",
        "    raise ValueError('Expect 2-D input label')\n",
        "\n",
        "  colormap = create_pascal_label_colormap()\n",
        "\n",
        "  if np.max(label) >= len(colormap):\n",
        "    raise ValueError('label value too large.')\n",
        "\n",
        "  return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map, body_color, pants_color):\n",
        "  \"\"\"Visualizes input image, segmentation map, segmentation overlay, blob overlay and biggest blob overlay view.\"\"\"\n",
        "  plt.figure(figsize=(30, 5))\n",
        "  grid_spec = gridspec.GridSpec(1, 6, width_ratios=[6, 6, 6, 6, 6, 1])\n",
        "\n",
        "  plt.subplot(grid_spec[0])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title('input image')\n",
        "\n",
        "  plt.subplot(grid_spec[1])\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation map')\n",
        "\n",
        "  plt.subplot(grid_spec[2])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(seg_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation overlay')\n",
        "\n",
        "  plt.subplot(grid_spec[3])\n",
        "  blob_image, biggest_blobs, _ = get_contours_with_colors(seg_image, body_color, pants_color)\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(blob_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('blob overlay')\n",
        "\n",
        "  plt.subplot(grid_spec[4])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(biggest_blobs, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('biggest blob overlay')\n",
        "\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(grid_spec[5])\n",
        "  plt.imshow(FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right()\n",
        "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "  plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0)\n",
        "  plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'Background', 'Hat', 'Hair', 'Glove', 'Sunglasses', 'UpperClothes', 'Dress', 'Coat',\n",
        "    'Socks', 'Pants', 'Jumpsuits', 'Scarf', 'Skirt', 'Face', 'Left-Arm', 'Arm',\n",
        "    'Left-leg', 'Leg', 'Left-shoe', 'Shoe'\n",
        "])\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)\n",
        "\n",
        "MODEL = DeepLabModel(MODEL_INFER_GRAPH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCT9-TKtMEr"
      },
      "source": [
        "BODY_COLOR = FULL_COLOR_MAP[5]\n",
        "PANTS_COLOR = FULL_COLOR_MAP[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If6g8BmfCNo3"
      },
      "source": [
        "## Functions definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR0p84kAMpCv"
      },
      "source": [
        "def biggest_contours(contours_body, contours_pants):\n",
        "  \"\"\"Finds the contours with highest area with body and pants label.\n",
        "\n",
        "    Args:\n",
        "      contours_body: Contours found labeled as body\n",
        "      contours_pants: Contours found labeled as pants\n",
        "\n",
        "    Returns:\n",
        "      biggest_body: Index of the highest-area body contour\n",
        "      biggest_pants: Index of the highest-area pants contour\n",
        "  \"\"\"  \n",
        "  biggest_body = 0\n",
        "  biggest_pants = 0\n",
        "\n",
        "  for index, body in enumerate(contours_body):\n",
        "    if cv2.contourArea(body) > cv2.contourArea(contours_body[biggest_body]):\n",
        "        biggest_body = index\n",
        "\n",
        "  for index, pants in enumerate(contours_pants):\n",
        "    if cv2.contourArea(pants) > cv2.contourArea(contours_pants[biggest_pants]):\n",
        "        biggest_pants = index\n",
        "  return biggest_body, biggest_pants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JEEkUwd5lf"
      },
      "source": [
        "def crop_roi(im, seg_map, body_color, pants_color):\n",
        "  \"\"\"Crops the image to the ROI (body + pants).\n",
        "\n",
        "    Args:\n",
        "      im: Image to crop\n",
        "      seg_map: Segmentation map of the image to crop\n",
        "      body_color: Body color in the segmentation map\n",
        "      pants_color: Pants color in the segmentation map\n",
        "\n",
        "    Returns:\n",
        "      out: Cropped image within the ROI\n",
        "  \"\"\" \n",
        "  img = cv2.imread(im)\n",
        "\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "\n",
        "  _, _, contours = get_contours_with_colors(seg_image, body_color, pants_color)\n",
        "  i_body, i_pants = biggest_contours(contours[0], contours[1])\n",
        "\n",
        "  xb, yb, wb, hb = cv2.boundingRect(contours[0][i_body])\n",
        "  xp, yp, wp, hp = cv2.boundingRect(contours[1][i_pants])\n",
        "\n",
        "  mask = np.zeros_like(img)\n",
        "\n",
        "  cv2.drawContours(mask, contours[0], i_body, (255,255,255), -1)\n",
        "  cv2.drawContours(mask, contours[1], i_pants, (255,255,255), -1)\n",
        "\n",
        "  out = np.zeros_like(img)\n",
        "\n",
        "  out[mask == 255] = img[mask == 255]\n",
        "  out[mask == 0] = img[mask == 0]\n",
        "\n",
        "  (top_y, top_x) = (yb, xb)\n",
        "  (bottom_y, bottom_x) = (yp + hp, xp + wp)\n",
        "  out = out[top_y:bottom_y+1, top_x:bottom_x+1]\n",
        "\n",
        "  return cv2.cvtColor(out, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwAYuhWZt0_Q"
      },
      "source": [
        "def get_contours_with_colors(seg_map, body_color, pants_color):\n",
        "  \"\"\"Get contours of the ROI (body + pants).\n",
        "\n",
        "    Args:\n",
        "      seg_map: Segmentation map of the image\n",
        "      body_color: Body color in the segmentation map\n",
        "      pants_color: Pants color in the segmentation map\n",
        "\n",
        "    Returns:\n",
        "      seg_map: Segmentation map with the contours drawn\n",
        "      seg_map_biggest_blobs: Segmentation map with the highest-area contours drawn\n",
        "      [contours_body, contours_pants]: List of the contours found\n",
        "  \"\"\" \n",
        "  seg_map_body = np.copy(seg_map)\n",
        "  seg_map_pants = np.copy(seg_map)\n",
        "  seg_map_biggest_blobs = np.copy(seg_map)\n",
        "\n",
        "  seg_map_body[seg_map_body == body_color] = 255\n",
        "  seg_map_pants[seg_map_pants == pants_color] = 255\n",
        "\n",
        "  imgray_body = cv2.cvtColor(seg_map_body, cv2.COLOR_BGR2GRAY)\n",
        "  imgray_pants = cv2.cvtColor(seg_map_pants, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  _, thresh_body = cv2.threshold(imgray_body, 254, 255, cv2.THRESH_BINARY)\n",
        "  _, thresh_pants = cv2.threshold(imgray_pants, 254, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  contours_body, _ = cv2.findContours(thresh_body, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours_pants, _ = cv2.findContours(thresh_pants, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  biggest_body, biggest_pants = biggest_contours(contours_body, contours_pants)\n",
        "\n",
        "  cv2.drawContours(seg_map, contours_body, -1, (0,255,0), 3)\n",
        "  cv2.drawContours(seg_map, contours_pants, -1, (255,255,0), 3)\n",
        "\n",
        "  cv2.drawContours(seg_map_biggest_blobs, contours_body, biggest_body, (0,255,0), 3)\n",
        "  cv2.drawContours(seg_map_biggest_blobs, contours_pants, biggest_pants, (255,255,0), 3)\n",
        "\n",
        "  return seg_map, seg_map_biggest_blobs, [contours_body, contours_pants]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNypR7leCYD7"
      },
      "source": [
        "## Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvYL_sH4CHFj"
      },
      "source": [
        "image_list_siani = os.listdir(VIS_IMAGES)\n",
        "image_picker_siani = widgets.Dropdown(options=image_list_siani, value=image_list_siani[0], disabled=False)\n",
        "image_picker_siani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hs-lbRoCssN"
      },
      "source": [
        "### Segmentation and blobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZvFyTPLpXY"
      },
      "source": [
        "def run_visualization_siani(file):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    original_im = Image.open(os.path.join(VIS_IMAGES, file))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check file: ' + os.path.join(VIS_IMAGES, file))\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % file)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  vis_segmentation(resized_im, seg_map, BODY_COLOR, PANTS_COLOR)\n",
        "\n",
        "run_visualization_siani(image_picker_siani.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGHo9BEuCw-T"
      },
      "source": [
        "### Cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0mEoAocvZa"
      },
      "source": [
        "def run_crop_siani(file):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    original_im = Image.open(os.path.join(VIS_IMAGES, file))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check file: ' + os.path.join(VIS_IMAGES, file))\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % file)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  return resized_im, crop_roi(os.path.join(VIS_IMAGES, file), seg_map, BODY_COLOR, PANTS_COLOR)\n",
        "\n",
        "img, crop = run_crop_siani(image_picker_siani.value)\n",
        "\n",
        "print(f'\\nOriginal image: ({img.size[1]}, {img.size[0]})')\n",
        "print(f'Cropped image: {crop.shape}\\n')\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "fig.add_subplot(1,2,2)\n",
        "plt.imshow(Image.fromarray(crop))\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScY7T9QuGaUH"
      },
      "source": [
        "## Crop and save all images in a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGQclpYIMla"
      },
      "source": [
        "%mkdir {EXPORT_CROP}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pjEodkZGfVm"
      },
      "source": [
        "total = len(glob.glob1(VIS_IMAGES, \"*.jpg\"))\n",
        "count = 0\n",
        "\n",
        "for filename in glob.glob(VIS_IMAGES + '/*.jpg'):\n",
        "  _, crop = run_crop_siani(os.path.join(VIS_IMAGES, filename))\n",
        "  cv2.imwrite(os.path.join(EXPORT_CROP, os.path.basename(filename)), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "  count = count + 1\n",
        "  print(f'Image {count}/{total}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}