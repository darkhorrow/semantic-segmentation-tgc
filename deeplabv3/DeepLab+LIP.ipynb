{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLab+LIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5bhjtWsOGEU"
      },
      "source": [
        "# Deeplabv3 + LIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nisjqD6ZlmuG"
      },
      "source": [
        "## Path definitions - change to your own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfHFNuxXlk1G"
      },
      "source": [
        "ROOT_PROJECT = \"/content/drive/MyDrive/TFM\"\n",
        "TRAIN_VAL_IMAGES = os.path.join(ROOT_PROJECT, 'lip_trainval_images')\n",
        "TRAIN_VAL_SEGMENTATIONS = os.path.join(ROOT_PROJECT, 'lip_trainval_segmentations')\n",
        "TRAIN_TFRECORD = os.path.join(ROOT_PROJECT, 'train_lip_tfrecord')\n",
        "VAL_TFRECORD = os.path.join(ROOT_PROJECT, 'val_lip_tfrecord')\n",
        "TRAIN_VAL_TFRECORD = os.path.join(ROOT_PROJECT, 'trainval_lip_tfrecord')\n",
        "CHECKPOINT = os.path.join(ROOT_PROJECT, 'checkpoint_lip_mobilenet')\n",
        "PRETRAINED_MODEL = os.path.join(ROOT_PROJECT, 'deeplabv3_mnv2_pascal_train_aug/model.ckpt-30000')\n",
        "EVAL_RESULTS = os.path.join(ROOT_PROJECT, 'eval_results_lip')\n",
        "VIS_RESULTS = os.path.join(ROOT_PROJECT, 'vis_results_lip')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLPh3_Yl0Fl"
      },
      "source": [
        "## Setup Deeplabv3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySRcX9P61CxY"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.3\n",
        "!pip install tf_slim==1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIDpAbAl2d78"
      },
      "source": [
        "%env TF_CPP_MIN_LOG_LEVEL=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVp1uuC8F0f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhJxu73pF-wM"
      },
      "source": [
        "%cd {ROOT_PROJECT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD1z3vED2Rz2"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFKuwCK-21qr"
      },
      "source": [
        "%cd {ROOT_PROJECT}/models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpn6pXo124Er"
      },
      "source": [
        "%env PYTHONPATH={ROOT_PROJECT}/models/research/:{ROOT_PROJECT}/models/research/deeplab:{ROOT_PROJECT}/models/research/slim:/env/python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtjq5ghc0fyY"
      },
      "source": [
        "%cd {ROOT_PROJECT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhaWByTCPFs-"
      },
      "source": [
        "## Using LIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_fDp6BLxh_E"
      },
      "source": [
        "### Unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUydjH3IX8oG"
      },
      "source": [
        "!unzip {ROOT_PROJECT}/LIP/TrainVal_images.zip -d {TRAIN_VAL_IMAGES}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tc6agE-ZJJE"
      },
      "source": [
        "!unzip -q {TRAIN_VAL_IMAGES}/TrainVal_images.zip -d {TRAIN_VAL_IMAGES}/TrainVal_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPo7X-KwcMj_"
      },
      "source": [
        "!unzip {ROOT_PROJECT}/LIP/TrainVal_parsing_annotations.zip -d {TRAIN_VAL_SEGMENTATIONS}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ8iMnsPcT7k"
      },
      "source": [
        "!unzip -q {TRAIN_VAL_SEGMENTATIONS}/TrainVal_parsing_annotations/TrainVal_parsing_annotations.zip -d {TRAIN_VAL_SEGMENTATIONS}/TrainVal_parsing_annotations/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHRQ2xc6xpXb"
      },
      "source": [
        "### Build tfrecord of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgwGYAzeHOiI"
      },
      "source": [
        "!mkdir {TRAIN_TFRECORD}\n",
        "!mkdir {VAL_TFRECORD}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lOFxtxCIYcq"
      },
      "source": [
        "!python models/research/deeplab/datasets/build_voc2012_data.py \\\n",
        "  --image_folder=\"{TRAIN_VAL_IMAGES}/TrainVal_images/train_images\" \\\n",
        "  --semantic_segmentation_folder=\"{TRAIN_VAL_SEGMENTATIONS}/TrainVal_parsing_annotations/train_segmentations\" \\\n",
        "  --list_folder=\"{TRAIN_VAL_IMAGES}\" \\\n",
        "  --image_format=\"jpg\" \\\n",
        "  --output_dir=\"{TRAIN_TFRECORD}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKKAe-ZQBFW"
      },
      "source": [
        "!python models/research/deeplab/datasets/build_voc2012_data.py \\\n",
        "  --image_folder=\"{TRAIN_VAL_IMAGES}/TrainVal_images/val_images\" \\\n",
        "  --semantic_segmentation_folder=\"{TRAIN_VAL_SEGMENTATIONS}/TrainVal_parsing_annotations/val_segmentations\" \\\n",
        "  --list_folder=\"{TRAIN_VAL_IMAGES}\" \\\n",
        "  --image_format=\"jpg\" \\\n",
        "  --output_dir=\"{VAL_TFRECORD}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kHtC1vUz9xa"
      },
      "source": [
        "#### Move both tfrecord to a single directory and rename them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdQQBJ2H4a1z"
      },
      "source": [
        "%cd {TRAIN_TFRECORD}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBIIxYJ74dk3"
      },
      "source": [
        "!rename 's/_id//;' *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMvQtEFK1TDw"
      },
      "source": [
        "%cd {VAL_TFRECORD}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Df3-WhS0ESz"
      },
      "source": [
        "!rename 's/_id//;' *"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O-Li81s3T6D"
      },
      "source": [
        "%mv {VAL_TFRECORD}/* {TRAIN_VAL_TFRECORD}\n",
        "%mv {TRAIN_TFRECORD}/* {TRAIN_VAL_TFRECORD}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrkgaK3eOn0Y"
      },
      "source": [
        "## Train with LIP\n",
        "Use the --dataset param with lip or cihp to change the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kwanfwFjhZ_"
      },
      "source": [
        "%mkdir {CHECKPOINT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4MQgN9m7AKn"
      },
      "source": [
        "%cd {ROOT_PROJECT}/models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3XXP7_Jsw0J"
      },
      "source": [
        "!python deeplab/model_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6HQbwt1SnA"
      },
      "source": [
        "Use the following parameter only if its the first time you run it: --tf_initial_checkpoint=\"{PRETRAINED_MODEL}\" \\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRJ5Qhm6fD3I",
        "outputId": "8a97d8d3-ad4e-4680-ed48-7791487ef403"
      },
      "source": [
        "!python deeplab/train.py --logtostderr \\\n",
        "  --training_number_of_steps=60000 \\\n",
        "  --train_split=\"train\" \\\n",
        "  --model_variant=\"mobilenet_v2\" \\\n",
        "  --atrous_rates=6 \\\n",
        "  --atrous_rates=12 \\\n",
        "   --atrous_rates=18 \\\n",
        "   --output_stride=16 \\\n",
        "   --decoder_output_stride=4 \\\n",
        "   --train_batch_size=1 \\\n",
        "   --dataset=\"lip\" \\\n",
        "   --train_logdir=\"{CHECKPOINT}\" \\\n",
        "   --dataset_dir=\"{TRAIN_VAL_TFRECORD}\" \\\n",
        "   --fine_tune_batch_norm=false \\\n",
        "   --initialize_last_layer=false \\\n",
        "   --last_layers_contain_logits_only=false"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:464: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0608 11:35:52.292854 139948276815744 module_wrapper.py:139] From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0608 11:35:52.293177 139948276815744 module_wrapper.py:139] From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0608 11:35:52.293476 139948276815744 module_wrapper.py:139] From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0608 11:35:52.294134 139948276815744 module_wrapper.py:139] From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Training on train set\n",
            "I0608 11:35:52.294309 139948276815744 train.py:290] Training on train set\n",
            "WARNING:tensorflow:From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0608 11:35:52.295467 139948276815744 module_wrapper.py:139] From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:375: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0608 11:35:52.301678 139948276815744 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:375: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0608 11:35:52.458060 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0608 11:35:52.459153 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0608 11:35:53.513100 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0608 11:35:53.516826 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0608 11:35:54.451242 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.lin_space is deprecated. Please use tf.linspace instead.\n",
            "\n",
            "W0608 11:35:54.452257 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.lin_space is deprecated. Please use tf.linspace instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0608 11:35:54.453030 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0608 11:35:54.738495 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.reverse_v2 is deprecated. Please use tf.reverse instead.\n",
            "\n",
            "W0608 11:35:57.788423 139948276815744 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.reverse_v2 is deprecated. Please use tf.reverse instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:364: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0608 11:35:58.082777 139948276815744 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:364: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0608 11:35:58.114675 139948276815744 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0608 11:35:58.115272 139948276815744 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0608 11:35:58.119933 139948276815744 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0608 11:36:00.884289 139948276815744 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W0608 11:36:01.194010 139948276815744 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:326: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0608 11:36:01.194425 139948276815744 module_wrapper.py:139] From deeplab/train.py:326: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:326: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0608 11:36:01.194560 139948276815744 module_wrapper.py:139] From deeplab/train.py:326: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:332: The name tf.model_variables is deprecated. Please use tf.compat.v1.model_variables instead.\n",
            "\n",
            "W0608 11:36:01.194710 139948276815744 module_wrapper.py:139] From deeplab/train.py:332: The name tf.model_variables is deprecated. Please use tf.compat.v1.model_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0608 11:36:01.194904 139948276815744 module_wrapper.py:139] From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0608 11:36:01.579269 139948276815744 module_wrapper.py:139] From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "INFO:tensorflow:Setting decay_steps to total training steps.\n",
            "I0608 11:36:01.583312 139948276815744 train_utils.py:327] Setting decay_steps to total training steps.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0608 11:36:01.583622 139948276815744 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:372: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0608 11:36:01.601315 139948276815744 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/utils/train_utils.py:372: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0608 11:36:01.605956 139948276815744 module_wrapper.py:139] From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:398: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "W0608 11:36:03.235972 139948276815744 module_wrapper.py:139] From deeplab/train.py:398: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0608 11:36:04.539395 139948276815744 module_wrapper.py:139] From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/train.py:427: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0608 11:36:04.550229 139948276815744 module_wrapper.py:139] From deeplab/train.py:427: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0608 11:36:05.613059 139948276815744 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-45924\n",
            "I0608 11:36:06.052205 139948276815744 saver.py:1284] Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-45924\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0608 11:36:07.074547 139948276815744 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0608 11:36:07.085505 139948276815744 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0608 11:36:07.240761 139948276815744 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0608 11:36:10.820715 139948276815744 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 11:36:10.996663 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0608 11:36:10.996852 139948276815744 learning.py:768] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0608 11:36:20.988204 139946064713472 supervisor.py:1099] global_step/sec: 0\n",
            "INFO:tensorflow:Recording summary at step 45924.\n",
            "I0608 11:36:22.017475 139946056320768 supervisor.py:1050] Recording summary at step 45924.\n",
            "INFO:tensorflow:global step 45930: loss = 0.7253 (2.661 sec/step)\n",
            "I0608 11:36:38.502083 139948276815744 learning.py:507] global step 45930: loss = 0.7253 (2.661 sec/step)\n",
            "INFO:tensorflow:global step 45940: loss = 1.1821 (2.274 sec/step)\n",
            "I0608 11:37:04.524947 139948276815744 learning.py:507] global step 45940: loss = 1.1821 (2.274 sec/step)\n",
            "INFO:tensorflow:global step 45950: loss = 1.6311 (2.688 sec/step)\n",
            "I0608 11:37:29.643140 139948276815744 learning.py:507] global step 45950: loss = 1.6311 (2.688 sec/step)\n",
            "INFO:tensorflow:global step 45960: loss = 0.5547 (2.606 sec/step)\n",
            "I0608 11:37:55.306817 139948276815744 learning.py:507] global step 45960: loss = 0.5547 (2.606 sec/step)\n",
            "INFO:tensorflow:global step 45970: loss = 1.0787 (2.251 sec/step)\n",
            "I0608 11:38:19.247483 139948276815744 learning.py:507] global step 45970: loss = 1.0787 (2.251 sec/step)\n",
            "INFO:tensorflow:global step 45980: loss = 1.2008 (2.806 sec/step)\n",
            "I0608 11:38:44.360178 139948276815744 learning.py:507] global step 45980: loss = 1.2008 (2.806 sec/step)\n",
            "INFO:tensorflow:global step 45990: loss = 1.0460 (2.388 sec/step)\n",
            "I0608 11:39:07.748856 139948276815744 learning.py:507] global step 45990: loss = 1.0460 (2.388 sec/step)\n",
            "INFO:tensorflow:global step 46000: loss = 1.0663 (2.406 sec/step)\n",
            "I0608 11:39:31.603672 139948276815744 learning.py:507] global step 46000: loss = 1.0663 (2.406 sec/step)\n",
            "INFO:tensorflow:global step 46010: loss = 0.4993 (2.237 sec/step)\n",
            "I0608 11:39:53.994140 139948276815744 learning.py:507] global step 46010: loss = 0.4993 (2.237 sec/step)\n",
            "INFO:tensorflow:global step 46020: loss = 2.1123 (2.236 sec/step)\n",
            "I0608 11:40:16.460016 139948276815744 learning.py:507] global step 46020: loss = 2.1123 (2.236 sec/step)\n",
            "INFO:tensorflow:global step 46030: loss = 0.9164 (2.379 sec/step)\n",
            "I0608 11:40:40.542598 139948276815744 learning.py:507] global step 46030: loss = 0.9164 (2.379 sec/step)\n",
            "INFO:tensorflow:global step 46040: loss = 1.0891 (2.233 sec/step)\n",
            "I0608 11:41:05.835486 139948276815744 learning.py:507] global step 46040: loss = 1.0891 (2.233 sec/step)\n",
            "INFO:tensorflow:global step 46050: loss = 0.8818 (2.468 sec/step)\n",
            "I0608 11:41:31.017744 139948276815744 learning.py:507] global step 46050: loss = 0.8818 (2.468 sec/step)\n",
            "INFO:tensorflow:global step 46060: loss = 1.8773 (2.218 sec/step)\n",
            "I0608 11:41:56.404360 139948276815744 learning.py:507] global step 46060: loss = 1.8773 (2.218 sec/step)\n",
            "INFO:tensorflow:global step 46070: loss = 2.0045 (2.246 sec/step)\n",
            "I0608 11:42:18.500510 139948276815744 learning.py:507] global step 46070: loss = 2.0045 (2.246 sec/step)\n",
            "INFO:tensorflow:global step 46080: loss = 0.8282 (2.244 sec/step)\n",
            "I0608 11:42:40.633152 139948276815744 learning.py:507] global step 46080: loss = 0.8282 (2.244 sec/step)\n",
            "INFO:tensorflow:global step 46090: loss = 0.3355 (2.445 sec/step)\n",
            "I0608 11:43:03.747630 139948276815744 learning.py:507] global step 46090: loss = 0.3355 (2.445 sec/step)\n",
            "INFO:tensorflow:global step 46100: loss = 1.0683 (2.280 sec/step)\n",
            "I0608 11:43:27.767325 139948276815744 learning.py:507] global step 46100: loss = 1.0683 (2.280 sec/step)\n",
            "INFO:tensorflow:global step 46110: loss = 1.0372 (2.191 sec/step)\n",
            "I0608 11:43:50.621529 139948276815744 learning.py:507] global step 46110: loss = 1.0372 (2.191 sec/step)\n",
            "INFO:tensorflow:global step 46120: loss = 2.1359 (2.561 sec/step)\n",
            "I0608 11:44:13.968385 139948276815744 learning.py:507] global step 46120: loss = 2.1359 (2.561 sec/step)\n",
            "INFO:tensorflow:global step 46130: loss = 0.8096 (2.255 sec/step)\n",
            "I0608 11:44:37.558062 139948276815744 learning.py:507] global step 46130: loss = 0.8096 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 46140: loss = 1.9676 (2.295 sec/step)\n",
            "I0608 11:45:00.260312 139948276815744 learning.py:507] global step 46140: loss = 1.9676 (2.295 sec/step)\n",
            "INFO:tensorflow:global step 46150: loss = 0.2532 (2.240 sec/step)\n",
            "I0608 11:45:23.042658 139948276815744 learning.py:507] global step 46150: loss = 0.2532 (2.240 sec/step)\n",
            "INFO:tensorflow:global step 46160: loss = 0.9844 (2.309 sec/step)\n",
            "I0608 11:45:45.869072 139948276815744 learning.py:507] global step 46160: loss = 0.9844 (2.309 sec/step)\n",
            "INFO:tensorflow:global step 46170: loss = 1.6656 (2.382 sec/step)\n",
            "I0608 11:46:09.144611 139948276815744 learning.py:507] global step 46170: loss = 1.6656 (2.382 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 46171.\n",
            "I0608 11:46:12.532005 139946056320768 supervisor.py:1050] Recording summary at step 46171.\n",
            "INFO:tensorflow:global_step/sec: 0.417516\n",
            "I0608 11:46:12.581871 139946064713472 supervisor.py:1099] global_step/sec: 0.417516\n",
            "INFO:tensorflow:global step 46180: loss = 0.5137 (2.273 sec/step)\n",
            "I0608 11:46:33.113330 139948276815744 learning.py:507] global step 46180: loss = 0.5137 (2.273 sec/step)\n",
            "INFO:tensorflow:global step 46190: loss = 1.6560 (2.336 sec/step)\n",
            "I0608 11:46:55.934168 139948276815744 learning.py:507] global step 46190: loss = 1.6560 (2.336 sec/step)\n",
            "INFO:tensorflow:global step 46200: loss = 0.8130 (2.226 sec/step)\n",
            "I0608 11:47:18.909051 139948276815744 learning.py:507] global step 46200: loss = 0.8130 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 46210: loss = 2.3195 (2.361 sec/step)\n",
            "I0608 11:47:41.962628 139948276815744 learning.py:507] global step 46210: loss = 2.3195 (2.361 sec/step)\n",
            "INFO:tensorflow:global step 46220: loss = 1.1866 (2.255 sec/step)\n",
            "I0608 11:48:04.873215 139948276815744 learning.py:507] global step 46220: loss = 1.1866 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 46230: loss = 0.7123 (2.234 sec/step)\n",
            "I0608 11:48:27.322421 139948276815744 learning.py:507] global step 46230: loss = 0.7123 (2.234 sec/step)\n",
            "INFO:tensorflow:global step 46240: loss = 1.0242 (2.253 sec/step)\n",
            "I0608 11:48:50.880228 139948276815744 learning.py:507] global step 46240: loss = 1.0242 (2.253 sec/step)\n",
            "INFO:tensorflow:global step 46250: loss = 1.3795 (2.378 sec/step)\n",
            "I0608 11:49:13.793087 139948276815744 learning.py:507] global step 46250: loss = 1.3795 (2.378 sec/step)\n",
            "INFO:tensorflow:global step 46260: loss = 0.9468 (2.516 sec/step)\n",
            "I0608 11:49:36.901542 139948276815744 learning.py:507] global step 46260: loss = 0.9468 (2.516 sec/step)\n",
            "INFO:tensorflow:global step 46270: loss = 0.9072 (2.753 sec/step)\n",
            "I0608 11:50:01.619501 139948276815744 learning.py:507] global step 46270: loss = 0.9072 (2.753 sec/step)\n",
            "INFO:tensorflow:global step 46280: loss = 1.8794 (2.441 sec/step)\n",
            "I0608 11:50:27.835992 139948276815744 learning.py:507] global step 46280: loss = 1.8794 (2.441 sec/step)\n",
            "INFO:tensorflow:global step 46290: loss = 0.7007 (2.450 sec/step)\n",
            "I0608 11:50:51.651467 139948276815744 learning.py:507] global step 46290: loss = 0.7007 (2.450 sec/step)\n",
            "INFO:tensorflow:global step 46300: loss = 1.0134 (2.580 sec/step)\n",
            "I0608 11:51:14.998702 139948276815744 learning.py:507] global step 46300: loss = 1.0134 (2.580 sec/step)\n",
            "INFO:tensorflow:global step 46310: loss = 0.9091 (2.349 sec/step)\n",
            "I0608 11:51:38.652068 139948276815744 learning.py:507] global step 46310: loss = 0.9091 (2.349 sec/step)\n",
            "INFO:tensorflow:global step 46320: loss = 1.2494 (2.198 sec/step)\n",
            "I0608 11:52:01.019271 139948276815744 learning.py:507] global step 46320: loss = 1.2494 (2.198 sec/step)\n",
            "INFO:tensorflow:global step 46330: loss = 0.8527 (2.225 sec/step)\n",
            "I0608 11:52:23.377837 139948276815744 learning.py:507] global step 46330: loss = 0.8527 (2.225 sec/step)\n",
            "INFO:tensorflow:global step 46340: loss = 0.6028 (2.356 sec/step)\n",
            "I0608 11:52:46.955084 139948276815744 learning.py:507] global step 46340: loss = 0.6028 (2.356 sec/step)\n",
            "INFO:tensorflow:global step 46350: loss = 0.9049 (2.316 sec/step)\n",
            "I0608 11:53:11.540356 139948276815744 learning.py:507] global step 46350: loss = 0.9049 (2.316 sec/step)\n",
            "INFO:tensorflow:global step 46360: loss = 1.4860 (2.455 sec/step)\n",
            "I0608 11:53:34.819053 139948276815744 learning.py:507] global step 46360: loss = 1.4860 (2.455 sec/step)\n",
            "INFO:tensorflow:global step 46370: loss = 0.8527 (2.512 sec/step)\n",
            "I0608 11:54:00.626536 139948276815744 learning.py:507] global step 46370: loss = 0.8527 (2.512 sec/step)\n",
            "INFO:tensorflow:global step 46380: loss = 1.2123 (2.206 sec/step)\n",
            "I0608 11:54:22.795629 139948276815744 learning.py:507] global step 46380: loss = 1.2123 (2.206 sec/step)\n",
            "INFO:tensorflow:global step 46390: loss = 0.7567 (2.252 sec/step)\n",
            "I0608 11:54:44.928424 139948276815744 learning.py:507] global step 46390: loss = 0.7567 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 46400: loss = 1.0791 (2.178 sec/step)\n",
            "I0608 11:55:06.934846 139948276815744 learning.py:507] global step 46400: loss = 1.0791 (2.178 sec/step)\n",
            "INFO:tensorflow:global step 46410: loss = 1.1175 (2.186 sec/step)\n",
            "I0608 11:55:28.867516 139948276815744 learning.py:507] global step 46410: loss = 1.1175 (2.186 sec/step)\n",
            "INFO:tensorflow:global step 46420: loss = 1.6757 (2.219 sec/step)\n",
            "I0608 11:55:50.927897 139948276815744 learning.py:507] global step 46420: loss = 1.6757 (2.219 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 11:56:10.998091 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 46429.\n",
            "I0608 11:56:12.557281 139946056320768 supervisor.py:1050] Recording summary at step 46429.\n",
            "INFO:tensorflow:global_step/sec: 0.43001\n",
            "I0608 11:56:12.567480 139946064713472 supervisor.py:1099] global_step/sec: 0.43001\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0608 11:56:12.969437 139946073106176 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:global step 46430: loss = 0.9007 (3.525 sec/step)\n",
            "I0608 11:56:14.483521 139948276815744 learning.py:507] global step 46430: loss = 0.9007 (3.525 sec/step)\n",
            "INFO:tensorflow:global step 46440: loss = 0.8663 (2.241 sec/step)\n",
            "I0608 11:56:36.907764 139948276815744 learning.py:507] global step 46440: loss = 0.8663 (2.241 sec/step)\n",
            "INFO:tensorflow:global step 46450: loss = 0.7163 (2.173 sec/step)\n",
            "I0608 11:56:59.198473 139948276815744 learning.py:507] global step 46450: loss = 0.7163 (2.173 sec/step)\n",
            "INFO:tensorflow:global step 46460: loss = 1.0501 (2.254 sec/step)\n",
            "I0608 11:57:21.233324 139948276815744 learning.py:507] global step 46460: loss = 1.0501 (2.254 sec/step)\n",
            "INFO:tensorflow:global step 46470: loss = 0.8632 (2.252 sec/step)\n",
            "I0608 11:57:43.750363 139948276815744 learning.py:507] global step 46470: loss = 0.8632 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 46480: loss = 0.7491 (2.224 sec/step)\n",
            "I0608 11:58:05.942877 139948276815744 learning.py:507] global step 46480: loss = 0.7491 (2.224 sec/step)\n",
            "INFO:tensorflow:global step 46490: loss = 0.5839 (2.227 sec/step)\n",
            "I0608 11:58:28.370864 139948276815744 learning.py:507] global step 46490: loss = 0.5839 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 46500: loss = 0.5680 (2.317 sec/step)\n",
            "I0608 11:58:51.281141 139948276815744 learning.py:507] global step 46500: loss = 0.5680 (2.317 sec/step)\n",
            "INFO:tensorflow:global step 46510: loss = 0.9092 (2.579 sec/step)\n",
            "I0608 11:59:14.109607 139948276815744 learning.py:507] global step 46510: loss = 0.9092 (2.579 sec/step)\n",
            "INFO:tensorflow:global step 46520: loss = 1.3263 (2.472 sec/step)\n",
            "I0608 11:59:38.400864 139948276815744 learning.py:507] global step 46520: loss = 1.3263 (2.472 sec/step)\n",
            "INFO:tensorflow:global step 46530: loss = 1.1797 (2.244 sec/step)\n",
            "I0608 12:00:01.313104 139948276815744 learning.py:507] global step 46530: loss = 1.1797 (2.244 sec/step)\n",
            "INFO:tensorflow:global step 46540: loss = 0.8166 (2.257 sec/step)\n",
            "I0608 12:00:24.851288 139948276815744 learning.py:507] global step 46540: loss = 0.8166 (2.257 sec/step)\n",
            "INFO:tensorflow:global step 46550: loss = 1.1910 (2.428 sec/step)\n",
            "I0608 12:00:48.805191 139948276815744 learning.py:507] global step 46550: loss = 1.1910 (2.428 sec/step)\n",
            "INFO:tensorflow:global step 46560: loss = 0.9541 (2.395 sec/step)\n",
            "I0608 12:01:11.574575 139948276815744 learning.py:507] global step 46560: loss = 0.9541 (2.395 sec/step)\n",
            "INFO:tensorflow:global step 46570: loss = 0.8343 (2.353 sec/step)\n",
            "I0608 12:01:35.652416 139948276815744 learning.py:507] global step 46570: loss = 0.8343 (2.353 sec/step)\n",
            "INFO:tensorflow:global step 46580: loss = 1.2990 (2.524 sec/step)\n",
            "I0608 12:02:00.935898 139948276815744 learning.py:507] global step 46580: loss = 1.2990 (2.524 sec/step)\n",
            "INFO:tensorflow:global step 46590: loss = 1.2586 (2.393 sec/step)\n",
            "I0608 12:02:27.466322 139948276815744 learning.py:507] global step 46590: loss = 1.2586 (2.393 sec/step)\n",
            "INFO:tensorflow:global step 46600: loss = 0.7045 (2.250 sec/step)\n",
            "I0608 12:02:54.362125 139948276815744 learning.py:507] global step 46600: loss = 0.7045 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 46610: loss = 1.0789 (2.413 sec/step)\n",
            "I0608 12:03:19.147464 139948276815744 learning.py:507] global step 46610: loss = 1.0789 (2.413 sec/step)\n",
            "INFO:tensorflow:global step 46620: loss = 1.4347 (2.341 sec/step)\n",
            "I0608 12:03:42.774802 139948276815744 learning.py:507] global step 46620: loss = 1.4347 (2.341 sec/step)\n",
            "INFO:tensorflow:global step 46630: loss = 0.6480 (2.210 sec/step)\n",
            "I0608 12:04:04.928952 139948276815744 learning.py:507] global step 46630: loss = 0.6480 (2.210 sec/step)\n",
            "INFO:tensorflow:global step 46640: loss = 0.5580 (2.710 sec/step)\n",
            "I0608 12:04:28.396393 139948276815744 learning.py:507] global step 46640: loss = 0.5580 (2.710 sec/step)\n",
            "INFO:tensorflow:global step 46650: loss = 0.6251 (2.749 sec/step)\n",
            "I0608 12:04:57.332756 139948276815744 learning.py:507] global step 46650: loss = 0.6251 (2.749 sec/step)\n",
            "INFO:tensorflow:global step 46660: loss = 1.0249 (2.720 sec/step)\n",
            "I0608 12:05:22.444771 139948276815744 learning.py:507] global step 46660: loss = 1.0249 (2.720 sec/step)\n",
            "INFO:tensorflow:global step 46670: loss = 0.5225 (2.454 sec/step)\n",
            "I0608 12:05:48.490569 139948276815744 learning.py:507] global step 46670: loss = 0.5225 (2.454 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 46679.\n",
            "I0608 12:06:12.592396 139946056320768 supervisor.py:1050] Recording summary at step 46679.\n",
            "INFO:tensorflow:global_step/sec: 0.416649\n",
            "I0608 12:06:12.593277 139946064713472 supervisor.py:1099] global_step/sec: 0.416649\n",
            "INFO:tensorflow:global step 46680: loss = 1.3027 (2.849 sec/step)\n",
            "I0608 12:06:14.173994 139948276815744 learning.py:507] global step 46680: loss = 1.3027 (2.849 sec/step)\n",
            "INFO:tensorflow:global step 46690: loss = 0.8763 (2.221 sec/step)\n",
            "I0608 12:06:36.460334 139948276815744 learning.py:507] global step 46690: loss = 0.8763 (2.221 sec/step)\n",
            "INFO:tensorflow:global step 46700: loss = 1.3604 (2.197 sec/step)\n",
            "I0608 12:06:58.773167 139948276815744 learning.py:507] global step 46700: loss = 1.3604 (2.197 sec/step)\n",
            "INFO:tensorflow:global step 46710: loss = 0.7321 (2.196 sec/step)\n",
            "I0608 12:07:20.663178 139948276815744 learning.py:507] global step 46710: loss = 0.7321 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 46720: loss = 0.6830 (2.253 sec/step)\n",
            "I0608 12:07:42.642645 139948276815744 learning.py:507] global step 46720: loss = 0.6830 (2.253 sec/step)\n",
            "INFO:tensorflow:global step 46730: loss = 0.6088 (2.209 sec/step)\n",
            "I0608 12:08:05.275825 139948276815744 learning.py:507] global step 46730: loss = 0.6088 (2.209 sec/step)\n",
            "INFO:tensorflow:global step 46740: loss = 1.2154 (2.234 sec/step)\n",
            "I0608 12:08:27.745991 139948276815744 learning.py:507] global step 46740: loss = 1.2154 (2.234 sec/step)\n",
            "INFO:tensorflow:global step 46750: loss = 0.9902 (2.335 sec/step)\n",
            "I0608 12:08:50.341741 139948276815744 learning.py:507] global step 46750: loss = 0.9902 (2.335 sec/step)\n",
            "INFO:tensorflow:global step 46760: loss = 0.6254 (2.226 sec/step)\n",
            "I0608 12:09:12.906904 139948276815744 learning.py:507] global step 46760: loss = 0.6254 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 46770: loss = 1.2741 (2.190 sec/step)\n",
            "I0608 12:09:35.284402 139948276815744 learning.py:507] global step 46770: loss = 1.2741 (2.190 sec/step)\n",
            "INFO:tensorflow:global step 46780: loss = 0.7681 (2.171 sec/step)\n",
            "I0608 12:09:57.431745 139948276815744 learning.py:507] global step 46780: loss = 0.7681 (2.171 sec/step)\n",
            "INFO:tensorflow:global step 46790: loss = 1.0265 (2.220 sec/step)\n",
            "I0608 12:10:19.809244 139948276815744 learning.py:507] global step 46790: loss = 1.0265 (2.220 sec/step)\n",
            "INFO:tensorflow:global step 46800: loss = 0.7349 (2.253 sec/step)\n",
            "I0608 12:10:41.917370 139948276815744 learning.py:507] global step 46800: loss = 0.7349 (2.253 sec/step)\n",
            "INFO:tensorflow:global step 46810: loss = 1.4128 (2.243 sec/step)\n",
            "I0608 12:11:04.464631 139948276815744 learning.py:507] global step 46810: loss = 1.4128 (2.243 sec/step)\n",
            "INFO:tensorflow:global step 46820: loss = 0.8799 (2.210 sec/step)\n",
            "I0608 12:11:26.584455 139948276815744 learning.py:507] global step 46820: loss = 0.8799 (2.210 sec/step)\n",
            "INFO:tensorflow:global step 46830: loss = 2.5199 (2.217 sec/step)\n",
            "I0608 12:11:49.053709 139948276815744 learning.py:507] global step 46830: loss = 2.5199 (2.217 sec/step)\n",
            "INFO:tensorflow:global step 46840: loss = 0.7473 (2.255 sec/step)\n",
            "I0608 12:12:11.475601 139948276815744 learning.py:507] global step 46840: loss = 0.7473 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 46850: loss = 1.2170 (2.408 sec/step)\n",
            "I0608 12:12:35.100678 139948276815744 learning.py:507] global step 46850: loss = 1.2170 (2.408 sec/step)\n",
            "INFO:tensorflow:global step 46860: loss = 0.9220 (2.340 sec/step)\n",
            "I0608 12:12:58.681052 139948276815744 learning.py:507] global step 46860: loss = 0.9220 (2.340 sec/step)\n",
            "INFO:tensorflow:global step 46870: loss = 1.0248 (2.240 sec/step)\n",
            "I0608 12:13:20.969157 139948276815744 learning.py:507] global step 46870: loss = 1.0248 (2.240 sec/step)\n",
            "INFO:tensorflow:global step 46880: loss = 0.8643 (2.271 sec/step)\n",
            "I0608 12:13:43.173040 139948276815744 learning.py:507] global step 46880: loss = 0.8643 (2.271 sec/step)\n",
            "INFO:tensorflow:global step 46890: loss = 0.8402 (2.203 sec/step)\n",
            "I0608 12:14:05.696533 139948276815744 learning.py:507] global step 46890: loss = 0.8402 (2.203 sec/step)\n",
            "INFO:tensorflow:global step 46900: loss = 0.9247 (2.282 sec/step)\n",
            "I0608 12:14:28.200915 139948276815744 learning.py:507] global step 46900: loss = 0.9247 (2.282 sec/step)\n",
            "INFO:tensorflow:global step 46910: loss = 1.0692 (2.216 sec/step)\n",
            "I0608 12:14:50.265300 139948276815744 learning.py:507] global step 46910: loss = 1.0692 (2.216 sec/step)\n",
            "INFO:tensorflow:global step 46920: loss = 0.7564 (2.299 sec/step)\n",
            "I0608 12:15:13.049575 139948276815744 learning.py:507] global step 46920: loss = 0.7564 (2.299 sec/step)\n",
            "INFO:tensorflow:global step 46930: loss = 0.9924 (2.314 sec/step)\n",
            "I0608 12:15:36.853448 139948276815744 learning.py:507] global step 46930: loss = 0.9924 (2.314 sec/step)\n",
            "INFO:tensorflow:global step 46940: loss = 1.3769 (2.296 sec/step)\n",
            "I0608 12:16:00.097260 139948276815744 learning.py:507] global step 46940: loss = 1.3769 (2.296 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 12:16:10.997860 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 46944.\n",
            "I0608 12:16:12.640735 139946056320768 supervisor.py:1050] Recording summary at step 46944.\n",
            "INFO:tensorflow:global_step/sec: 0.441616\n",
            "I0608 12:16:12.662148 139946064713472 supervisor.py:1099] global_step/sec: 0.441616\n",
            "INFO:tensorflow:global step 46950: loss = 0.4547 (2.358 sec/step)\n",
            "I0608 12:16:25.907183 139948276815744 learning.py:507] global step 46950: loss = 0.4547 (2.358 sec/step)\n",
            "INFO:tensorflow:global step 46960: loss = 1.0313 (2.475 sec/step)\n",
            "I0608 12:16:50.884306 139948276815744 learning.py:507] global step 46960: loss = 1.0313 (2.475 sec/step)\n",
            "INFO:tensorflow:global step 46970: loss = 1.1631 (2.408 sec/step)\n",
            "I0608 12:17:15.316010 139948276815744 learning.py:507] global step 46970: loss = 1.1631 (2.408 sec/step)\n",
            "INFO:tensorflow:global step 46980: loss = 0.9802 (2.808 sec/step)\n",
            "I0608 12:17:39.056603 139948276815744 learning.py:507] global step 46980: loss = 0.9802 (2.808 sec/step)\n",
            "INFO:tensorflow:global step 46990: loss = 1.2550 (2.860 sec/step)\n",
            "I0608 12:18:04.389926 139948276815744 learning.py:507] global step 46990: loss = 1.2550 (2.860 sec/step)\n",
            "INFO:tensorflow:global step 47000: loss = 1.6320 (2.404 sec/step)\n",
            "I0608 12:18:31.191631 139948276815744 learning.py:507] global step 47000: loss = 1.6320 (2.404 sec/step)\n",
            "INFO:tensorflow:global step 47010: loss = 0.6246 (2.472 sec/step)\n",
            "I0608 12:18:56.351069 139948276815744 learning.py:507] global step 47010: loss = 0.6246 (2.472 sec/step)\n",
            "INFO:tensorflow:global step 47020: loss = 1.1088 (3.025 sec/step)\n",
            "I0608 12:19:23.179971 139948276815744 learning.py:507] global step 47020: loss = 1.1088 (3.025 sec/step)\n",
            "INFO:tensorflow:global step 47030: loss = 0.5936 (2.559 sec/step)\n",
            "I0608 12:19:49.971826 139948276815744 learning.py:507] global step 47030: loss = 0.5936 (2.559 sec/step)\n",
            "INFO:tensorflow:global step 47040: loss = 0.8674 (2.405 sec/step)\n",
            "I0608 12:20:15.537629 139948276815744 learning.py:507] global step 47040: loss = 0.8674 (2.405 sec/step)\n",
            "INFO:tensorflow:global step 47050: loss = 0.7351 (2.555 sec/step)\n",
            "I0608 12:20:40.482528 139948276815744 learning.py:507] global step 47050: loss = 0.7351 (2.555 sec/step)\n",
            "INFO:tensorflow:global step 47060: loss = 0.8886 (2.392 sec/step)\n",
            "I0608 12:21:05.220546 139948276815744 learning.py:507] global step 47060: loss = 0.8886 (2.392 sec/step)\n",
            "INFO:tensorflow:global step 47070: loss = 0.7587 (2.342 sec/step)\n",
            "I0608 12:21:29.204976 139948276815744 learning.py:507] global step 47070: loss = 0.7587 (2.342 sec/step)\n",
            "INFO:tensorflow:global step 47080: loss = 0.8193 (2.227 sec/step)\n",
            "I0608 12:21:53.549043 139948276815744 learning.py:507] global step 47080: loss = 0.8193 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 47090: loss = 0.8506 (2.197 sec/step)\n",
            "I0608 12:22:16.400125 139948276815744 learning.py:507] global step 47090: loss = 0.8506 (2.197 sec/step)\n",
            "INFO:tensorflow:global step 47100: loss = 0.5288 (2.259 sec/step)\n",
            "I0608 12:22:38.959319 139948276815744 learning.py:507] global step 47100: loss = 0.5288 (2.259 sec/step)\n",
            "INFO:tensorflow:global step 47110: loss = 0.4637 (2.188 sec/step)\n",
            "I0608 12:23:01.055827 139948276815744 learning.py:507] global step 47110: loss = 0.4637 (2.188 sec/step)\n",
            "INFO:tensorflow:global step 47120: loss = 1.0716 (2.202 sec/step)\n",
            "I0608 12:23:23.387374 139948276815744 learning.py:507] global step 47120: loss = 1.0716 (2.202 sec/step)\n",
            "INFO:tensorflow:global step 47130: loss = 0.3738 (2.167 sec/step)\n",
            "I0608 12:23:45.786178 139948276815744 learning.py:507] global step 47130: loss = 0.3738 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 47140: loss = 1.0044 (2.226 sec/step)\n",
            "I0608 12:24:08.077352 139948276815744 learning.py:507] global step 47140: loss = 1.0044 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 47150: loss = 0.9669 (2.190 sec/step)\n",
            "I0608 12:24:30.032309 139948276815744 learning.py:507] global step 47150: loss = 0.9669 (2.190 sec/step)\n",
            "INFO:tensorflow:global step 47160: loss = 0.5412 (2.274 sec/step)\n",
            "I0608 12:24:52.400070 139948276815744 learning.py:507] global step 47160: loss = 0.5412 (2.274 sec/step)\n",
            "INFO:tensorflow:global step 47170: loss = 1.1966 (2.239 sec/step)\n",
            "I0608 12:25:14.687104 139948276815744 learning.py:507] global step 47170: loss = 1.1966 (2.239 sec/step)\n",
            "INFO:tensorflow:global step 47180: loss = 0.5191 (2.195 sec/step)\n",
            "I0608 12:25:36.833242 139948276815744 learning.py:507] global step 47180: loss = 0.5191 (2.195 sec/step)\n",
            "INFO:tensorflow:global step 47190: loss = 0.9325 (2.302 sec/step)\n",
            "I0608 12:25:59.312262 139948276815744 learning.py:507] global step 47190: loss = 0.9325 (2.302 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 47195.\n",
            "I0608 12:26:12.606668 139946056320768 supervisor.py:1050] Recording summary at step 47195.\n",
            "INFO:tensorflow:global_step/sec: 0.418372\n",
            "I0608 12:26:12.607350 139946064713472 supervisor.py:1099] global_step/sec: 0.418372\n",
            "INFO:tensorflow:global step 47200: loss = 0.8108 (2.227 sec/step)\n",
            "I0608 12:26:22.581089 139948276815744 learning.py:507] global step 47200: loss = 0.8108 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 47210: loss = 1.0720 (2.167 sec/step)\n",
            "I0608 12:26:44.859362 139948276815744 learning.py:507] global step 47210: loss = 1.0720 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 47220: loss = 0.7669 (3.178 sec/step)\n",
            "I0608 12:27:09.138450 139948276815744 learning.py:507] global step 47220: loss = 0.7669 (3.178 sec/step)\n",
            "INFO:tensorflow:global step 47230: loss = 0.6201 (2.614 sec/step)\n",
            "I0608 12:27:36.850318 139948276815744 learning.py:507] global step 47230: loss = 0.6201 (2.614 sec/step)\n",
            "INFO:tensorflow:global step 47240: loss = 0.5863 (2.227 sec/step)\n",
            "I0608 12:28:00.834758 139948276815744 learning.py:507] global step 47240: loss = 0.5863 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 47250: loss = 1.3686 (2.268 sec/step)\n",
            "I0608 12:28:23.256535 139948276815744 learning.py:507] global step 47250: loss = 1.3686 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 47260: loss = 0.9221 (2.258 sec/step)\n",
            "I0608 12:28:45.755143 139948276815744 learning.py:507] global step 47260: loss = 0.9221 (2.258 sec/step)\n",
            "INFO:tensorflow:global step 47270: loss = 0.5903 (2.225 sec/step)\n",
            "I0608 12:29:08.089660 139948276815744 learning.py:507] global step 47270: loss = 0.5903 (2.225 sec/step)\n",
            "INFO:tensorflow:global step 47280: loss = 1.2783 (2.224 sec/step)\n",
            "I0608 12:29:30.291502 139948276815744 learning.py:507] global step 47280: loss = 1.2783 (2.224 sec/step)\n",
            "INFO:tensorflow:global step 47290: loss = 0.5203 (2.222 sec/step)\n",
            "I0608 12:29:52.403442 139948276815744 learning.py:507] global step 47290: loss = 0.5203 (2.222 sec/step)\n",
            "INFO:tensorflow:global step 47300: loss = 0.6930 (2.213 sec/step)\n",
            "I0608 12:30:14.684003 139948276815744 learning.py:507] global step 47300: loss = 0.6930 (2.213 sec/step)\n",
            "INFO:tensorflow:global step 47310: loss = 0.7877 (2.204 sec/step)\n",
            "I0608 12:30:36.832590 139948276815744 learning.py:507] global step 47310: loss = 0.7877 (2.204 sec/step)\n",
            "INFO:tensorflow:global step 47320: loss = 1.3414 (2.220 sec/step)\n",
            "I0608 12:30:59.009571 139948276815744 learning.py:507] global step 47320: loss = 1.3414 (2.220 sec/step)\n",
            "INFO:tensorflow:global step 47330: loss = 1.1011 (2.202 sec/step)\n",
            "I0608 12:31:21.078249 139948276815744 learning.py:507] global step 47330: loss = 1.1011 (2.202 sec/step)\n",
            "INFO:tensorflow:global step 47340: loss = 1.6789 (2.232 sec/step)\n",
            "I0608 12:31:43.370049 139948276815744 learning.py:507] global step 47340: loss = 1.6789 (2.232 sec/step)\n",
            "INFO:tensorflow:global step 47350: loss = 1.5930 (2.250 sec/step)\n",
            "I0608 12:32:05.965401 139948276815744 learning.py:507] global step 47350: loss = 1.5930 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 47360: loss = 0.8751 (2.312 sec/step)\n",
            "I0608 12:32:28.681310 139948276815744 learning.py:507] global step 47360: loss = 0.8751 (2.312 sec/step)\n",
            "INFO:tensorflow:global step 47370: loss = 1.2466 (2.205 sec/step)\n",
            "I0608 12:32:50.792036 139948276815744 learning.py:507] global step 47370: loss = 1.2466 (2.205 sec/step)\n",
            "INFO:tensorflow:global step 47380: loss = 0.8120 (2.220 sec/step)\n",
            "I0608 12:33:12.777765 139948276815744 learning.py:507] global step 47380: loss = 0.8120 (2.220 sec/step)\n",
            "INFO:tensorflow:global step 47390: loss = 1.1575 (2.208 sec/step)\n",
            "I0608 12:33:34.922559 139948276815744 learning.py:507] global step 47390: loss = 1.1575 (2.208 sec/step)\n",
            "INFO:tensorflow:global step 47400: loss = 0.8680 (2.183 sec/step)\n",
            "I0608 12:33:56.929182 139948276815744 learning.py:507] global step 47400: loss = 0.8680 (2.183 sec/step)\n",
            "INFO:tensorflow:global step 47410: loss = 0.8111 (2.250 sec/step)\n",
            "I0608 12:34:19.363228 139948276815744 learning.py:507] global step 47410: loss = 0.8111 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 47420: loss = 0.5037 (2.284 sec/step)\n",
            "I0608 12:34:41.716404 139948276815744 learning.py:507] global step 47420: loss = 0.5037 (2.284 sec/step)\n",
            "INFO:tensorflow:global step 47430: loss = 1.3132 (2.256 sec/step)\n",
            "I0608 12:35:04.153195 139948276815744 learning.py:507] global step 47430: loss = 1.3132 (2.256 sec/step)\n",
            "INFO:tensorflow:global step 47440: loss = 0.8312 (2.238 sec/step)\n",
            "I0608 12:35:26.541594 139948276815744 learning.py:507] global step 47440: loss = 0.8312 (2.238 sec/step)\n",
            "INFO:tensorflow:global step 47450: loss = 0.7708 (2.290 sec/step)\n",
            "I0608 12:35:49.034373 139948276815744 learning.py:507] global step 47450: loss = 0.7708 (2.290 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 12:36:11.000091 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:global step 47460: loss = 0.6373 (2.898 sec/step)\n",
            "I0608 12:36:12.321872 139948276815744 learning.py:507] global step 47460: loss = 0.6373 (2.898 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 47460.\n",
            "I0608 12:36:12.432813 139946056320768 supervisor.py:1050] Recording summary at step 47460.\n",
            "INFO:tensorflow:global_step/sec: 0.441794\n",
            "I0608 12:36:12.434185 139946064713472 supervisor.py:1099] global_step/sec: 0.441794\n",
            "INFO:tensorflow:global step 47470: loss = 0.5564 (2.353 sec/step)\n",
            "I0608 12:36:36.717816 139948276815744 learning.py:507] global step 47470: loss = 0.5564 (2.353 sec/step)\n",
            "INFO:tensorflow:global step 47480: loss = 1.0004 (2.227 sec/step)\n",
            "I0608 12:36:59.647566 139948276815744 learning.py:507] global step 47480: loss = 1.0004 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 47490: loss = 1.6551 (2.219 sec/step)\n",
            "I0608 12:37:22.019321 139948276815744 learning.py:507] global step 47490: loss = 1.6551 (2.219 sec/step)\n",
            "INFO:tensorflow:global step 47500: loss = 0.6555 (2.217 sec/step)\n",
            "I0608 12:37:44.065366 139948276815744 learning.py:507] global step 47500: loss = 0.6555 (2.217 sec/step)\n",
            "INFO:tensorflow:global step 47510: loss = 0.8158 (2.245 sec/step)\n",
            "I0608 12:38:06.275123 139948276815744 learning.py:507] global step 47510: loss = 0.8158 (2.245 sec/step)\n",
            "INFO:tensorflow:global step 47520: loss = 0.6416 (2.230 sec/step)\n",
            "I0608 12:38:29.311617 139948276815744 learning.py:507] global step 47520: loss = 0.6416 (2.230 sec/step)\n",
            "INFO:tensorflow:global step 47530: loss = 0.7728 (2.284 sec/step)\n",
            "I0608 12:38:51.918591 139948276815744 learning.py:507] global step 47530: loss = 0.7728 (2.284 sec/step)\n",
            "INFO:tensorflow:global step 47540: loss = 0.6490 (2.183 sec/step)\n",
            "I0608 12:39:14.756999 139948276815744 learning.py:507] global step 47540: loss = 0.6490 (2.183 sec/step)\n",
            "INFO:tensorflow:global step 47550: loss = 0.6280 (2.337 sec/step)\n",
            "I0608 12:39:37.333391 139948276815744 learning.py:507] global step 47550: loss = 0.6280 (2.337 sec/step)\n",
            "INFO:tensorflow:global step 47560: loss = 0.8983 (2.196 sec/step)\n",
            "I0608 12:39:59.574073 139948276815744 learning.py:507] global step 47560: loss = 0.8983 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 47570: loss = 0.8109 (2.302 sec/step)\n",
            "I0608 12:40:21.895112 139948276815744 learning.py:507] global step 47570: loss = 0.8109 (2.302 sec/step)\n",
            "INFO:tensorflow:global step 47580: loss = 0.9769 (2.239 sec/step)\n",
            "I0608 12:40:44.355520 139948276815744 learning.py:507] global step 47580: loss = 0.9769 (2.239 sec/step)\n",
            "INFO:tensorflow:global step 47590: loss = 0.5570 (2.206 sec/step)\n",
            "I0608 12:41:06.850205 139948276815744 learning.py:507] global step 47590: loss = 0.5570 (2.206 sec/step)\n",
            "INFO:tensorflow:global step 47600: loss = 1.0303 (2.281 sec/step)\n",
            "I0608 12:41:29.420000 139948276815744 learning.py:507] global step 47600: loss = 1.0303 (2.281 sec/step)\n",
            "INFO:tensorflow:global step 47610: loss = 0.5908 (2.188 sec/step)\n",
            "I0608 12:41:52.078853 139948276815744 learning.py:507] global step 47610: loss = 0.5908 (2.188 sec/step)\n",
            "INFO:tensorflow:global step 47620: loss = 1.2217 (2.204 sec/step)\n",
            "I0608 12:42:14.519996 139948276815744 learning.py:507] global step 47620: loss = 1.2217 (2.204 sec/step)\n",
            "INFO:tensorflow:global step 47630: loss = 0.6094 (2.228 sec/step)\n",
            "I0608 12:42:36.960324 139948276815744 learning.py:507] global step 47630: loss = 0.6094 (2.228 sec/step)\n",
            "INFO:tensorflow:global step 47640: loss = 0.9966 (2.206 sec/step)\n",
            "I0608 12:42:59.211860 139948276815744 learning.py:507] global step 47640: loss = 0.9966 (2.206 sec/step)\n",
            "INFO:tensorflow:global step 47650: loss = 0.8414 (2.268 sec/step)\n",
            "I0608 12:43:21.643862 139948276815744 learning.py:507] global step 47650: loss = 0.8414 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 47660: loss = 0.8771 (2.202 sec/step)\n",
            "I0608 12:43:44.013092 139948276815744 learning.py:507] global step 47660: loss = 0.8771 (2.202 sec/step)\n",
            "INFO:tensorflow:global step 47670: loss = 1.0308 (2.310 sec/step)\n",
            "I0608 12:44:06.904036 139948276815744 learning.py:507] global step 47670: loss = 1.0308 (2.310 sec/step)\n",
            "INFO:tensorflow:global step 47680: loss = 0.6730 (2.252 sec/step)\n",
            "I0608 12:44:29.136267 139948276815744 learning.py:507] global step 47680: loss = 0.6730 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 47690: loss = 0.5746 (2.304 sec/step)\n",
            "I0608 12:44:51.747416 139948276815744 learning.py:507] global step 47690: loss = 0.5746 (2.304 sec/step)\n",
            "INFO:tensorflow:global step 47700: loss = 0.8021 (2.200 sec/step)\n",
            "I0608 12:45:14.589126 139948276815744 learning.py:507] global step 47700: loss = 0.8021 (2.200 sec/step)\n",
            "INFO:tensorflow:global step 47710: loss = 1.0990 (2.246 sec/step)\n",
            "I0608 12:45:36.970527 139948276815744 learning.py:507] global step 47710: loss = 1.0990 (2.246 sec/step)\n",
            "INFO:tensorflow:global step 47720: loss = 0.8872 (2.210 sec/step)\n",
            "I0608 12:45:59.618725 139948276815744 learning.py:507] global step 47720: loss = 0.8872 (2.210 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 47725.\n",
            "I0608 12:46:12.448626 139946056320768 supervisor.py:1050] Recording summary at step 47725.\n",
            "INFO:tensorflow:global_step/sec: 0.441647\n",
            "I0608 12:46:12.461381 139946064713472 supervisor.py:1099] global_step/sec: 0.441647\n",
            "INFO:tensorflow:global step 47730: loss = 0.6142 (2.318 sec/step)\n",
            "I0608 12:46:23.538464 139948276815744 learning.py:507] global step 47730: loss = 0.6142 (2.318 sec/step)\n",
            "INFO:tensorflow:global step 47740: loss = 1.9711 (2.379 sec/step)\n",
            "I0608 12:46:46.286287 139948276815744 learning.py:507] global step 47740: loss = 1.9711 (2.379 sec/step)\n",
            "INFO:tensorflow:global step 47750: loss = 0.9278 (2.303 sec/step)\n",
            "I0608 12:47:09.375106 139948276815744 learning.py:507] global step 47750: loss = 0.9278 (2.303 sec/step)\n",
            "INFO:tensorflow:global step 47760: loss = 0.9129 (2.266 sec/step)\n",
            "I0608 12:47:32.096730 139948276815744 learning.py:507] global step 47760: loss = 0.9129 (2.266 sec/step)\n",
            "INFO:tensorflow:global step 47770: loss = 1.0098 (2.236 sec/step)\n",
            "I0608 12:47:54.342525 139948276815744 learning.py:507] global step 47770: loss = 1.0098 (2.236 sec/step)\n",
            "INFO:tensorflow:global step 47780: loss = 0.5267 (2.309 sec/step)\n",
            "I0608 12:48:16.464001 139948276815744 learning.py:507] global step 47780: loss = 0.5267 (2.309 sec/step)\n",
            "INFO:tensorflow:global step 47790: loss = 1.3764 (2.234 sec/step)\n",
            "I0608 12:48:38.725562 139948276815744 learning.py:507] global step 47790: loss = 1.3764 (2.234 sec/step)\n",
            "INFO:tensorflow:global step 47800: loss = 1.4088 (2.246 sec/step)\n",
            "I0608 12:49:01.105322 139948276815744 learning.py:507] global step 47800: loss = 1.4088 (2.246 sec/step)\n",
            "INFO:tensorflow:global step 47810: loss = 0.6757 (2.260 sec/step)\n",
            "I0608 12:49:24.288608 139948276815744 learning.py:507] global step 47810: loss = 0.6757 (2.260 sec/step)\n",
            "INFO:tensorflow:global step 47820: loss = 0.6767 (2.198 sec/step)\n",
            "I0608 12:49:46.851754 139948276815744 learning.py:507] global step 47820: loss = 0.6767 (2.198 sec/step)\n",
            "INFO:tensorflow:global step 47830: loss = 1.2983 (2.326 sec/step)\n",
            "I0608 12:50:09.664524 139948276815744 learning.py:507] global step 47830: loss = 1.2983 (2.326 sec/step)\n",
            "INFO:tensorflow:global step 47840: loss = 0.8789 (2.292 sec/step)\n",
            "I0608 12:50:32.529219 139948276815744 learning.py:507] global step 47840: loss = 0.8789 (2.292 sec/step)\n",
            "INFO:tensorflow:global step 47850: loss = 0.7937 (2.296 sec/step)\n",
            "I0608 12:50:55.015930 139948276815744 learning.py:507] global step 47850: loss = 0.7937 (2.296 sec/step)\n",
            "INFO:tensorflow:global step 47860: loss = 1.0179 (2.181 sec/step)\n",
            "I0608 12:51:17.678394 139948276815744 learning.py:507] global step 47860: loss = 1.0179 (2.181 sec/step)\n",
            "INFO:tensorflow:global step 47870: loss = 0.7798 (2.255 sec/step)\n",
            "I0608 12:51:40.032090 139948276815744 learning.py:507] global step 47870: loss = 0.7798 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 47880: loss = 1.0896 (2.232 sec/step)\n",
            "I0608 12:52:02.539251 139948276815744 learning.py:507] global step 47880: loss = 1.0896 (2.232 sec/step)\n",
            "INFO:tensorflow:global step 47890: loss = 1.0876 (2.255 sec/step)\n",
            "I0608 12:52:25.242621 139948276815744 learning.py:507] global step 47890: loss = 1.0876 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 47900: loss = 1.0070 (2.196 sec/step)\n",
            "I0608 12:52:47.667026 139948276815744 learning.py:507] global step 47900: loss = 1.0070 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 47910: loss = 0.5453 (2.259 sec/step)\n",
            "I0608 12:53:10.179504 139948276815744 learning.py:507] global step 47910: loss = 0.5453 (2.259 sec/step)\n",
            "INFO:tensorflow:global step 47920: loss = 0.6868 (2.246 sec/step)\n",
            "I0608 12:53:32.906844 139948276815744 learning.py:507] global step 47920: loss = 0.6868 (2.246 sec/step)\n",
            "INFO:tensorflow:global step 47930: loss = 0.8661 (2.220 sec/step)\n",
            "I0608 12:53:55.438952 139948276815744 learning.py:507] global step 47930: loss = 0.8661 (2.220 sec/step)\n",
            "INFO:tensorflow:global step 47940: loss = 0.5764 (2.357 sec/step)\n",
            "I0608 12:54:18.703765 139948276815744 learning.py:507] global step 47940: loss = 0.5764 (2.357 sec/step)\n",
            "INFO:tensorflow:global step 47950: loss = 1.8526 (2.336 sec/step)\n",
            "I0608 12:54:42.207095 139948276815744 learning.py:507] global step 47950: loss = 1.8526 (2.336 sec/step)\n",
            "INFO:tensorflow:global step 47960: loss = 0.5292 (2.286 sec/step)\n",
            "I0608 12:55:05.007021 139948276815744 learning.py:507] global step 47960: loss = 0.5292 (2.286 sec/step)\n",
            "INFO:tensorflow:global step 47970: loss = 1.5807 (2.298 sec/step)\n",
            "I0608 12:55:28.020040 139948276815744 learning.py:507] global step 47970: loss = 1.5807 (2.298 sec/step)\n",
            "INFO:tensorflow:global step 47980: loss = 1.6525 (2.204 sec/step)\n",
            "I0608 12:55:50.813317 139948276815744 learning.py:507] global step 47980: loss = 1.6525 (2.204 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 12:56:10.997223 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 47989.\n",
            "I0608 12:56:12.851745 139946056320768 supervisor.py:1050] Recording summary at step 47989.\n",
            "INFO:tensorflow:global_step/sec: 0.43969\n",
            "I0608 12:56:12.884705 139946064713472 supervisor.py:1099] global_step/sec: 0.43969\n",
            "INFO:tensorflow:global step 47990: loss = 0.8365 (2.829 sec/step)\n",
            "I0608 12:56:14.819802 139948276815744 learning.py:507] global step 47990: loss = 0.8365 (2.829 sec/step)\n",
            "INFO:tensorflow:global step 48000: loss = 1.0710 (2.332 sec/step)\n",
            "I0608 12:56:37.670381 139948276815744 learning.py:507] global step 48000: loss = 1.0710 (2.332 sec/step)\n",
            "INFO:tensorflow:global step 48010: loss = 0.7438 (2.347 sec/step)\n",
            "I0608 12:57:00.696461 139948276815744 learning.py:507] global step 48010: loss = 0.7438 (2.347 sec/step)\n",
            "INFO:tensorflow:global step 48020: loss = 2.2553 (2.383 sec/step)\n",
            "I0608 12:57:24.412322 139948276815744 learning.py:507] global step 48020: loss = 2.2553 (2.383 sec/step)\n",
            "INFO:tensorflow:global step 48030: loss = 1.3010 (2.366 sec/step)\n",
            "I0608 12:57:48.089539 139948276815744 learning.py:507] global step 48030: loss = 1.3010 (2.366 sec/step)\n",
            "INFO:tensorflow:global step 48040: loss = 0.8030 (2.163 sec/step)\n",
            "I0608 12:58:10.375742 139948276815744 learning.py:507] global step 48040: loss = 0.8030 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 48050: loss = 0.7223 (2.260 sec/step)\n",
            "I0608 12:58:32.800324 139948276815744 learning.py:507] global step 48050: loss = 0.7223 (2.260 sec/step)\n",
            "INFO:tensorflow:global step 48060: loss = 1.2684 (2.313 sec/step)\n",
            "I0608 12:58:55.501375 139948276815744 learning.py:507] global step 48060: loss = 1.2684 (2.313 sec/step)\n",
            "INFO:tensorflow:global step 48070: loss = 1.5237 (2.277 sec/step)\n",
            "I0608 12:59:18.030850 139948276815744 learning.py:507] global step 48070: loss = 1.5237 (2.277 sec/step)\n",
            "INFO:tensorflow:global step 48080: loss = 0.7168 (2.366 sec/step)\n",
            "I0608 12:59:41.011084 139948276815744 learning.py:507] global step 48080: loss = 0.7168 (2.366 sec/step)\n",
            "INFO:tensorflow:global step 48090: loss = 1.9085 (2.437 sec/step)\n",
            "I0608 13:00:04.803457 139948276815744 learning.py:507] global step 48090: loss = 1.9085 (2.437 sec/step)\n",
            "INFO:tensorflow:global step 48100: loss = 0.6710 (2.231 sec/step)\n",
            "I0608 13:00:27.953342 139948276815744 learning.py:507] global step 48100: loss = 0.6710 (2.231 sec/step)\n",
            "INFO:tensorflow:global step 48110: loss = 1.2131 (2.207 sec/step)\n",
            "I0608 13:00:51.508061 139948276815744 learning.py:507] global step 48110: loss = 1.2131 (2.207 sec/step)\n",
            "INFO:tensorflow:global step 48120: loss = 1.8079 (2.402 sec/step)\n",
            "I0608 13:01:15.635679 139948276815744 learning.py:507] global step 48120: loss = 1.8079 (2.402 sec/step)\n",
            "INFO:tensorflow:global step 48130: loss = 1.7000 (2.402 sec/step)\n",
            "I0608 13:01:38.986405 139948276815744 learning.py:507] global step 48130: loss = 1.7000 (2.402 sec/step)\n",
            "INFO:tensorflow:global step 48140: loss = 2.0313 (2.351 sec/step)\n",
            "I0608 13:02:02.557940 139948276815744 learning.py:507] global step 48140: loss = 2.0313 (2.351 sec/step)\n",
            "INFO:tensorflow:global step 48150: loss = 1.0028 (2.414 sec/step)\n",
            "I0608 13:02:26.319786 139948276815744 learning.py:507] global step 48150: loss = 1.0028 (2.414 sec/step)\n",
            "INFO:tensorflow:global step 48160: loss = 0.6613 (2.282 sec/step)\n",
            "I0608 13:02:50.040461 139948276815744 learning.py:507] global step 48160: loss = 0.6613 (2.282 sec/step)\n",
            "INFO:tensorflow:global step 48170: loss = 0.5779 (2.469 sec/step)\n",
            "I0608 13:03:13.025193 139948276815744 learning.py:507] global step 48170: loss = 0.5779 (2.469 sec/step)\n",
            "INFO:tensorflow:global step 48180: loss = 1.1494 (2.361 sec/step)\n",
            "I0608 13:03:38.651427 139948276815744 learning.py:507] global step 48180: loss = 1.1494 (2.361 sec/step)\n",
            "INFO:tensorflow:global step 48190: loss = 1.6451 (2.331 sec/step)\n",
            "I0608 13:04:01.911529 139948276815744 learning.py:507] global step 48190: loss = 1.6451 (2.331 sec/step)\n",
            "INFO:tensorflow:global step 48200: loss = 0.6882 (2.226 sec/step)\n",
            "I0608 13:04:25.152901 139948276815744 learning.py:507] global step 48200: loss = 0.6882 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 48210: loss = 2.1590 (2.291 sec/step)\n",
            "I0608 13:04:48.554422 139948276815744 learning.py:507] global step 48210: loss = 2.1590 (2.291 sec/step)\n",
            "INFO:tensorflow:global step 48220: loss = 0.6284 (2.505 sec/step)\n",
            "I0608 13:05:12.478638 139948276815744 learning.py:507] global step 48220: loss = 0.6284 (2.505 sec/step)\n",
            "INFO:tensorflow:global step 48230: loss = 1.1605 (2.238 sec/step)\n",
            "I0608 13:05:35.987864 139948276815744 learning.py:507] global step 48230: loss = 1.1605 (2.238 sec/step)\n",
            "INFO:tensorflow:global step 48240: loss = 0.3710 (2.258 sec/step)\n",
            "I0608 13:05:58.575815 139948276815744 learning.py:507] global step 48240: loss = 0.3710 (2.258 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.426951\n",
            "I0608 13:06:12.485645 139946064713472 supervisor.py:1099] global_step/sec: 0.426951\n",
            "INFO:tensorflow:Recording summary at step 48245.\n",
            "I0608 13:06:12.650851 139946056320768 supervisor.py:1050] Recording summary at step 48245.\n",
            "INFO:tensorflow:global step 48250: loss = 1.2366 (2.312 sec/step)\n",
            "I0608 13:06:22.349399 139948276815744 learning.py:507] global step 48250: loss = 1.2366 (2.312 sec/step)\n",
            "INFO:tensorflow:global step 48260: loss = 1.1110 (2.217 sec/step)\n",
            "I0608 13:06:45.336038 139948276815744 learning.py:507] global step 48260: loss = 1.1110 (2.217 sec/step)\n",
            "INFO:tensorflow:global step 48270: loss = 0.7218 (2.301 sec/step)\n",
            "I0608 13:07:08.536085 139948276815744 learning.py:507] global step 48270: loss = 0.7218 (2.301 sec/step)\n",
            "INFO:tensorflow:global step 48280: loss = 1.8620 (2.194 sec/step)\n",
            "I0608 13:07:31.499885 139948276815744 learning.py:507] global step 48280: loss = 1.8620 (2.194 sec/step)\n",
            "INFO:tensorflow:global step 48290: loss = 0.7343 (2.285 sec/step)\n",
            "I0608 13:07:54.784710 139948276815744 learning.py:507] global step 48290: loss = 0.7343 (2.285 sec/step)\n",
            "INFO:tensorflow:global step 48300: loss = 1.5499 (2.308 sec/step)\n",
            "I0608 13:08:17.875784 139948276815744 learning.py:507] global step 48300: loss = 1.5499 (2.308 sec/step)\n",
            "INFO:tensorflow:global step 48310: loss = 1.1106 (2.251 sec/step)\n",
            "I0608 13:08:40.660306 139948276815744 learning.py:507] global step 48310: loss = 1.1106 (2.251 sec/step)\n",
            "INFO:tensorflow:global step 48320: loss = 0.9024 (2.238 sec/step)\n",
            "I0608 13:09:03.379765 139948276815744 learning.py:507] global step 48320: loss = 0.9024 (2.238 sec/step)\n",
            "INFO:tensorflow:global step 48330: loss = 0.9717 (2.240 sec/step)\n",
            "I0608 13:09:26.748862 139948276815744 learning.py:507] global step 48330: loss = 0.9717 (2.240 sec/step)\n",
            "INFO:tensorflow:global step 48340: loss = 0.9074 (2.218 sec/step)\n",
            "I0608 13:09:49.095414 139948276815744 learning.py:507] global step 48340: loss = 0.9074 (2.218 sec/step)\n",
            "INFO:tensorflow:global step 48350: loss = 0.8174 (2.260 sec/step)\n",
            "I0608 13:10:12.148683 139948276815744 learning.py:507] global step 48350: loss = 0.8174 (2.260 sec/step)\n",
            "INFO:tensorflow:global step 48360: loss = 1.0458 (2.331 sec/step)\n",
            "I0608 13:10:35.452165 139948276815744 learning.py:507] global step 48360: loss = 1.0458 (2.331 sec/step)\n",
            "INFO:tensorflow:global step 48370: loss = 1.2292 (2.258 sec/step)\n",
            "I0608 13:10:58.075583 139948276815744 learning.py:507] global step 48370: loss = 1.2292 (2.258 sec/step)\n",
            "INFO:tensorflow:global step 48380: loss = 1.8408 (2.227 sec/step)\n",
            "I0608 13:11:20.325200 139948276815744 learning.py:507] global step 48380: loss = 1.8408 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 48390: loss = 1.0493 (2.255 sec/step)\n",
            "I0608 13:11:43.417005 139948276815744 learning.py:507] global step 48390: loss = 1.0493 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 48400: loss = 1.4803 (2.254 sec/step)\n",
            "I0608 13:12:06.550846 139948276815744 learning.py:507] global step 48400: loss = 1.4803 (2.254 sec/step)\n",
            "INFO:tensorflow:global step 48410: loss = 0.8981 (2.207 sec/step)\n",
            "I0608 13:12:28.817101 139948276815744 learning.py:507] global step 48410: loss = 0.8981 (2.207 sec/step)\n",
            "INFO:tensorflow:global step 48420: loss = 0.5638 (2.180 sec/step)\n",
            "I0608 13:12:51.020959 139948276815744 learning.py:507] global step 48420: loss = 0.5638 (2.180 sec/step)\n",
            "INFO:tensorflow:global step 48430: loss = 0.8695 (2.235 sec/step)\n",
            "I0608 13:13:13.500248 139948276815744 learning.py:507] global step 48430: loss = 0.8695 (2.235 sec/step)\n",
            "INFO:tensorflow:global step 48440: loss = 1.1821 (2.229 sec/step)\n",
            "I0608 13:13:35.880585 139948276815744 learning.py:507] global step 48440: loss = 1.1821 (2.229 sec/step)\n",
            "INFO:tensorflow:global step 48450: loss = 1.6597 (2.226 sec/step)\n",
            "I0608 13:13:58.197147 139948276815744 learning.py:507] global step 48450: loss = 1.6597 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 48460: loss = 0.5414 (2.176 sec/step)\n",
            "I0608 13:14:20.551749 139948276815744 learning.py:507] global step 48460: loss = 0.5414 (2.176 sec/step)\n",
            "INFO:tensorflow:global step 48470: loss = 0.7054 (2.196 sec/step)\n",
            "I0608 13:14:42.955215 139948276815744 learning.py:507] global step 48470: loss = 0.7054 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 48480: loss = 0.2538 (2.306 sec/step)\n",
            "I0608 13:15:05.105979 139948276815744 learning.py:507] global step 48480: loss = 0.2538 (2.306 sec/step)\n",
            "INFO:tensorflow:global step 48490: loss = 0.9206 (2.224 sec/step)\n",
            "I0608 13:15:27.616739 139948276815744 learning.py:507] global step 48490: loss = 0.9206 (2.224 sec/step)\n",
            "INFO:tensorflow:global step 48500: loss = 0.9889 (2.214 sec/step)\n",
            "I0608 13:15:49.932911 139948276815744 learning.py:507] global step 48500: loss = 0.9889 (2.214 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 13:16:10.997426 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 48509.\n",
            "I0608 13:16:12.514090 139946056320768 supervisor.py:1050] Recording summary at step 48509.\n",
            "INFO:tensorflow:global step 48510: loss = 1.1750 (3.483 sec/step)\n",
            "I0608 13:16:14.174546 139948276815744 learning.py:507] global step 48510: loss = 1.1750 (3.483 sec/step)\n",
            "INFO:tensorflow:global step 48520: loss = 0.4411 (2.250 sec/step)\n",
            "I0608 13:16:36.680629 139948276815744 learning.py:507] global step 48520: loss = 0.4411 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 48530: loss = 1.6634 (2.211 sec/step)\n",
            "I0608 13:16:59.121492 139948276815744 learning.py:507] global step 48530: loss = 1.6634 (2.211 sec/step)\n",
            "INFO:tensorflow:global step 48540: loss = 1.0161 (2.258 sec/step)\n",
            "I0608 13:17:21.266258 139948276815744 learning.py:507] global step 48540: loss = 1.0161 (2.258 sec/step)\n",
            "INFO:tensorflow:global step 48550: loss = 1.3051 (2.391 sec/step)\n",
            "I0608 13:17:44.506604 139948276815744 learning.py:507] global step 48550: loss = 1.3051 (2.391 sec/step)\n",
            "INFO:tensorflow:global step 48560: loss = 0.9425 (2.252 sec/step)\n",
            "I0608 13:18:07.514830 139948276815744 learning.py:507] global step 48560: loss = 0.9425 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 48570: loss = 0.4021 (2.286 sec/step)\n",
            "I0608 13:18:30.461600 139948276815744 learning.py:507] global step 48570: loss = 0.4021 (2.286 sec/step)\n",
            "INFO:tensorflow:global step 48580: loss = 0.5829 (2.265 sec/step)\n",
            "I0608 13:18:53.625866 139948276815744 learning.py:507] global step 48580: loss = 0.5829 (2.265 sec/step)\n",
            "INFO:tensorflow:global step 48590: loss = 0.8115 (2.279 sec/step)\n",
            "I0608 13:19:16.496839 139948276815744 learning.py:507] global step 48590: loss = 0.8115 (2.279 sec/step)\n",
            "INFO:tensorflow:global step 48600: loss = 0.8404 (2.282 sec/step)\n",
            "I0608 13:19:39.614567 139948276815744 learning.py:507] global step 48600: loss = 0.8404 (2.282 sec/step)\n",
            "INFO:tensorflow:global step 48610: loss = 1.0097 (2.326 sec/step)\n",
            "I0608 13:20:03.907944 139948276815744 learning.py:507] global step 48610: loss = 1.0097 (2.326 sec/step)\n",
            "INFO:tensorflow:global step 48620: loss = 0.7133 (2.239 sec/step)\n",
            "I0608 13:20:28.711626 139948276815744 learning.py:507] global step 48620: loss = 0.7133 (2.239 sec/step)\n",
            "INFO:tensorflow:global step 48630: loss = 0.9563 (2.350 sec/step)\n",
            "I0608 13:20:51.822227 139948276815744 learning.py:507] global step 48630: loss = 0.9563 (2.350 sec/step)\n",
            "INFO:tensorflow:global step 48640: loss = 0.9434 (2.575 sec/step)\n",
            "I0608 13:21:15.303708 139948276815744 learning.py:507] global step 48640: loss = 0.9434 (2.575 sec/step)\n",
            "INFO:tensorflow:global step 48650: loss = 1.0037 (2.304 sec/step)\n",
            "I0608 13:21:39.102321 139948276815744 learning.py:507] global step 48650: loss = 1.0037 (2.304 sec/step)\n",
            "INFO:tensorflow:global step 48660: loss = 0.8608 (2.343 sec/step)\n",
            "I0608 13:22:03.783039 139948276815744 learning.py:507] global step 48660: loss = 0.8608 (2.343 sec/step)\n",
            "INFO:tensorflow:global step 48670: loss = 1.1330 (2.462 sec/step)\n",
            "I0608 13:22:27.713156 139948276815744 learning.py:507] global step 48670: loss = 1.1330 (2.462 sec/step)\n",
            "INFO:tensorflow:global step 48680: loss = 0.8933 (2.274 sec/step)\n",
            "I0608 13:22:51.654675 139948276815744 learning.py:507] global step 48680: loss = 0.8933 (2.274 sec/step)\n",
            "INFO:tensorflow:global step 48690: loss = 0.6644 (2.317 sec/step)\n",
            "I0608 13:23:14.286958 139948276815744 learning.py:507] global step 48690: loss = 0.6644 (2.317 sec/step)\n",
            "INFO:tensorflow:global step 48700: loss = 0.8008 (2.387 sec/step)\n",
            "I0608 13:23:36.776106 139948276815744 learning.py:507] global step 48700: loss = 0.8008 (2.387 sec/step)\n",
            "INFO:tensorflow:global step 48710: loss = 1.0503 (2.246 sec/step)\n",
            "I0608 13:24:00.182140 139948276815744 learning.py:507] global step 48710: loss = 1.0503 (2.246 sec/step)\n",
            "INFO:tensorflow:global step 48720: loss = 1.0383 (2.233 sec/step)\n",
            "I0608 13:24:23.268610 139948276815744 learning.py:507] global step 48720: loss = 1.0383 (2.233 sec/step)\n",
            "INFO:tensorflow:global step 48730: loss = 2.4469 (2.324 sec/step)\n",
            "I0608 13:24:46.224811 139948276815744 learning.py:507] global step 48730: loss = 2.4469 (2.324 sec/step)\n",
            "INFO:tensorflow:global step 48740: loss = 1.8118 (2.506 sec/step)\n",
            "I0608 13:25:09.955912 139948276815744 learning.py:507] global step 48740: loss = 1.8118 (2.506 sec/step)\n",
            "INFO:tensorflow:global step 48750: loss = 0.8545 (2.390 sec/step)\n",
            "I0608 13:25:33.770792 139948276815744 learning.py:507] global step 48750: loss = 0.8545 (2.390 sec/step)\n",
            "INFO:tensorflow:global step 48760: loss = 0.5883 (2.330 sec/step)\n",
            "I0608 13:25:56.760724 139948276815744 learning.py:507] global step 48760: loss = 0.5883 (2.330 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 48766.\n",
            "I0608 13:26:12.709362 139946056320768 supervisor.py:1050] Recording summary at step 48766.\n",
            "INFO:tensorflow:global step 48770: loss = 1.2018 (2.250 sec/step)\n",
            "I0608 13:26:20.739453 139948276815744 learning.py:507] global step 48770: loss = 1.2018 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 48780: loss = 0.9480 (2.261 sec/step)\n",
            "I0608 13:26:43.177159 139948276815744 learning.py:507] global step 48780: loss = 0.9480 (2.261 sec/step)\n",
            "INFO:tensorflow:global step 48790: loss = 0.5912 (2.788 sec/step)\n",
            "I0608 13:27:07.350934 139948276815744 learning.py:507] global step 48790: loss = 0.5912 (2.788 sec/step)\n",
            "INFO:tensorflow:global step 48800: loss = 0.5056 (2.507 sec/step)\n",
            "I0608 13:27:30.695223 139948276815744 learning.py:507] global step 48800: loss = 0.5056 (2.507 sec/step)\n",
            "INFO:tensorflow:global step 48810: loss = 1.1947 (2.313 sec/step)\n",
            "I0608 13:27:54.105919 139948276815744 learning.py:507] global step 48810: loss = 1.1947 (2.313 sec/step)\n",
            "INFO:tensorflow:global step 48820: loss = 0.9786 (2.392 sec/step)\n",
            "I0608 13:28:17.073168 139948276815744 learning.py:507] global step 48820: loss = 0.9786 (2.392 sec/step)\n",
            "INFO:tensorflow:global step 48830: loss = 1.1564 (2.620 sec/step)\n",
            "I0608 13:28:40.368774 139948276815744 learning.py:507] global step 48830: loss = 1.1564 (2.620 sec/step)\n",
            "INFO:tensorflow:global step 48840: loss = 0.3722 (2.352 sec/step)\n",
            "I0608 13:29:03.662616 139948276815744 learning.py:507] global step 48840: loss = 0.3722 (2.352 sec/step)\n",
            "INFO:tensorflow:global step 48850: loss = 0.8271 (2.244 sec/step)\n",
            "I0608 13:29:27.073943 139948276815744 learning.py:507] global step 48850: loss = 0.8271 (2.244 sec/step)\n",
            "INFO:tensorflow:global step 48860: loss = 1.6529 (2.377 sec/step)\n",
            "I0608 13:29:50.663956 139948276815744 learning.py:507] global step 48860: loss = 1.6529 (2.377 sec/step)\n",
            "INFO:tensorflow:global step 48870: loss = 1.3755 (2.335 sec/step)\n",
            "I0608 13:30:14.096873 139948276815744 learning.py:507] global step 48870: loss = 1.3755 (2.335 sec/step)\n",
            "INFO:tensorflow:global step 48880: loss = 2.3039 (2.922 sec/step)\n",
            "I0608 13:30:38.501683 139948276815744 learning.py:507] global step 48880: loss = 2.3039 (2.922 sec/step)\n",
            "INFO:tensorflow:global step 48890: loss = 0.6543 (2.355 sec/step)\n",
            "I0608 13:31:01.779596 139948276815744 learning.py:507] global step 48890: loss = 0.6543 (2.355 sec/step)\n",
            "INFO:tensorflow:global step 48900: loss = 1.0768 (2.316 sec/step)\n",
            "I0608 13:31:25.196121 139948276815744 learning.py:507] global step 48900: loss = 1.0768 (2.316 sec/step)\n",
            "INFO:tensorflow:global step 48910: loss = 1.1920 (2.275 sec/step)\n",
            "I0608 13:31:48.383815 139948276815744 learning.py:507] global step 48910: loss = 1.1920 (2.275 sec/step)\n",
            "INFO:tensorflow:global step 48920: loss = 0.7218 (2.225 sec/step)\n",
            "I0608 13:32:11.230858 139948276815744 learning.py:507] global step 48920: loss = 0.7218 (2.225 sec/step)\n",
            "INFO:tensorflow:global step 48930: loss = 0.6845 (2.255 sec/step)\n",
            "I0608 13:32:34.911854 139948276815744 learning.py:507] global step 48930: loss = 0.6845 (2.255 sec/step)\n",
            "INFO:tensorflow:global step 48940: loss = 0.4491 (2.219 sec/step)\n",
            "I0608 13:32:57.578258 139948276815744 learning.py:507] global step 48940: loss = 0.4491 (2.219 sec/step)\n",
            "INFO:tensorflow:global step 48950: loss = 1.0200 (2.286 sec/step)\n",
            "I0608 13:33:20.306982 139948276815744 learning.py:507] global step 48950: loss = 1.0200 (2.286 sec/step)\n",
            "INFO:tensorflow:global step 48960: loss = 0.9194 (2.453 sec/step)\n",
            "I0608 13:33:44.179975 139948276815744 learning.py:507] global step 48960: loss = 0.9194 (2.453 sec/step)\n",
            "INFO:tensorflow:global step 48970: loss = 1.1287 (2.287 sec/step)\n",
            "I0608 13:34:07.374408 139948276815744 learning.py:507] global step 48970: loss = 1.1287 (2.287 sec/step)\n",
            "INFO:tensorflow:global step 48980: loss = 0.8672 (2.265 sec/step)\n",
            "I0608 13:34:29.955497 139948276815744 learning.py:507] global step 48980: loss = 0.8672 (2.265 sec/step)\n",
            "INFO:tensorflow:global step 48990: loss = 1.1884 (2.253 sec/step)\n",
            "I0608 13:34:53.228903 139948276815744 learning.py:507] global step 48990: loss = 1.1884 (2.253 sec/step)\n",
            "INFO:tensorflow:global step 49000: loss = 0.3551 (2.283 sec/step)\n",
            "I0608 13:35:17.676832 139948276815744 learning.py:507] global step 49000: loss = 0.3551 (2.283 sec/step)\n",
            "INFO:tensorflow:global step 49010: loss = 1.2097 (2.385 sec/step)\n",
            "I0608 13:35:40.996946 139948276815744 learning.py:507] global step 49010: loss = 1.2097 (2.385 sec/step)\n",
            "INFO:tensorflow:global step 49020: loss = 0.6728 (2.259 sec/step)\n",
            "I0608 13:36:04.205551 139948276815744 learning.py:507] global step 49020: loss = 0.6728 (2.259 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 13:36:11.000133 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 49023.\n",
            "I0608 13:36:13.067799 139946056320768 supervisor.py:1050] Recording summary at step 49023.\n",
            "INFO:tensorflow:global step 49030: loss = 0.5485 (2.274 sec/step)\n",
            "I0608 13:36:29.014143 139948276815744 learning.py:507] global step 49030: loss = 0.5485 (2.274 sec/step)\n",
            "INFO:tensorflow:global step 49040: loss = 0.3176 (2.343 sec/step)\n",
            "I0608 13:36:53.572052 139948276815744 learning.py:507] global step 49040: loss = 0.3176 (2.343 sec/step)\n",
            "INFO:tensorflow:global step 49050: loss = 2.7596 (2.249 sec/step)\n",
            "I0608 13:37:16.465434 139948276815744 learning.py:507] global step 49050: loss = 2.7596 (2.249 sec/step)\n",
            "INFO:tensorflow:global step 49060: loss = 1.0007 (2.250 sec/step)\n",
            "I0608 13:37:39.406296 139948276815744 learning.py:507] global step 49060: loss = 1.0007 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 49070: loss = 1.0381 (2.406 sec/step)\n",
            "I0608 13:38:02.173740 139948276815744 learning.py:507] global step 49070: loss = 1.0381 (2.406 sec/step)\n",
            "INFO:tensorflow:global step 49080: loss = 1.3393 (2.268 sec/step)\n",
            "I0608 13:38:24.935927 139948276815744 learning.py:507] global step 49080: loss = 1.3393 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 49090: loss = 0.4199 (2.228 sec/step)\n",
            "I0608 13:38:47.447006 139948276815744 learning.py:507] global step 49090: loss = 0.4199 (2.228 sec/step)\n",
            "INFO:tensorflow:global step 49100: loss = 0.9614 (2.201 sec/step)\n",
            "I0608 13:39:10.163174 139948276815744 learning.py:507] global step 49100: loss = 0.9614 (2.201 sec/step)\n",
            "INFO:tensorflow:global step 49110: loss = 0.7975 (2.309 sec/step)\n",
            "I0608 13:39:33.014755 139948276815744 learning.py:507] global step 49110: loss = 0.7975 (2.309 sec/step)\n",
            "INFO:tensorflow:global step 49120: loss = 1.3800 (2.240 sec/step)\n",
            "I0608 13:39:55.893036 139948276815744 learning.py:507] global step 49120: loss = 1.3800 (2.240 sec/step)\n",
            "INFO:tensorflow:global step 49130: loss = 1.0185 (2.538 sec/step)\n",
            "I0608 13:40:19.829070 139948276815744 learning.py:507] global step 49130: loss = 1.0185 (2.538 sec/step)\n",
            "INFO:tensorflow:global step 49140: loss = 0.5628 (2.237 sec/step)\n",
            "I0608 13:40:43.569397 139948276815744 learning.py:507] global step 49140: loss = 0.5628 (2.237 sec/step)\n",
            "INFO:tensorflow:global step 49150: loss = 0.6989 (2.301 sec/step)\n",
            "I0608 13:41:06.558197 139948276815744 learning.py:507] global step 49150: loss = 0.6989 (2.301 sec/step)\n",
            "INFO:tensorflow:global step 49160: loss = 1.2022 (2.225 sec/step)\n",
            "I0608 13:41:29.200259 139948276815744 learning.py:507] global step 49160: loss = 1.2022 (2.225 sec/step)\n",
            "INFO:tensorflow:global step 49170: loss = 1.0724 (2.194 sec/step)\n",
            "I0608 13:41:51.657174 139948276815744 learning.py:507] global step 49170: loss = 1.0724 (2.194 sec/step)\n",
            "INFO:tensorflow:global step 49180: loss = 0.9429 (2.335 sec/step)\n",
            "I0608 13:42:14.661619 139948276815744 learning.py:507] global step 49180: loss = 0.9429 (2.335 sec/step)\n",
            "INFO:tensorflow:global step 49190: loss = 0.8896 (2.252 sec/step)\n",
            "I0608 13:42:38.252111 139948276815744 learning.py:507] global step 49190: loss = 0.8896 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 49200: loss = 1.1139 (2.241 sec/step)\n",
            "I0608 13:43:01.097955 139948276815744 learning.py:507] global step 49200: loss = 1.1139 (2.241 sec/step)\n",
            "INFO:tensorflow:global step 49210: loss = 0.8045 (2.191 sec/step)\n",
            "I0608 13:43:23.409142 139948276815744 learning.py:507] global step 49210: loss = 0.8045 (2.191 sec/step)\n",
            "INFO:tensorflow:global step 49220: loss = 1.2212 (2.651 sec/step)\n",
            "I0608 13:43:46.317439 139948276815744 learning.py:507] global step 49220: loss = 1.2212 (2.651 sec/step)\n",
            "INFO:tensorflow:global step 49230: loss = 1.3197 (2.239 sec/step)\n",
            "I0608 13:44:09.746985 139948276815744 learning.py:507] global step 49230: loss = 1.3197 (2.239 sec/step)\n",
            "INFO:tensorflow:global step 49240: loss = 1.9241 (2.487 sec/step)\n",
            "I0608 13:44:33.282424 139948276815744 learning.py:507] global step 49240: loss = 1.9241 (2.487 sec/step)\n",
            "INFO:tensorflow:global step 49250: loss = 1.3031 (2.552 sec/step)\n",
            "I0608 13:44:56.159609 139948276815744 learning.py:507] global step 49250: loss = 1.3031 (2.552 sec/step)\n",
            "INFO:tensorflow:global step 49260: loss = 0.6569 (2.343 sec/step)\n",
            "I0608 13:45:20.702119 139948276815744 learning.py:507] global step 49260: loss = 0.6569 (2.343 sec/step)\n",
            "INFO:tensorflow:global step 49270: loss = 0.3970 (2.229 sec/step)\n",
            "I0608 13:45:44.067129 139948276815744 learning.py:507] global step 49270: loss = 0.3970 (2.229 sec/step)\n",
            "INFO:tensorflow:global step 49280: loss = 0.8343 (2.368 sec/step)\n",
            "I0608 13:46:07.450224 139948276815744 learning.py:507] global step 49280: loss = 0.8343 (2.368 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 49281.\n",
            "I0608 13:46:12.652816 139946056320768 supervisor.py:1050] Recording summary at step 49281.\n",
            "INFO:tensorflow:global step 49290: loss = 0.9587 (2.404 sec/step)\n",
            "I0608 13:46:33.075957 139948276815744 learning.py:507] global step 49290: loss = 0.9587 (2.404 sec/step)\n",
            "INFO:tensorflow:global step 49300: loss = 0.8252 (2.337 sec/step)\n",
            "I0608 13:46:56.241166 139948276815744 learning.py:507] global step 49300: loss = 0.8252 (2.337 sec/step)\n",
            "INFO:tensorflow:global step 49310: loss = 0.8186 (2.390 sec/step)\n",
            "I0608 13:47:19.228509 139948276815744 learning.py:507] global step 49310: loss = 0.8186 (2.390 sec/step)\n",
            "INFO:tensorflow:global step 49320: loss = 0.4586 (2.286 sec/step)\n",
            "I0608 13:47:42.396482 139948276815744 learning.py:507] global step 49320: loss = 0.4586 (2.286 sec/step)\n",
            "INFO:tensorflow:global step 49330: loss = 0.5082 (2.303 sec/step)\n",
            "I0608 13:48:05.609504 139948276815744 learning.py:507] global step 49330: loss = 0.5082 (2.303 sec/step)\n",
            "INFO:tensorflow:global step 49340: loss = 0.6492 (2.224 sec/step)\n",
            "I0608 13:48:28.509060 139948276815744 learning.py:507] global step 49340: loss = 0.6492 (2.224 sec/step)\n",
            "INFO:tensorflow:global step 49350: loss = 0.6221 (2.247 sec/step)\n",
            "I0608 13:48:51.148941 139948276815744 learning.py:507] global step 49350: loss = 0.6221 (2.247 sec/step)\n",
            "INFO:tensorflow:global step 49360: loss = 2.7996 (2.445 sec/step)\n",
            "I0608 13:49:14.869879 139948276815744 learning.py:507] global step 49360: loss = 2.7996 (2.445 sec/step)\n",
            "INFO:tensorflow:global step 49370: loss = 0.5802 (2.386 sec/step)\n",
            "I0608 13:49:38.392930 139948276815744 learning.py:507] global step 49370: loss = 0.5802 (2.386 sec/step)\n",
            "INFO:tensorflow:global step 49380: loss = 0.9906 (2.272 sec/step)\n",
            "I0608 13:50:01.528897 139948276815744 learning.py:507] global step 49380: loss = 0.9906 (2.272 sec/step)\n",
            "INFO:tensorflow:global step 49390: loss = 1.0784 (2.252 sec/step)\n",
            "I0608 13:50:24.491829 139948276815744 learning.py:507] global step 49390: loss = 1.0784 (2.252 sec/step)\n",
            "INFO:tensorflow:global step 49400: loss = 0.2747 (2.569 sec/step)\n",
            "I0608 13:50:47.714165 139948276815744 learning.py:507] global step 49400: loss = 0.2747 (2.569 sec/step)\n",
            "INFO:tensorflow:global step 49410: loss = 0.2730 (2.226 sec/step)\n",
            "I0608 13:51:11.240047 139948276815744 learning.py:507] global step 49410: loss = 0.2730 (2.226 sec/step)\n",
            "INFO:tensorflow:global step 49420: loss = 0.6642 (2.354 sec/step)\n",
            "I0608 13:51:36.571889 139948276815744 learning.py:507] global step 49420: loss = 0.6642 (2.354 sec/step)\n",
            "INFO:tensorflow:global step 49430: loss = 0.5905 (2.705 sec/step)\n",
            "I0608 13:52:01.689548 139948276815744 learning.py:507] global step 49430: loss = 0.5905 (2.705 sec/step)\n",
            "INFO:tensorflow:global step 49440: loss = 0.8696 (2.327 sec/step)\n",
            "I0608 13:52:25.402744 139948276815744 learning.py:507] global step 49440: loss = 0.8696 (2.327 sec/step)\n",
            "INFO:tensorflow:global step 49450: loss = 0.5621 (2.405 sec/step)\n",
            "I0608 13:52:49.297146 139948276815744 learning.py:507] global step 49450: loss = 0.5621 (2.405 sec/step)\n",
            "INFO:tensorflow:global step 49460: loss = 1.5529 (2.408 sec/step)\n",
            "I0608 13:53:13.131764 139948276815744 learning.py:507] global step 49460: loss = 1.5529 (2.408 sec/step)\n",
            "INFO:tensorflow:global step 49470: loss = 0.9593 (2.251 sec/step)\n",
            "I0608 13:53:36.483572 139948276815744 learning.py:507] global step 49470: loss = 0.9593 (2.251 sec/step)\n",
            "INFO:tensorflow:global step 49480: loss = 0.2609 (2.342 sec/step)\n",
            "I0608 13:54:00.754143 139948276815744 learning.py:507] global step 49480: loss = 0.2609 (2.342 sec/step)\n",
            "INFO:tensorflow:global step 49490: loss = 2.4676 (2.407 sec/step)\n",
            "I0608 13:54:25.480067 139948276815744 learning.py:507] global step 49490: loss = 2.4676 (2.407 sec/step)\n",
            "INFO:tensorflow:global step 49500: loss = 0.5276 (2.445 sec/step)\n",
            "I0608 13:54:49.176616 139948276815744 learning.py:507] global step 49500: loss = 0.5276 (2.445 sec/step)\n",
            "INFO:tensorflow:global step 49510: loss = 0.4537 (2.375 sec/step)\n",
            "I0608 13:55:13.771264 139948276815744 learning.py:507] global step 49510: loss = 0.4537 (2.375 sec/step)\n",
            "INFO:tensorflow:global step 49520: loss = 1.1078 (2.347 sec/step)\n",
            "I0608 13:55:37.923327 139948276815744 learning.py:507] global step 49520: loss = 1.1078 (2.347 sec/step)\n",
            "INFO:tensorflow:global step 49530: loss = 1.0733 (2.416 sec/step)\n",
            "I0608 13:56:01.689615 139948276815744 learning.py:507] global step 49530: loss = 1.0733 (2.416 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 13:56:10.997494 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 49534.\n",
            "I0608 13:56:13.274071 139946056320768 supervisor.py:1050] Recording summary at step 49534.\n",
            "INFO:tensorflow:global step 49540: loss = 0.9387 (2.303 sec/step)\n",
            "I0608 13:56:26.383857 139948276815744 learning.py:507] global step 49540: loss = 0.9387 (2.303 sec/step)\n",
            "INFO:tensorflow:global step 49550: loss = 0.4119 (2.333 sec/step)\n",
            "I0608 13:56:50.114183 139948276815744 learning.py:507] global step 49550: loss = 0.4119 (2.333 sec/step)\n",
            "INFO:tensorflow:global step 49560: loss = 1.4047 (2.399 sec/step)\n",
            "I0608 13:57:14.212654 139948276815744 learning.py:507] global step 49560: loss = 1.4047 (2.399 sec/step)\n",
            "INFO:tensorflow:global step 49570: loss = 0.8320 (2.337 sec/step)\n",
            "I0608 13:57:38.177021 139948276815744 learning.py:507] global step 49570: loss = 0.8320 (2.337 sec/step)\n",
            "INFO:tensorflow:global step 49580: loss = 0.6479 (2.592 sec/step)\n",
            "I0608 13:58:02.268998 139948276815744 learning.py:507] global step 49580: loss = 0.6479 (2.592 sec/step)\n",
            "INFO:tensorflow:global step 49590: loss = 0.6955 (2.338 sec/step)\n",
            "I0608 13:58:27.265659 139948276815744 learning.py:507] global step 49590: loss = 0.6955 (2.338 sec/step)\n",
            "INFO:tensorflow:global step 49600: loss = 0.6133 (2.850 sec/step)\n",
            "I0608 13:58:53.698234 139948276815744 learning.py:507] global step 49600: loss = 0.6133 (2.850 sec/step)\n",
            "INFO:tensorflow:global step 49610: loss = 1.2609 (2.614 sec/step)\n",
            "I0608 13:59:18.665873 139948276815744 learning.py:507] global step 49610: loss = 1.2609 (2.614 sec/step)\n",
            "INFO:tensorflow:global step 49620: loss = 0.9964 (2.623 sec/step)\n",
            "I0608 13:59:43.750728 139948276815744 learning.py:507] global step 49620: loss = 0.9964 (2.623 sec/step)\n",
            "INFO:tensorflow:global step 49630: loss = 0.5387 (2.422 sec/step)\n",
            "I0608 14:00:07.182182 139948276815744 learning.py:507] global step 49630: loss = 0.5387 (2.422 sec/step)\n",
            "INFO:tensorflow:global step 49640: loss = 3.0839 (2.332 sec/step)\n",
            "I0608 14:00:30.147242 139948276815744 learning.py:507] global step 49640: loss = 3.0839 (2.332 sec/step)\n",
            "INFO:tensorflow:global step 49650: loss = 1.4879 (2.472 sec/step)\n",
            "I0608 14:00:54.035109 139948276815744 learning.py:507] global step 49650: loss = 1.4879 (2.472 sec/step)\n",
            "INFO:tensorflow:global step 49660: loss = 1.9066 (2.267 sec/step)\n",
            "I0608 14:01:18.646334 139948276815744 learning.py:507] global step 49660: loss = 1.9066 (2.267 sec/step)\n",
            "INFO:tensorflow:global step 49670: loss = 0.7440 (2.909 sec/step)\n",
            "I0608 14:01:44.564572 139948276815744 learning.py:507] global step 49670: loss = 0.7440 (2.909 sec/step)\n",
            "INFO:tensorflow:global step 49680: loss = 1.0384 (2.390 sec/step)\n",
            "I0608 14:02:09.779021 139948276815744 learning.py:507] global step 49680: loss = 1.0384 (2.390 sec/step)\n",
            "INFO:tensorflow:global step 49690: loss = 1.1918 (2.273 sec/step)\n",
            "I0608 14:02:33.220029 139948276815744 learning.py:507] global step 49690: loss = 1.1918 (2.273 sec/step)\n",
            "INFO:tensorflow:global step 49700: loss = 1.7866 (2.377 sec/step)\n",
            "I0608 14:02:57.425863 139948276815744 learning.py:507] global step 49700: loss = 1.7866 (2.377 sec/step)\n",
            "INFO:tensorflow:global step 49710: loss = 1.1051 (2.497 sec/step)\n",
            "I0608 14:03:22.463995 139948276815744 learning.py:507] global step 49710: loss = 1.1051 (2.497 sec/step)\n",
            "INFO:tensorflow:global step 49720: loss = 1.2987 (2.429 sec/step)\n",
            "I0608 14:03:46.574233 139948276815744 learning.py:507] global step 49720: loss = 1.2987 (2.429 sec/step)\n",
            "INFO:tensorflow:global step 49730: loss = 0.8453 (2.496 sec/step)\n",
            "I0608 14:04:10.797223 139948276815744 learning.py:507] global step 49730: loss = 0.8453 (2.496 sec/step)\n",
            "INFO:tensorflow:global step 49740: loss = 0.7031 (2.608 sec/step)\n",
            "I0608 14:04:34.673207 139948276815744 learning.py:507] global step 49740: loss = 0.7031 (2.608 sec/step)\n",
            "INFO:tensorflow:global step 49750: loss = 1.8507 (2.419 sec/step)\n",
            "I0608 14:05:00.168877 139948276815744 learning.py:507] global step 49750: loss = 1.8507 (2.419 sec/step)\n",
            "INFO:tensorflow:global step 49760: loss = 1.1074 (2.269 sec/step)\n",
            "I0608 14:05:24.572939 139948276815744 learning.py:507] global step 49760: loss = 1.1074 (2.269 sec/step)\n",
            "INFO:tensorflow:global step 49770: loss = 0.6423 (2.213 sec/step)\n",
            "I0608 14:05:48.020221 139948276815744 learning.py:507] global step 49770: loss = 0.6423 (2.213 sec/step)\n",
            "INFO:tensorflow:global step 49780: loss = 1.4372 (2.272 sec/step)\n",
            "I0608 14:06:10.909913 139948276815744 learning.py:507] global step 49780: loss = 1.4372 (2.272 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 49780.\n",
            "I0608 14:06:12.696616 139946056320768 supervisor.py:1050] Recording summary at step 49780.\n",
            "INFO:tensorflow:global step 49790: loss = 0.7736 (2.357 sec/step)\n",
            "I0608 14:06:36.026165 139948276815744 learning.py:507] global step 49790: loss = 0.7736 (2.357 sec/step)\n",
            "INFO:tensorflow:global step 49800: loss = 0.6748 (2.596 sec/step)\n",
            "I0608 14:07:00.575438 139948276815744 learning.py:507] global step 49800: loss = 0.6748 (2.596 sec/step)\n",
            "INFO:tensorflow:global step 49810: loss = 1.0924 (2.489 sec/step)\n",
            "I0608 14:07:24.608778 139948276815744 learning.py:507] global step 49810: loss = 1.0924 (2.489 sec/step)\n",
            "INFO:tensorflow:global step 49820: loss = 1.4221 (2.406 sec/step)\n",
            "I0608 14:07:49.190471 139948276815744 learning.py:507] global step 49820: loss = 1.4221 (2.406 sec/step)\n",
            "INFO:tensorflow:global step 49830: loss = 1.3029 (2.432 sec/step)\n",
            "I0608 14:08:13.492363 139948276815744 learning.py:507] global step 49830: loss = 1.3029 (2.432 sec/step)\n",
            "INFO:tensorflow:global step 49840: loss = 0.5770 (2.678 sec/step)\n",
            "I0608 14:08:38.606895 139948276815744 learning.py:507] global step 49840: loss = 0.5770 (2.678 sec/step)\n",
            "INFO:tensorflow:global step 49850: loss = 0.6299 (2.351 sec/step)\n",
            "I0608 14:09:01.710072 139948276815744 learning.py:507] global step 49850: loss = 0.6299 (2.351 sec/step)\n",
            "INFO:tensorflow:global step 49860: loss = 2.5180 (2.229 sec/step)\n",
            "I0608 14:09:24.789095 139948276815744 learning.py:507] global step 49860: loss = 2.5180 (2.229 sec/step)\n",
            "INFO:tensorflow:global step 49870: loss = 0.8572 (2.534 sec/step)\n",
            "I0608 14:09:48.008651 139948276815744 learning.py:507] global step 49870: loss = 0.8572 (2.534 sec/step)\n",
            "INFO:tensorflow:global step 49880: loss = 0.8582 (2.360 sec/step)\n",
            "I0608 14:10:11.573027 139948276815744 learning.py:507] global step 49880: loss = 0.8582 (2.360 sec/step)\n",
            "INFO:tensorflow:global step 49890: loss = 0.9398 (2.474 sec/step)\n",
            "I0608 14:10:36.873541 139948276815744 learning.py:507] global step 49890: loss = 0.9398 (2.474 sec/step)\n",
            "INFO:tensorflow:global step 49900: loss = 0.4267 (2.372 sec/step)\n",
            "I0608 14:11:00.499300 139948276815744 learning.py:507] global step 49900: loss = 0.4267 (2.372 sec/step)\n",
            "INFO:tensorflow:global step 49910: loss = 0.5330 (2.317 sec/step)\n",
            "I0608 14:11:24.730594 139948276815744 learning.py:507] global step 49910: loss = 0.5330 (2.317 sec/step)\n",
            "INFO:tensorflow:global step 49920: loss = 0.8358 (2.647 sec/step)\n",
            "I0608 14:11:48.887608 139948276815744 learning.py:507] global step 49920: loss = 0.8358 (2.647 sec/step)\n",
            "INFO:tensorflow:global step 49930: loss = 2.1365 (2.276 sec/step)\n",
            "I0608 14:12:13.259319 139948276815744 learning.py:507] global step 49930: loss = 2.1365 (2.276 sec/step)\n",
            "INFO:tensorflow:global step 49940: loss = 0.9071 (2.402 sec/step)\n",
            "I0608 14:12:38.006981 139948276815744 learning.py:507] global step 49940: loss = 0.9071 (2.402 sec/step)\n",
            "INFO:tensorflow:global step 49950: loss = 0.9972 (2.362 sec/step)\n",
            "I0608 14:13:02.492933 139948276815744 learning.py:507] global step 49950: loss = 0.9972 (2.362 sec/step)\n",
            "INFO:tensorflow:global step 49960: loss = 1.6026 (2.339 sec/step)\n",
            "I0608 14:13:26.779483 139948276815744 learning.py:507] global step 49960: loss = 1.6026 (2.339 sec/step)\n",
            "INFO:tensorflow:global step 49970: loss = 3.8290 (2.262 sec/step)\n",
            "I0608 14:13:50.281422 139948276815744 learning.py:507] global step 49970: loss = 3.8290 (2.262 sec/step)\n",
            "INFO:tensorflow:global step 49980: loss = 0.5006 (2.290 sec/step)\n",
            "I0608 14:14:14.001878 139948276815744 learning.py:507] global step 49980: loss = 0.5006 (2.290 sec/step)\n",
            "INFO:tensorflow:global step 49990: loss = 0.6787 (2.416 sec/step)\n",
            "I0608 14:14:36.987610 139948276815744 learning.py:507] global step 49990: loss = 0.6787 (2.416 sec/step)\n",
            "INFO:tensorflow:global step 50000: loss = 0.4496 (2.394 sec/step)\n",
            "I0608 14:15:00.478005 139948276815744 learning.py:507] global step 50000: loss = 0.4496 (2.394 sec/step)\n",
            "INFO:tensorflow:global step 50010: loss = 1.3754 (2.262 sec/step)\n",
            "I0608 14:15:24.596954 139948276815744 learning.py:507] global step 50010: loss = 1.3754 (2.262 sec/step)\n",
            "INFO:tensorflow:global step 50020: loss = 1.0829 (2.209 sec/step)\n",
            "I0608 14:15:47.667475 139948276815744 learning.py:507] global step 50020: loss = 1.0829 (2.209 sec/step)\n",
            "INFO:tensorflow:global step 50030: loss = 0.7963 (2.326 sec/step)\n",
            "I0608 14:16:10.540606 139948276815744 learning.py:507] global step 50030: loss = 0.7963 (2.326 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 14:16:11.002055 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 50030.\n",
            "I0608 14:16:13.375596 139946056320768 supervisor.py:1050] Recording summary at step 50030.\n",
            "INFO:tensorflow:global step 50040: loss = 1.3344 (2.438 sec/step)\n",
            "I0608 14:16:35.589982 139948276815744 learning.py:507] global step 50040: loss = 1.3344 (2.438 sec/step)\n",
            "INFO:tensorflow:global step 50050: loss = 1.1185 (2.286 sec/step)\n",
            "I0608 14:16:59.115072 139948276815744 learning.py:507] global step 50050: loss = 1.1185 (2.286 sec/step)\n",
            "INFO:tensorflow:global step 50060: loss = 1.0190 (2.351 sec/step)\n",
            "I0608 14:17:22.360663 139948276815744 learning.py:507] global step 50060: loss = 1.0190 (2.351 sec/step)\n",
            "INFO:tensorflow:global step 50070: loss = 0.9214 (2.288 sec/step)\n",
            "I0608 14:17:45.362013 139948276815744 learning.py:507] global step 50070: loss = 0.9214 (2.288 sec/step)\n",
            "INFO:tensorflow:global step 50080: loss = 0.3902 (2.419 sec/step)\n",
            "I0608 14:18:08.766194 139948276815744 learning.py:507] global step 50080: loss = 0.3902 (2.419 sec/step)\n",
            "INFO:tensorflow:global step 50090: loss = 0.9264 (2.642 sec/step)\n",
            "I0608 14:18:33.553468 139948276815744 learning.py:507] global step 50090: loss = 0.9264 (2.642 sec/step)\n",
            "INFO:tensorflow:global step 50100: loss = 1.3006 (2.242 sec/step)\n",
            "I0608 14:18:57.040877 139948276815744 learning.py:507] global step 50100: loss = 1.3006 (2.242 sec/step)\n",
            "INFO:tensorflow:global step 50110: loss = 0.9327 (2.236 sec/step)\n",
            "I0608 14:19:19.916993 139948276815744 learning.py:507] global step 50110: loss = 0.9327 (2.236 sec/step)\n",
            "INFO:tensorflow:global step 50120: loss = 1.7243 (2.198 sec/step)\n",
            "I0608 14:19:42.956644 139948276815744 learning.py:507] global step 50120: loss = 1.7243 (2.198 sec/step)\n",
            "INFO:tensorflow:global step 50130: loss = 0.9379 (2.348 sec/step)\n",
            "I0608 14:20:05.842660 139948276815744 learning.py:507] global step 50130: loss = 0.9379 (2.348 sec/step)\n",
            "INFO:tensorflow:global step 50140: loss = 0.7595 (2.371 sec/step)\n",
            "I0608 14:20:28.398186 139948276815744 learning.py:507] global step 50140: loss = 0.7595 (2.371 sec/step)\n",
            "INFO:tensorflow:global step 50150: loss = 0.7555 (2.309 sec/step)\n",
            "I0608 14:20:50.835517 139948276815744 learning.py:507] global step 50150: loss = 0.7555 (2.309 sec/step)\n",
            "INFO:tensorflow:global step 50160: loss = 0.6741 (2.327 sec/step)\n",
            "I0608 14:21:14.335763 139948276815744 learning.py:507] global step 50160: loss = 0.6741 (2.327 sec/step)\n",
            "INFO:tensorflow:global step 50170: loss = 0.9688 (2.785 sec/step)\n",
            "I0608 14:21:39.480420 139948276815744 learning.py:507] global step 50170: loss = 0.9688 (2.785 sec/step)\n",
            "INFO:tensorflow:global step 50180: loss = 0.9173 (2.643 sec/step)\n",
            "I0608 14:22:04.600855 139948276815744 learning.py:507] global step 50180: loss = 0.9173 (2.643 sec/step)\n",
            "INFO:tensorflow:global step 50190: loss = 1.2378 (2.563 sec/step)\n",
            "I0608 14:22:31.865124 139948276815744 learning.py:507] global step 50190: loss = 1.2378 (2.563 sec/step)\n",
            "INFO:tensorflow:global step 50200: loss = 0.6334 (2.401 sec/step)\n",
            "I0608 14:22:57.679027 139948276815744 learning.py:507] global step 50200: loss = 0.6334 (2.401 sec/step)\n",
            "INFO:tensorflow:global step 50210: loss = 1.0792 (2.477 sec/step)\n",
            "I0608 14:23:21.324425 139948276815744 learning.py:507] global step 50210: loss = 1.0792 (2.477 sec/step)\n",
            "INFO:tensorflow:global step 50220: loss = 1.0602 (2.561 sec/step)\n",
            "I0608 14:23:44.938812 139948276815744 learning.py:507] global step 50220: loss = 1.0602 (2.561 sec/step)\n",
            "INFO:tensorflow:global step 50230: loss = 0.8987 (2.681 sec/step)\n",
            "I0608 14:24:09.609627 139948276815744 learning.py:507] global step 50230: loss = 0.8987 (2.681 sec/step)\n",
            "INFO:tensorflow:global step 50240: loss = 1.6134 (2.383 sec/step)\n",
            "I0608 14:24:33.672844 139948276815744 learning.py:507] global step 50240: loss = 1.6134 (2.383 sec/step)\n",
            "INFO:tensorflow:global step 50250: loss = 0.9678 (2.418 sec/step)\n",
            "I0608 14:24:58.613725 139948276815744 learning.py:507] global step 50250: loss = 0.9678 (2.418 sec/step)\n",
            "INFO:tensorflow:global step 50260: loss = 0.7375 (2.465 sec/step)\n",
            "I0608 14:25:22.007356 139948276815744 learning.py:507] global step 50260: loss = 0.7375 (2.465 sec/step)\n",
            "INFO:tensorflow:global step 50270: loss = 0.6166 (2.405 sec/step)\n",
            "I0608 14:25:45.917299 139948276815744 learning.py:507] global step 50270: loss = 0.6166 (2.405 sec/step)\n",
            "INFO:tensorflow:global step 50280: loss = 0.7723 (2.421 sec/step)\n",
            "I0608 14:26:09.703175 139948276815744 learning.py:507] global step 50280: loss = 0.7723 (2.421 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 50280.\n",
            "I0608 14:26:12.592232 139946056320768 supervisor.py:1050] Recording summary at step 50280.\n",
            "INFO:tensorflow:global step 50290: loss = 0.5770 (2.779 sec/step)\n",
            "I0608 14:26:34.868038 139948276815744 learning.py:507] global step 50290: loss = 0.5770 (2.779 sec/step)\n",
            "INFO:tensorflow:global step 50300: loss = 0.6376 (2.493 sec/step)\n",
            "I0608 14:26:58.963738 139948276815744 learning.py:507] global step 50300: loss = 0.6376 (2.493 sec/step)\n",
            "INFO:tensorflow:global step 50310: loss = 0.8275 (2.723 sec/step)\n",
            "I0608 14:27:25.046374 139948276815744 learning.py:507] global step 50310: loss = 0.8275 (2.723 sec/step)\n",
            "INFO:tensorflow:global step 50320: loss = 0.4010 (2.463 sec/step)\n",
            "I0608 14:27:49.914716 139948276815744 learning.py:507] global step 50320: loss = 0.4010 (2.463 sec/step)\n",
            "INFO:tensorflow:global step 50330: loss = 1.0510 (2.659 sec/step)\n",
            "I0608 14:28:14.271326 139948276815744 learning.py:507] global step 50330: loss = 1.0510 (2.659 sec/step)\n",
            "INFO:tensorflow:global step 50340: loss = 2.0954 (2.290 sec/step)\n",
            "I0608 14:28:38.362277 139948276815744 learning.py:507] global step 50340: loss = 2.0954 (2.290 sec/step)\n",
            "INFO:tensorflow:global step 50350: loss = 0.9913 (2.698 sec/step)\n",
            "I0608 14:29:03.132949 139948276815744 learning.py:507] global step 50350: loss = 0.9913 (2.698 sec/step)\n",
            "INFO:tensorflow:global step 50360: loss = 0.7773 (2.359 sec/step)\n",
            "I0608 14:29:28.740993 139948276815744 learning.py:507] global step 50360: loss = 0.7773 (2.359 sec/step)\n",
            "INFO:tensorflow:global step 50370: loss = 0.8859 (2.499 sec/step)\n",
            "I0608 14:29:53.172233 139948276815744 learning.py:507] global step 50370: loss = 0.8859 (2.499 sec/step)\n",
            "INFO:tensorflow:global step 50380: loss = 0.6072 (2.544 sec/step)\n",
            "I0608 14:30:18.156503 139948276815744 learning.py:507] global step 50380: loss = 0.6072 (2.544 sec/step)\n",
            "INFO:tensorflow:global step 50390: loss = 0.5412 (2.710 sec/step)\n",
            "I0608 14:30:42.859236 139948276815744 learning.py:507] global step 50390: loss = 0.5412 (2.710 sec/step)\n",
            "INFO:tensorflow:global step 50400: loss = 0.9557 (2.843 sec/step)\n",
            "I0608 14:31:10.593222 139948276815744 learning.py:507] global step 50400: loss = 0.9557 (2.843 sec/step)\n",
            "INFO:tensorflow:global step 50410: loss = 1.0197 (2.494 sec/step)\n",
            "I0608 14:31:36.003031 139948276815744 learning.py:507] global step 50410: loss = 1.0197 (2.494 sec/step)\n",
            "INFO:tensorflow:global step 50420: loss = 0.4933 (2.425 sec/step)\n",
            "I0608 14:32:00.846533 139948276815744 learning.py:507] global step 50420: loss = 0.4933 (2.425 sec/step)\n",
            "INFO:tensorflow:global step 50430: loss = 0.2589 (2.673 sec/step)\n",
            "I0608 14:32:28.075356 139948276815744 learning.py:507] global step 50430: loss = 0.2589 (2.673 sec/step)\n",
            "INFO:tensorflow:global step 50440: loss = 0.8532 (2.980 sec/step)\n",
            "I0608 14:32:54.752036 139948276815744 learning.py:507] global step 50440: loss = 0.8532 (2.980 sec/step)\n",
            "INFO:tensorflow:global step 50450: loss = 0.5110 (2.288 sec/step)\n",
            "I0608 14:33:18.376852 139948276815744 learning.py:507] global step 50450: loss = 0.5110 (2.288 sec/step)\n",
            "INFO:tensorflow:global step 50460: loss = 1.2407 (2.315 sec/step)\n",
            "I0608 14:33:42.014462 139948276815744 learning.py:507] global step 50460: loss = 1.2407 (2.315 sec/step)\n",
            "INFO:tensorflow:global step 50470: loss = 0.8820 (2.268 sec/step)\n",
            "I0608 14:34:04.850605 139948276815744 learning.py:507] global step 50470: loss = 0.8820 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 50480: loss = 0.5709 (2.449 sec/step)\n",
            "I0608 14:34:28.892707 139948276815744 learning.py:507] global step 50480: loss = 0.5709 (2.449 sec/step)\n",
            "INFO:tensorflow:global step 50490: loss = 1.0153 (2.112 sec/step)\n",
            "I0608 14:34:53.772202 139948276815744 learning.py:507] global step 50490: loss = 1.0153 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 50500: loss = 1.3745 (2.129 sec/step)\n",
            "I0608 14:35:15.238433 139948276815744 learning.py:507] global step 50500: loss = 1.3745 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 50510: loss = 0.5613 (2.155 sec/step)\n",
            "I0608 14:35:36.654737 139948276815744 learning.py:507] global step 50510: loss = 0.5613 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 50520: loss = 0.8978 (2.141 sec/step)\n",
            "I0608 14:35:58.106170 139948276815744 learning.py:507] global step 50520: loss = 0.8978 (2.141 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 14:36:10.997124 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 50526.\n",
            "I0608 14:36:13.090712 139946056320768 supervisor.py:1050] Recording summary at step 50526.\n",
            "INFO:tensorflow:global step 50530: loss = 1.1397 (2.198 sec/step)\n",
            "I0608 14:36:20.728134 139948276815744 learning.py:507] global step 50530: loss = 1.1397 (2.198 sec/step)\n",
            "INFO:tensorflow:global step 50540: loss = 0.6684 (2.141 sec/step)\n",
            "I0608 14:36:42.203739 139948276815744 learning.py:507] global step 50540: loss = 0.6684 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 50550: loss = 0.7926 (2.120 sec/step)\n",
            "I0608 14:37:03.630237 139948276815744 learning.py:507] global step 50550: loss = 0.7926 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 50560: loss = 0.8615 (2.118 sec/step)\n",
            "I0608 14:37:24.995630 139948276815744 learning.py:507] global step 50560: loss = 0.8615 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 50570: loss = 0.6334 (2.138 sec/step)\n",
            "I0608 14:37:46.371803 139948276815744 learning.py:507] global step 50570: loss = 0.6334 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 50580: loss = 0.6568 (2.161 sec/step)\n",
            "I0608 14:38:07.803780 139948276815744 learning.py:507] global step 50580: loss = 0.6568 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 50590: loss = 0.8054 (2.138 sec/step)\n",
            "I0608 14:38:29.282553 139948276815744 learning.py:507] global step 50590: loss = 0.8054 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 50600: loss = 0.9789 (2.149 sec/step)\n",
            "I0608 14:38:50.630422 139948276815744 learning.py:507] global step 50600: loss = 0.9789 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 50610: loss = 0.5788 (2.149 sec/step)\n",
            "I0608 14:39:12.040631 139948276815744 learning.py:507] global step 50610: loss = 0.5788 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 50620: loss = 0.7717 (2.122 sec/step)\n",
            "I0608 14:39:33.339609 139948276815744 learning.py:507] global step 50620: loss = 0.7717 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 50630: loss = 0.6796 (2.111 sec/step)\n",
            "I0608 14:39:54.637821 139948276815744 learning.py:507] global step 50630: loss = 0.6796 (2.111 sec/step)\n",
            "INFO:tensorflow:global step 50640: loss = 0.8011 (2.162 sec/step)\n",
            "I0608 14:40:15.997728 139948276815744 learning.py:507] global step 50640: loss = 0.8011 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 50650: loss = 1.0455 (2.142 sec/step)\n",
            "I0608 14:40:37.367377 139948276815744 learning.py:507] global step 50650: loss = 1.0455 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 50660: loss = 0.9931 (2.115 sec/step)\n",
            "I0608 14:40:58.700714 139948276815744 learning.py:507] global step 50660: loss = 0.9931 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 50670: loss = 1.2721 (2.132 sec/step)\n",
            "I0608 14:41:20.048799 139948276815744 learning.py:507] global step 50670: loss = 1.2721 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 50680: loss = 1.0774 (2.118 sec/step)\n",
            "I0608 14:41:41.359893 139948276815744 learning.py:507] global step 50680: loss = 1.0774 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 50690: loss = 1.5269 (2.196 sec/step)\n",
            "I0608 14:42:02.788063 139948276815744 learning.py:507] global step 50690: loss = 1.5269 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 50700: loss = 1.3155 (2.151 sec/step)\n",
            "I0608 14:42:24.262342 139948276815744 learning.py:507] global step 50700: loss = 1.3155 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 50710: loss = 0.9986 (2.116 sec/step)\n",
            "I0608 14:42:45.520605 139948276815744 learning.py:507] global step 50710: loss = 0.9986 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 50720: loss = 0.6771 (2.130 sec/step)\n",
            "I0608 14:43:06.866717 139948276815744 learning.py:507] global step 50720: loss = 0.6771 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 50730: loss = 1.0722 (2.137 sec/step)\n",
            "I0608 14:43:28.153258 139948276815744 learning.py:507] global step 50730: loss = 1.0722 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 50740: loss = 0.8814 (2.143 sec/step)\n",
            "I0608 14:43:49.476026 139948276815744 learning.py:507] global step 50740: loss = 0.8814 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 50750: loss = 1.1302 (2.172 sec/step)\n",
            "I0608 14:44:10.932935 139948276815744 learning.py:507] global step 50750: loss = 1.1302 (2.172 sec/step)\n",
            "INFO:tensorflow:global step 50760: loss = 0.6681 (2.134 sec/step)\n",
            "I0608 14:44:32.282236 139948276815744 learning.py:507] global step 50760: loss = 0.6681 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 50770: loss = 0.5443 (2.127 sec/step)\n",
            "I0608 14:44:53.623507 139948276815744 learning.py:507] global step 50770: loss = 0.5443 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 50780: loss = 0.7458 (2.152 sec/step)\n",
            "I0608 14:45:14.949059 139948276815744 learning.py:507] global step 50780: loss = 0.7458 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 50790: loss = 1.4334 (2.135 sec/step)\n",
            "I0608 14:45:36.275288 139948276815744 learning.py:507] global step 50790: loss = 1.4334 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 50800: loss = 0.6019 (2.180 sec/step)\n",
            "I0608 14:45:57.690960 139948276815744 learning.py:507] global step 50800: loss = 0.6019 (2.180 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 50806.\n",
            "I0608 14:46:12.542070 139946056320768 supervisor.py:1050] Recording summary at step 50806.\n",
            "INFO:tensorflow:global step 50810: loss = 0.6859 (2.107 sec/step)\n",
            "I0608 14:46:19.772089 139948276815744 learning.py:507] global step 50810: loss = 0.6859 (2.107 sec/step)\n",
            "INFO:tensorflow:global step 50820: loss = 0.6593 (2.099 sec/step)\n",
            "I0608 14:46:41.109088 139948276815744 learning.py:507] global step 50820: loss = 0.6593 (2.099 sec/step)\n",
            "INFO:tensorflow:global step 50830: loss = 1.6869 (2.153 sec/step)\n",
            "I0608 14:47:02.367784 139948276815744 learning.py:507] global step 50830: loss = 1.6869 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 50840: loss = 0.6370 (2.153 sec/step)\n",
            "I0608 14:47:23.698835 139948276815744 learning.py:507] global step 50840: loss = 0.6370 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 50850: loss = 1.2921 (2.125 sec/step)\n",
            "I0608 14:47:44.998083 139948276815744 learning.py:507] global step 50850: loss = 1.2921 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 50860: loss = 0.8108 (2.109 sec/step)\n",
            "I0608 14:48:06.320389 139948276815744 learning.py:507] global step 50860: loss = 0.8108 (2.109 sec/step)\n",
            "INFO:tensorflow:global step 50870: loss = 0.7723 (2.123 sec/step)\n",
            "I0608 14:48:27.659123 139948276815744 learning.py:507] global step 50870: loss = 0.7723 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 50880: loss = 1.8286 (2.118 sec/step)\n",
            "I0608 14:48:48.988488 139948276815744 learning.py:507] global step 50880: loss = 1.8286 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 50890: loss = 0.8270 (2.119 sec/step)\n",
            "I0608 14:49:10.332175 139948276815744 learning.py:507] global step 50890: loss = 0.8270 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 50900: loss = 0.8242 (2.124 sec/step)\n",
            "I0608 14:49:31.636578 139948276815744 learning.py:507] global step 50900: loss = 0.8242 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 50910: loss = 1.1620 (2.126 sec/step)\n",
            "I0608 14:49:53.005104 139948276815744 learning.py:507] global step 50910: loss = 1.1620 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 50920: loss = 0.9589 (2.150 sec/step)\n",
            "I0608 14:50:14.395277 139948276815744 learning.py:507] global step 50920: loss = 0.9589 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 50930: loss = 0.5572 (2.123 sec/step)\n",
            "I0608 14:50:35.703253 139948276815744 learning.py:507] global step 50930: loss = 0.5572 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 50940: loss = 0.9451 (2.137 sec/step)\n",
            "I0608 14:50:57.050152 139948276815744 learning.py:507] global step 50940: loss = 0.9451 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 50950: loss = 0.8859 (2.119 sec/step)\n",
            "I0608 14:51:18.414473 139948276815744 learning.py:507] global step 50950: loss = 0.8859 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 50960: loss = 1.0582 (2.146 sec/step)\n",
            "I0608 14:51:39.724970 139948276815744 learning.py:507] global step 50960: loss = 1.0582 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 50970: loss = 0.6785 (2.126 sec/step)\n",
            "I0608 14:52:01.057470 139948276815744 learning.py:507] global step 50970: loss = 0.6785 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 50980: loss = 0.6877 (2.138 sec/step)\n",
            "I0608 14:52:22.529912 139948276815744 learning.py:507] global step 50980: loss = 0.6877 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 50990: loss = 0.3923 (2.154 sec/step)\n",
            "I0608 14:52:43.964280 139948276815744 learning.py:507] global step 50990: loss = 0.3923 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 51000: loss = 2.0719 (2.142 sec/step)\n",
            "I0608 14:53:05.478616 139948276815744 learning.py:507] global step 51000: loss = 2.0719 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 51010: loss = 2.2289 (2.167 sec/step)\n",
            "I0608 14:53:26.972136 139948276815744 learning.py:507] global step 51010: loss = 2.2289 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 51020: loss = 1.0168 (2.118 sec/step)\n",
            "I0608 14:53:48.323103 139948276815744 learning.py:507] global step 51020: loss = 1.0168 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 51030: loss = 0.7096 (2.218 sec/step)\n",
            "I0608 14:54:09.850949 139948276815744 learning.py:507] global step 51030: loss = 0.7096 (2.218 sec/step)\n",
            "INFO:tensorflow:global step 51040: loss = 1.1255 (2.130 sec/step)\n",
            "I0608 14:54:31.218770 139948276815744 learning.py:507] global step 51040: loss = 1.1255 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 51050: loss = 1.1851 (2.150 sec/step)\n",
            "I0608 14:54:52.608108 139948276815744 learning.py:507] global step 51050: loss = 1.1851 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 51060: loss = 1.3323 (2.138 sec/step)\n",
            "I0608 14:55:13.992007 139948276815744 learning.py:507] global step 51060: loss = 1.3323 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 51070: loss = 1.2812 (2.134 sec/step)\n",
            "I0608 14:55:35.398544 139948276815744 learning.py:507] global step 51070: loss = 1.2812 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 51080: loss = 0.5860 (2.117 sec/step)\n",
            "I0608 14:55:56.736845 139948276815744 learning.py:507] global step 51080: loss = 0.5860 (2.117 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 14:56:10.997353 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 51086.\n",
            "I0608 14:56:12.380440 139946056320768 supervisor.py:1050] Recording summary at step 51086.\n",
            "INFO:tensorflow:global step 51090: loss = 0.6260 (2.231 sec/step)\n",
            "I0608 14:56:19.414082 139948276815744 learning.py:507] global step 51090: loss = 0.6260 (2.231 sec/step)\n",
            "INFO:tensorflow:global step 51100: loss = 0.4226 (2.114 sec/step)\n",
            "I0608 14:56:40.775231 139948276815744 learning.py:507] global step 51100: loss = 0.4226 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 51110: loss = 1.0489 (2.116 sec/step)\n",
            "I0608 14:57:02.141604 139948276815744 learning.py:507] global step 51110: loss = 1.0489 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 51120: loss = 0.8206 (2.116 sec/step)\n",
            "I0608 14:57:23.564017 139948276815744 learning.py:507] global step 51120: loss = 0.8206 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 51130: loss = 1.6283 (2.122 sec/step)\n",
            "I0608 14:57:44.910655 139948276815744 learning.py:507] global step 51130: loss = 1.6283 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 51140: loss = 1.2501 (2.132 sec/step)\n",
            "I0608 14:58:06.255648 139948276815744 learning.py:507] global step 51140: loss = 1.2501 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51150: loss = 0.6463 (2.139 sec/step)\n",
            "I0608 14:58:27.639619 139948276815744 learning.py:507] global step 51150: loss = 0.6463 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 51160: loss = 1.5655 (2.133 sec/step)\n",
            "I0608 14:58:49.006485 139948276815744 learning.py:507] global step 51160: loss = 1.5655 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 51170: loss = 0.5906 (2.132 sec/step)\n",
            "I0608 14:59:10.403583 139948276815744 learning.py:507] global step 51170: loss = 0.5906 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51180: loss = 1.5213 (2.116 sec/step)\n",
            "I0608 14:59:31.763830 139948276815744 learning.py:507] global step 51180: loss = 1.5213 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 51190: loss = 0.4257 (2.115 sec/step)\n",
            "I0608 14:59:53.244191 139948276815744 learning.py:507] global step 51190: loss = 0.4257 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 51200: loss = 1.1157 (2.148 sec/step)\n",
            "I0608 15:00:14.685994 139948276815744 learning.py:507] global step 51200: loss = 1.1157 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 51210: loss = 0.8157 (2.139 sec/step)\n",
            "I0608 15:00:36.032775 139948276815744 learning.py:507] global step 51210: loss = 0.8157 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 51220: loss = 0.4903 (2.137 sec/step)\n",
            "I0608 15:00:57.484869 139948276815744 learning.py:507] global step 51220: loss = 0.4903 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 51230: loss = 1.7496 (2.113 sec/step)\n",
            "I0608 15:01:18.906587 139948276815744 learning.py:507] global step 51230: loss = 1.7496 (2.113 sec/step)\n",
            "INFO:tensorflow:global step 51240: loss = 0.8360 (2.134 sec/step)\n",
            "I0608 15:01:40.322234 139948276815744 learning.py:507] global step 51240: loss = 0.8360 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 51250: loss = 0.9166 (2.162 sec/step)\n",
            "I0608 15:02:01.815490 139948276815744 learning.py:507] global step 51250: loss = 0.9166 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 51260: loss = 1.1948 (2.155 sec/step)\n",
            "I0608 15:02:23.364922 139948276815744 learning.py:507] global step 51260: loss = 1.1948 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 51270: loss = 0.9006 (2.135 sec/step)\n",
            "I0608 15:02:44.732245 139948276815744 learning.py:507] global step 51270: loss = 0.9006 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 51280: loss = 0.6716 (2.109 sec/step)\n",
            "I0608 15:03:06.040829 139948276815744 learning.py:507] global step 51280: loss = 0.6716 (2.109 sec/step)\n",
            "INFO:tensorflow:global step 51290: loss = 0.5309 (2.132 sec/step)\n",
            "I0608 15:03:27.421720 139948276815744 learning.py:507] global step 51290: loss = 0.5309 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51300: loss = 0.8871 (2.117 sec/step)\n",
            "I0608 15:03:48.846709 139948276815744 learning.py:507] global step 51300: loss = 0.8871 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 51310: loss = 0.6963 (2.180 sec/step)\n",
            "I0608 15:04:10.272444 139948276815744 learning.py:507] global step 51310: loss = 0.6963 (2.180 sec/step)\n",
            "INFO:tensorflow:global step 51320: loss = 0.4746 (2.170 sec/step)\n",
            "I0608 15:04:31.745182 139948276815744 learning.py:507] global step 51320: loss = 0.4746 (2.170 sec/step)\n",
            "INFO:tensorflow:global step 51330: loss = 0.8359 (2.156 sec/step)\n",
            "I0608 15:04:53.178709 139948276815744 learning.py:507] global step 51330: loss = 0.8359 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 51340: loss = 0.9366 (2.153 sec/step)\n",
            "I0608 15:05:14.628088 139948276815744 learning.py:507] global step 51340: loss = 0.9366 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 51350: loss = 1.3697 (2.150 sec/step)\n",
            "I0608 15:05:36.033861 139948276815744 learning.py:507] global step 51350: loss = 1.3697 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 51360: loss = 0.9339 (2.149 sec/step)\n",
            "I0608 15:05:57.517405 139948276815744 learning.py:507] global step 51360: loss = 0.9339 (2.149 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 51366.\n",
            "I0608 15:06:12.477517 139946056320768 supervisor.py:1050] Recording summary at step 51366.\n",
            "INFO:tensorflow:global step 51370: loss = 0.7958 (2.138 sec/step)\n",
            "I0608 15:06:19.746961 139948276815744 learning.py:507] global step 51370: loss = 0.7958 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 51380: loss = 0.8494 (2.130 sec/step)\n",
            "I0608 15:06:41.143659 139948276815744 learning.py:507] global step 51380: loss = 0.8494 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 51390: loss = 0.7885 (2.134 sec/step)\n",
            "I0608 15:07:02.519522 139948276815744 learning.py:507] global step 51390: loss = 0.7885 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 51400: loss = 1.2871 (2.117 sec/step)\n",
            "I0608 15:07:23.966825 139948276815744 learning.py:507] global step 51400: loss = 1.2871 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 51410: loss = 0.8359 (2.161 sec/step)\n",
            "I0608 15:07:45.418868 139948276815744 learning.py:507] global step 51410: loss = 0.8359 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 51420: loss = 1.5007 (2.128 sec/step)\n",
            "I0608 15:08:06.798351 139948276815744 learning.py:507] global step 51420: loss = 1.5007 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 51430: loss = 1.2744 (2.138 sec/step)\n",
            "I0608 15:08:28.222028 139948276815744 learning.py:507] global step 51430: loss = 1.2744 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 51440: loss = 1.1113 (2.162 sec/step)\n",
            "I0608 15:08:49.628352 139948276815744 learning.py:507] global step 51440: loss = 1.1113 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 51450: loss = 1.1415 (2.161 sec/step)\n",
            "I0608 15:09:11.052222 139948276815744 learning.py:507] global step 51450: loss = 1.1415 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 51460: loss = 0.9907 (2.125 sec/step)\n",
            "I0608 15:09:32.333095 139948276815744 learning.py:507] global step 51460: loss = 0.9907 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 51470: loss = 2.0722 (2.137 sec/step)\n",
            "I0608 15:09:53.660160 139948276815744 learning.py:507] global step 51470: loss = 2.0722 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 51480: loss = 0.4277 (2.117 sec/step)\n",
            "I0608 15:10:15.170983 139948276815744 learning.py:507] global step 51480: loss = 0.4277 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 51490: loss = 1.5420 (2.132 sec/step)\n",
            "I0608 15:10:36.565037 139948276815744 learning.py:507] global step 51490: loss = 1.5420 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51500: loss = 0.6158 (2.130 sec/step)\n",
            "I0608 15:10:58.032559 139948276815744 learning.py:507] global step 51500: loss = 0.6158 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 51510: loss = 1.6535 (2.157 sec/step)\n",
            "I0608 15:11:19.407473 139948276815744 learning.py:507] global step 51510: loss = 1.6535 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 51520: loss = 0.6933 (2.119 sec/step)\n",
            "I0608 15:11:40.760777 139948276815744 learning.py:507] global step 51520: loss = 0.6933 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 51530: loss = 0.6249 (2.136 sec/step)\n",
            "I0608 15:12:02.206779 139948276815744 learning.py:507] global step 51530: loss = 0.6249 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 51540: loss = 1.4092 (2.132 sec/step)\n",
            "I0608 15:12:23.572840 139948276815744 learning.py:507] global step 51540: loss = 1.4092 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51550: loss = 1.1297 (2.173 sec/step)\n",
            "I0608 15:12:45.042847 139948276815744 learning.py:507] global step 51550: loss = 1.1297 (2.173 sec/step)\n",
            "INFO:tensorflow:global step 51560: loss = 0.6875 (2.167 sec/step)\n",
            "I0608 15:13:06.527442 139948276815744 learning.py:507] global step 51560: loss = 0.6875 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 51570: loss = 1.2176 (2.156 sec/step)\n",
            "I0608 15:13:28.021867 139948276815744 learning.py:507] global step 51570: loss = 1.2176 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 51580: loss = 0.7909 (2.136 sec/step)\n",
            "I0608 15:13:49.494983 139948276815744 learning.py:507] global step 51580: loss = 0.7909 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 51590: loss = 0.8223 (2.191 sec/step)\n",
            "I0608 15:14:11.009119 139948276815744 learning.py:507] global step 51590: loss = 0.8223 (2.191 sec/step)\n",
            "INFO:tensorflow:global step 51600: loss = 0.7569 (2.126 sec/step)\n",
            "I0608 15:14:32.377517 139948276815744 learning.py:507] global step 51600: loss = 0.7569 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 51610: loss = 0.5330 (2.150 sec/step)\n",
            "I0608 15:14:53.860741 139948276815744 learning.py:507] global step 51610: loss = 0.5330 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 51620: loss = 1.2508 (2.140 sec/step)\n",
            "I0608 15:15:15.317888 139948276815744 learning.py:507] global step 51620: loss = 1.2508 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 51630: loss = 1.6692 (2.126 sec/step)\n",
            "I0608 15:15:36.796015 139948276815744 learning.py:507] global step 51630: loss = 1.6692 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 51640: loss = 0.5742 (2.134 sec/step)\n",
            "I0608 15:15:58.258704 139948276815744 learning.py:507] global step 51640: loss = 0.5742 (2.134 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 15:16:10.997163 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 51646.\n",
            "I0608 15:16:12.938305 139946056320768 supervisor.py:1050] Recording summary at step 51646.\n",
            "INFO:tensorflow:global step 51650: loss = 0.6932 (2.227 sec/step)\n",
            "I0608 15:16:20.980889 139948276815744 learning.py:507] global step 51650: loss = 0.6932 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 51660: loss = 0.5587 (2.156 sec/step)\n",
            "I0608 15:16:42.325929 139948276815744 learning.py:507] global step 51660: loss = 0.5587 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 51670: loss = 1.1205 (2.114 sec/step)\n",
            "I0608 15:17:03.686046 139948276815744 learning.py:507] global step 51670: loss = 1.1205 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 51680: loss = 1.3363 (2.177 sec/step)\n",
            "I0608 15:17:25.211622 139948276815744 learning.py:507] global step 51680: loss = 1.3363 (2.177 sec/step)\n",
            "INFO:tensorflow:global step 51690: loss = 1.1288 (2.160 sec/step)\n",
            "I0608 15:17:46.572961 139948276815744 learning.py:507] global step 51690: loss = 1.1288 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 51700: loss = 0.8270 (2.125 sec/step)\n",
            "I0608 15:18:07.947600 139948276815744 learning.py:507] global step 51700: loss = 0.8270 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 51710: loss = 0.8440 (2.150 sec/step)\n",
            "I0608 15:18:29.335148 139948276815744 learning.py:507] global step 51710: loss = 0.8440 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 51720: loss = 0.7737 (2.129 sec/step)\n",
            "I0608 15:18:50.655557 139948276815744 learning.py:507] global step 51720: loss = 0.7737 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 51730: loss = 0.6199 (2.166 sec/step)\n",
            "I0608 15:19:12.012599 139948276815744 learning.py:507] global step 51730: loss = 0.6199 (2.166 sec/step)\n",
            "INFO:tensorflow:global step 51740: loss = 1.1000 (2.132 sec/step)\n",
            "I0608 15:19:33.433547 139948276815744 learning.py:507] global step 51740: loss = 1.1000 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51750: loss = 0.6306 (2.132 sec/step)\n",
            "I0608 15:19:54.796521 139948276815744 learning.py:507] global step 51750: loss = 0.6306 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 51760: loss = 0.6433 (2.125 sec/step)\n",
            "I0608 15:20:16.242365 139948276815744 learning.py:507] global step 51760: loss = 0.6433 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 51770: loss = 0.8743 (2.180 sec/step)\n",
            "I0608 15:20:37.777980 139948276815744 learning.py:507] global step 51770: loss = 0.8743 (2.180 sec/step)\n",
            "INFO:tensorflow:global step 51780: loss = 0.9519 (2.148 sec/step)\n",
            "I0608 15:20:59.201379 139948276815744 learning.py:507] global step 51780: loss = 0.9519 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 51790: loss = 0.5421 (2.148 sec/step)\n",
            "I0608 15:21:20.584260 139948276815744 learning.py:507] global step 51790: loss = 0.5421 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 51800: loss = 0.7646 (2.125 sec/step)\n",
            "I0608 15:21:41.916915 139948276815744 learning.py:507] global step 51800: loss = 0.7646 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 51810: loss = 1.6940 (2.143 sec/step)\n",
            "I0608 15:22:03.292976 139948276815744 learning.py:507] global step 51810: loss = 1.6940 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 51820: loss = 0.5366 (2.114 sec/step)\n",
            "I0608 15:22:24.597239 139948276815744 learning.py:507] global step 51820: loss = 0.5366 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 51830: loss = 0.7402 (2.140 sec/step)\n",
            "I0608 15:22:45.962503 139948276815744 learning.py:507] global step 51830: loss = 0.7402 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 51840: loss = 1.0713 (2.139 sec/step)\n",
            "I0608 15:23:07.392497 139948276815744 learning.py:507] global step 51840: loss = 1.0713 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 51850: loss = 1.2996 (2.153 sec/step)\n",
            "I0608 15:23:28.818347 139948276815744 learning.py:507] global step 51850: loss = 1.2996 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 51860: loss = 0.9959 (2.129 sec/step)\n",
            "I0608 15:23:50.188260 139948276815744 learning.py:507] global step 51860: loss = 0.9959 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 51870: loss = 1.0140 (2.175 sec/step)\n",
            "I0608 15:24:11.680222 139948276815744 learning.py:507] global step 51870: loss = 1.0140 (2.175 sec/step)\n",
            "INFO:tensorflow:global step 51880: loss = 0.8160 (2.122 sec/step)\n",
            "I0608 15:24:33.004665 139948276815744 learning.py:507] global step 51880: loss = 0.8160 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 51890: loss = 0.7618 (2.144 sec/step)\n",
            "I0608 15:24:54.392599 139948276815744 learning.py:507] global step 51890: loss = 0.7618 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 51900: loss = 1.1324 (2.160 sec/step)\n",
            "I0608 15:25:15.917352 139948276815744 learning.py:507] global step 51900: loss = 1.1324 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 51910: loss = 1.0754 (2.156 sec/step)\n",
            "I0608 15:25:37.289176 139948276815744 learning.py:507] global step 51910: loss = 1.0754 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 51920: loss = 0.9171 (2.141 sec/step)\n",
            "I0608 15:25:58.653366 139948276815744 learning.py:507] global step 51920: loss = 0.9171 (2.141 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 51926.\n",
            "I0608 15:26:12.357290 139946056320768 supervisor.py:1050] Recording summary at step 51926.\n",
            "INFO:tensorflow:global step 51930: loss = 0.7521 (2.115 sec/step)\n",
            "I0608 15:26:20.749520 139948276815744 learning.py:507] global step 51930: loss = 0.7521 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 51940: loss = 1.0042 (2.134 sec/step)\n",
            "I0608 15:26:42.179442 139948276815744 learning.py:507] global step 51940: loss = 1.0042 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 51950: loss = 0.8746 (2.143 sec/step)\n",
            "I0608 15:27:03.515556 139948276815744 learning.py:507] global step 51950: loss = 0.8746 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 51960: loss = 0.8066 (2.123 sec/step)\n",
            "I0608 15:27:24.880538 139948276815744 learning.py:507] global step 51960: loss = 0.8066 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 51970: loss = 0.8876 (2.152 sec/step)\n",
            "I0608 15:27:46.266773 139948276815744 learning.py:507] global step 51970: loss = 0.8876 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 51980: loss = 0.5519 (2.109 sec/step)\n",
            "I0608 15:28:07.590231 139948276815744 learning.py:507] global step 51980: loss = 0.5519 (2.109 sec/step)\n",
            "INFO:tensorflow:global step 51990: loss = 1.3889 (2.116 sec/step)\n",
            "I0608 15:28:28.985738 139948276815744 learning.py:507] global step 51990: loss = 1.3889 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 52000: loss = 1.4337 (2.158 sec/step)\n",
            "I0608 15:28:50.348568 139948276815744 learning.py:507] global step 52000: loss = 1.4337 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 52010: loss = 1.5153 (2.137 sec/step)\n",
            "I0608 15:29:11.655100 139948276815744 learning.py:507] global step 52010: loss = 1.5153 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 52020: loss = 1.6806 (2.130 sec/step)\n",
            "I0608 15:29:33.051353 139948276815744 learning.py:507] global step 52020: loss = 1.6806 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 52030: loss = 0.8281 (2.138 sec/step)\n",
            "I0608 15:29:54.425127 139948276815744 learning.py:507] global step 52030: loss = 0.8281 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 52040: loss = 1.1830 (2.122 sec/step)\n",
            "I0608 15:30:15.828945 139948276815744 learning.py:507] global step 52040: loss = 1.1830 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 52050: loss = 0.6550 (2.139 sec/step)\n",
            "I0608 15:30:37.234605 139948276815744 learning.py:507] global step 52050: loss = 0.6550 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 52060: loss = 0.4556 (2.144 sec/step)\n",
            "I0608 15:30:58.667846 139948276815744 learning.py:507] global step 52060: loss = 0.4556 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 52070: loss = 0.8339 (2.125 sec/step)\n",
            "I0608 15:31:20.066389 139948276815744 learning.py:507] global step 52070: loss = 0.8339 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 52080: loss = 2.5931 (2.126 sec/step)\n",
            "I0608 15:31:41.392689 139948276815744 learning.py:507] global step 52080: loss = 2.5931 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 52090: loss = 0.4937 (2.125 sec/step)\n",
            "I0608 15:32:02.731148 139948276815744 learning.py:507] global step 52090: loss = 0.4937 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 52100: loss = 2.2009 (2.124 sec/step)\n",
            "I0608 15:32:24.163752 139948276815744 learning.py:507] global step 52100: loss = 2.2009 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 52110: loss = 1.7875 (2.145 sec/step)\n",
            "I0608 15:32:45.630077 139948276815744 learning.py:507] global step 52110: loss = 1.7875 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 52120: loss = 0.4806 (2.152 sec/step)\n",
            "I0608 15:33:06.903505 139948276815744 learning.py:507] global step 52120: loss = 0.4806 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 52130: loss = 1.1446 (2.128 sec/step)\n",
            "I0608 15:33:28.199026 139948276815744 learning.py:507] global step 52130: loss = 1.1446 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 52140: loss = 1.2700 (2.135 sec/step)\n",
            "I0608 15:33:49.574842 139948276815744 learning.py:507] global step 52140: loss = 1.2700 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 52150: loss = 0.5185 (2.129 sec/step)\n",
            "I0608 15:34:10.874166 139948276815744 learning.py:507] global step 52150: loss = 0.5185 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 52160: loss = 2.1040 (2.123 sec/step)\n",
            "I0608 15:34:32.176845 139948276815744 learning.py:507] global step 52160: loss = 2.1040 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 52170: loss = 0.6056 (2.125 sec/step)\n",
            "I0608 15:34:53.542277 139948276815744 learning.py:507] global step 52170: loss = 0.6056 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 52180: loss = 1.0580 (2.128 sec/step)\n",
            "I0608 15:35:14.930203 139948276815744 learning.py:507] global step 52180: loss = 1.0580 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 52190: loss = 0.8985 (2.130 sec/step)\n",
            "I0608 15:35:36.311799 139948276815744 learning.py:507] global step 52190: loss = 0.8985 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 52200: loss = 1.1970 (2.156 sec/step)\n",
            "I0608 15:35:57.732733 139948276815744 learning.py:507] global step 52200: loss = 1.1970 (2.156 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 15:36:11.003044 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 52206.\n",
            "I0608 15:36:12.526626 139946056320768 supervisor.py:1050] Recording summary at step 52206.\n",
            "INFO:tensorflow:global step 52210: loss = 1.1662 (2.196 sec/step)\n",
            "I0608 15:36:20.362794 139948276815744 learning.py:507] global step 52210: loss = 1.1662 (2.196 sec/step)\n",
            "INFO:tensorflow:global step 52220: loss = 0.6598 (2.135 sec/step)\n",
            "I0608 15:36:41.787382 139948276815744 learning.py:507] global step 52220: loss = 0.6598 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 52230: loss = 0.8542 (2.142 sec/step)\n",
            "I0608 15:37:03.149785 139948276815744 learning.py:507] global step 52230: loss = 0.8542 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 52240: loss = 1.0967 (2.146 sec/step)\n",
            "I0608 15:37:24.545799 139948276815744 learning.py:507] global step 52240: loss = 1.0967 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 52250: loss = 1.1570 (2.141 sec/step)\n",
            "I0608 15:37:45.946842 139948276815744 learning.py:507] global step 52250: loss = 1.1570 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 52260: loss = 0.6428 (2.134 sec/step)\n",
            "I0608 15:38:07.361300 139948276815744 learning.py:507] global step 52260: loss = 0.6428 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 52270: loss = 1.0483 (2.122 sec/step)\n",
            "I0608 15:38:28.664345 139948276815744 learning.py:507] global step 52270: loss = 1.0483 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 52280: loss = 0.6095 (2.116 sec/step)\n",
            "I0608 15:38:50.052647 139948276815744 learning.py:507] global step 52280: loss = 0.6095 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 52290: loss = 0.8117 (2.144 sec/step)\n",
            "I0608 15:39:11.422739 139948276815744 learning.py:507] global step 52290: loss = 0.8117 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 52300: loss = 0.6819 (2.137 sec/step)\n",
            "I0608 15:39:32.778613 139948276815744 learning.py:507] global step 52300: loss = 0.6819 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 52310: loss = 1.1675 (2.129 sec/step)\n",
            "I0608 15:39:54.122445 139948276815744 learning.py:507] global step 52310: loss = 1.1675 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 52320: loss = 0.7449 (2.140 sec/step)\n",
            "I0608 15:40:15.496254 139948276815744 learning.py:507] global step 52320: loss = 0.7449 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 52330: loss = 1.4165 (2.124 sec/step)\n",
            "I0608 15:40:36.823025 139948276815744 learning.py:507] global step 52330: loss = 1.4165 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 52340: loss = 0.6682 (2.118 sec/step)\n",
            "I0608 15:40:58.179543 139948276815744 learning.py:507] global step 52340: loss = 0.6682 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 52350: loss = 0.6481 (2.128 sec/step)\n",
            "I0608 15:41:19.548267 139948276815744 learning.py:507] global step 52350: loss = 0.6481 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 52360: loss = 1.7336 (2.127 sec/step)\n",
            "I0608 15:41:40.913651 139948276815744 learning.py:507] global step 52360: loss = 1.7336 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 52370: loss = 2.2055 (2.142 sec/step)\n",
            "I0608 15:42:02.309942 139948276815744 learning.py:507] global step 52370: loss = 2.2055 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 52380: loss = 0.6570 (2.132 sec/step)\n",
            "I0608 15:42:23.703750 139948276815744 learning.py:507] global step 52380: loss = 0.6570 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 52390: loss = 1.1145 (2.135 sec/step)\n",
            "I0608 15:42:45.020460 139948276815744 learning.py:507] global step 52390: loss = 1.1145 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 52400: loss = 1.9191 (2.121 sec/step)\n",
            "I0608 15:43:06.321639 139948276815744 learning.py:507] global step 52400: loss = 1.9191 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 52410: loss = 0.5934 (2.147 sec/step)\n",
            "I0608 15:43:27.699267 139948276815744 learning.py:507] global step 52410: loss = 0.5934 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 52420: loss = 0.8706 (2.145 sec/step)\n",
            "I0608 15:43:49.069535 139948276815744 learning.py:507] global step 52420: loss = 0.8706 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 52430: loss = 1.3240 (2.157 sec/step)\n",
            "I0608 15:44:10.438670 139948276815744 learning.py:507] global step 52430: loss = 1.3240 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 52440: loss = 0.6961 (2.129 sec/step)\n",
            "I0608 15:44:31.789289 139948276815744 learning.py:507] global step 52440: loss = 0.6961 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 52450: loss = 0.7014 (2.126 sec/step)\n",
            "I0608 15:44:53.066210 139948276815744 learning.py:507] global step 52450: loss = 0.7014 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 52460: loss = 0.7727 (2.136 sec/step)\n",
            "I0608 15:45:14.432475 139948276815744 learning.py:507] global step 52460: loss = 0.7727 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 52470: loss = 0.6914 (2.127 sec/step)\n",
            "I0608 15:45:35.818536 139948276815744 learning.py:507] global step 52470: loss = 0.6914 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 52480: loss = 0.6669 (2.136 sec/step)\n",
            "I0608 15:45:57.134373 139948276815744 learning.py:507] global step 52480: loss = 0.6669 (2.136 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 52486.\n",
            "I0608 15:46:12.402427 139946056320768 supervisor.py:1050] Recording summary at step 52486.\n",
            "INFO:tensorflow:global step 52490: loss = 1.2187 (2.122 sec/step)\n",
            "I0608 15:46:19.183881 139948276815744 learning.py:507] global step 52490: loss = 1.2187 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 52500: loss = 0.8824 (2.116 sec/step)\n",
            "I0608 15:46:40.587311 139948276815744 learning.py:507] global step 52500: loss = 0.8824 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 52510: loss = 0.7697 (2.124 sec/step)\n",
            "I0608 15:47:01.939274 139948276815744 learning.py:507] global step 52510: loss = 0.7697 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 52520: loss = 1.1237 (2.127 sec/step)\n",
            "I0608 15:47:23.354857 139948276815744 learning.py:507] global step 52520: loss = 1.1237 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 52530: loss = 0.8829 (2.114 sec/step)\n",
            "I0608 15:47:44.671402 139948276815744 learning.py:507] global step 52530: loss = 0.8829 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 52540: loss = 0.9795 (2.143 sec/step)\n",
            "I0608 15:48:06.106742 139948276815744 learning.py:507] global step 52540: loss = 0.9795 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 52550: loss = 1.0760 (2.150 sec/step)\n",
            "I0608 15:48:27.396550 139948276815744 learning.py:507] global step 52550: loss = 1.0760 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 52560: loss = 1.9605 (2.129 sec/step)\n",
            "I0608 15:48:48.795418 139948276815744 learning.py:507] global step 52560: loss = 1.9605 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 52570: loss = 0.9187 (2.117 sec/step)\n",
            "I0608 15:49:10.112995 139948276815744 learning.py:507] global step 52570: loss = 0.9187 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 52580: loss = 0.8399 (2.149 sec/step)\n",
            "I0608 15:49:31.514049 139948276815744 learning.py:507] global step 52580: loss = 0.8399 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 52590: loss = 0.7417 (2.138 sec/step)\n",
            "I0608 15:49:52.928384 139948276815744 learning.py:507] global step 52590: loss = 0.7417 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 52600: loss = 0.5928 (2.156 sec/step)\n",
            "I0608 15:50:14.393467 139948276815744 learning.py:507] global step 52600: loss = 0.5928 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 52610: loss = 1.5737 (2.131 sec/step)\n",
            "I0608 15:50:35.791028 139948276815744 learning.py:507] global step 52610: loss = 1.5737 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 52620: loss = 1.9728 (2.132 sec/step)\n",
            "I0608 15:50:57.142895 139948276815744 learning.py:507] global step 52620: loss = 1.9728 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 52630: loss = 0.8083 (2.135 sec/step)\n",
            "I0608 15:51:18.481872 139948276815744 learning.py:507] global step 52630: loss = 0.8083 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 52640: loss = 0.5563 (2.118 sec/step)\n",
            "I0608 15:51:39.904039 139948276815744 learning.py:507] global step 52640: loss = 0.5563 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 52650: loss = 1.2950 (2.151 sec/step)\n",
            "I0608 15:52:01.392774 139948276815744 learning.py:507] global step 52650: loss = 1.2950 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 52660: loss = 0.5376 (2.140 sec/step)\n",
            "I0608 15:52:22.762182 139948276815744 learning.py:507] global step 52660: loss = 0.5376 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 52670: loss = 0.6017 (2.126 sec/step)\n",
            "I0608 15:52:44.103120 139948276815744 learning.py:507] global step 52670: loss = 0.6017 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 52680: loss = 1.6749 (2.138 sec/step)\n",
            "I0608 15:53:05.437949 139948276815744 learning.py:507] global step 52680: loss = 1.6749 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 52690: loss = 0.6997 (2.121 sec/step)\n",
            "I0608 15:53:26.732119 139948276815744 learning.py:507] global step 52690: loss = 0.6997 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 52700: loss = 1.0634 (2.154 sec/step)\n",
            "I0608 15:53:48.170569 139948276815744 learning.py:507] global step 52700: loss = 1.0634 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 52710: loss = 0.6441 (2.143 sec/step)\n",
            "I0608 15:54:09.585489 139948276815744 learning.py:507] global step 52710: loss = 0.6441 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 52720: loss = 0.9116 (2.108 sec/step)\n",
            "I0608 15:54:30.946554 139948276815744 learning.py:507] global step 52720: loss = 0.9116 (2.108 sec/step)\n",
            "INFO:tensorflow:global step 52730: loss = 0.6770 (2.140 sec/step)\n",
            "I0608 15:54:52.236562 139948276815744 learning.py:507] global step 52730: loss = 0.6770 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 52740: loss = 0.3996 (2.149 sec/step)\n",
            "I0608 15:55:13.591966 139948276815744 learning.py:507] global step 52740: loss = 0.3996 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 52750: loss = 1.1290 (2.131 sec/step)\n",
            "I0608 15:55:34.951310 139948276815744 learning.py:507] global step 52750: loss = 1.1290 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 52760: loss = 2.7912 (2.158 sec/step)\n",
            "I0608 15:55:56.280721 139948276815744 learning.py:507] global step 52760: loss = 2.7912 (2.158 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 15:56:10.997175 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 52767.\n",
            "I0608 15:56:12.783695 139946056320768 supervisor.py:1050] Recording summary at step 52767.\n",
            "INFO:tensorflow:global step 52770: loss = 1.2008 (2.247 sec/step)\n",
            "I0608 15:56:18.952466 139948276815744 learning.py:507] global step 52770: loss = 1.2008 (2.247 sec/step)\n",
            "INFO:tensorflow:global step 52780: loss = 0.7016 (2.132 sec/step)\n",
            "I0608 15:56:40.495796 139948276815744 learning.py:507] global step 52780: loss = 0.7016 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 52790: loss = 0.9900 (2.140 sec/step)\n",
            "I0608 15:57:01.909793 139948276815744 learning.py:507] global step 52790: loss = 0.9900 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 52800: loss = 1.5109 (2.127 sec/step)\n",
            "I0608 15:57:23.265450 139948276815744 learning.py:507] global step 52800: loss = 1.5109 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 52810: loss = 2.3750 (2.137 sec/step)\n",
            "I0608 15:57:44.599962 139948276815744 learning.py:507] global step 52810: loss = 2.3750 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 52820: loss = 0.8387 (2.155 sec/step)\n",
            "I0608 15:58:06.000569 139948276815744 learning.py:507] global step 52820: loss = 0.8387 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 52830: loss = 0.3554 (2.141 sec/step)\n",
            "I0608 15:58:27.429931 139948276815744 learning.py:507] global step 52830: loss = 0.3554 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 52840: loss = 1.4596 (2.124 sec/step)\n",
            "I0608 15:58:48.798725 139948276815744 learning.py:507] global step 52840: loss = 1.4596 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 52850: loss = 0.7393 (2.130 sec/step)\n",
            "I0608 15:59:10.238692 139948276815744 learning.py:507] global step 52850: loss = 0.7393 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 52860: loss = 0.7783 (2.130 sec/step)\n",
            "I0608 15:59:31.650123 139948276815744 learning.py:507] global step 52860: loss = 0.7783 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 52870: loss = 1.0275 (2.128 sec/step)\n",
            "I0608 15:59:53.008104 139948276815744 learning.py:507] global step 52870: loss = 1.0275 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 52880: loss = 0.6043 (2.139 sec/step)\n",
            "I0608 16:00:14.372737 139948276815744 learning.py:507] global step 52880: loss = 0.6043 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 52890: loss = 0.7946 (2.163 sec/step)\n",
            "I0608 16:00:35.720440 139948276815744 learning.py:507] global step 52890: loss = 0.7946 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 52900: loss = 0.9282 (2.128 sec/step)\n",
            "I0608 16:00:57.046942 139948276815744 learning.py:507] global step 52900: loss = 0.9282 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 52910: loss = 0.4949 (2.163 sec/step)\n",
            "I0608 16:01:18.463642 139948276815744 learning.py:507] global step 52910: loss = 0.4949 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 52920: loss = 0.5923 (2.157 sec/step)\n",
            "I0608 16:01:39.947628 139948276815744 learning.py:507] global step 52920: loss = 0.5923 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 52930: loss = 1.3215 (2.143 sec/step)\n",
            "I0608 16:02:01.458613 139948276815744 learning.py:507] global step 52930: loss = 1.3215 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 52940: loss = 0.6674 (2.126 sec/step)\n",
            "I0608 16:02:22.829378 139948276815744 learning.py:507] global step 52940: loss = 0.6674 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 52950: loss = 1.7149 (2.136 sec/step)\n",
            "I0608 16:02:44.229053 139948276815744 learning.py:507] global step 52950: loss = 1.7149 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 52960: loss = 0.9768 (2.137 sec/step)\n",
            "I0608 16:03:05.567116 139948276815744 learning.py:507] global step 52960: loss = 0.9768 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 52970: loss = 1.4343 (2.132 sec/step)\n",
            "I0608 16:03:26.971657 139948276815744 learning.py:507] global step 52970: loss = 1.4343 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 52980: loss = 0.8960 (2.160 sec/step)\n",
            "I0608 16:03:48.340724 139948276815744 learning.py:507] global step 52980: loss = 0.8960 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 52990: loss = 0.7152 (2.158 sec/step)\n",
            "I0608 16:04:09.781034 139948276815744 learning.py:507] global step 52990: loss = 0.7152 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 53000: loss = 1.0444 (2.135 sec/step)\n",
            "I0608 16:04:31.184514 139948276815744 learning.py:507] global step 53000: loss = 1.0444 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 53010: loss = 0.9021 (2.143 sec/step)\n",
            "I0608 16:04:52.594854 139948276815744 learning.py:507] global step 53010: loss = 0.9021 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 53020: loss = 0.8798 (2.111 sec/step)\n",
            "I0608 16:05:13.947586 139948276815744 learning.py:507] global step 53020: loss = 0.8798 (2.111 sec/step)\n",
            "INFO:tensorflow:global step 53030: loss = 0.4281 (2.143 sec/step)\n",
            "I0608 16:05:35.333375 139948276815744 learning.py:507] global step 53030: loss = 0.4281 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 53040: loss = 0.8178 (2.129 sec/step)\n",
            "I0608 16:05:56.756004 139948276815744 learning.py:507] global step 53040: loss = 0.8178 (2.129 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 53047.\n",
            "I0608 16:06:12.439571 139946056320768 supervisor.py:1050] Recording summary at step 53047.\n",
            "INFO:tensorflow:global step 53050: loss = 1.1226 (2.146 sec/step)\n",
            "I0608 16:06:18.864915 139948276815744 learning.py:507] global step 53050: loss = 1.1226 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 53060: loss = 1.0721 (2.124 sec/step)\n",
            "I0608 16:06:40.258455 139948276815744 learning.py:507] global step 53060: loss = 1.0721 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 53070: loss = 0.3286 (2.126 sec/step)\n",
            "I0608 16:07:01.665688 139948276815744 learning.py:507] global step 53070: loss = 0.3286 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 53080: loss = 1.5902 (2.125 sec/step)\n",
            "I0608 16:07:22.973629 139948276815744 learning.py:507] global step 53080: loss = 1.5902 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 53090: loss = 1.4537 (2.151 sec/step)\n",
            "I0608 16:07:44.306412 139948276815744 learning.py:507] global step 53090: loss = 1.4537 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 53100: loss = 0.2030 (2.156 sec/step)\n",
            "I0608 16:08:05.850181 139948276815744 learning.py:507] global step 53100: loss = 0.2030 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 53110: loss = 0.3302 (2.123 sec/step)\n",
            "I0608 16:08:27.152126 139948276815744 learning.py:507] global step 53110: loss = 0.3302 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 53120: loss = 0.5514 (2.157 sec/step)\n",
            "I0608 16:08:48.516639 139948276815744 learning.py:507] global step 53120: loss = 0.5514 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 53130: loss = 0.6952 (2.141 sec/step)\n",
            "I0608 16:09:09.850679 139948276815744 learning.py:507] global step 53130: loss = 0.6952 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 53140: loss = 0.5841 (2.127 sec/step)\n",
            "I0608 16:09:31.314739 139948276815744 learning.py:507] global step 53140: loss = 0.5841 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 53150: loss = 0.5572 (2.128 sec/step)\n",
            "I0608 16:09:52.773653 139948276815744 learning.py:507] global step 53150: loss = 0.5572 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53160: loss = 0.6927 (2.150 sec/step)\n",
            "I0608 16:10:14.118286 139948276815744 learning.py:507] global step 53160: loss = 0.6927 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 53170: loss = 0.4095 (2.145 sec/step)\n",
            "I0608 16:10:35.487803 139948276815744 learning.py:507] global step 53170: loss = 0.4095 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 53180: loss = 0.4412 (2.114 sec/step)\n",
            "I0608 16:10:56.884427 139948276815744 learning.py:507] global step 53180: loss = 0.4412 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 53190: loss = 2.2760 (2.162 sec/step)\n",
            "I0608 16:11:18.212961 139948276815744 learning.py:507] global step 53190: loss = 2.2760 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 53200: loss = 0.8044 (2.131 sec/step)\n",
            "I0608 16:11:39.556933 139948276815744 learning.py:507] global step 53200: loss = 0.8044 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 53210: loss = 1.0571 (2.135 sec/step)\n",
            "I0608 16:12:00.908736 139948276815744 learning.py:507] global step 53210: loss = 1.0571 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 53220: loss = 1.9964 (2.124 sec/step)\n",
            "I0608 16:12:22.360275 139948276815744 learning.py:507] global step 53220: loss = 1.9964 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 53230: loss = 0.7949 (2.131 sec/step)\n",
            "I0608 16:12:43.703385 139948276815744 learning.py:507] global step 53230: loss = 0.7949 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 53240: loss = 1.2749 (2.116 sec/step)\n",
            "I0608 16:13:05.074340 139948276815744 learning.py:507] global step 53240: loss = 1.2749 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 53250: loss = 0.5690 (2.121 sec/step)\n",
            "I0608 16:13:26.383759 139948276815744 learning.py:507] global step 53250: loss = 0.5690 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 53260: loss = 0.6312 (2.134 sec/step)\n",
            "I0608 16:13:47.755858 139948276815744 learning.py:507] global step 53260: loss = 0.6312 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 53270: loss = 0.4307 (2.128 sec/step)\n",
            "I0608 16:14:09.132911 139948276815744 learning.py:507] global step 53270: loss = 0.4307 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53280: loss = 1.1896 (2.130 sec/step)\n",
            "I0608 16:14:30.490751 139948276815744 learning.py:507] global step 53280: loss = 1.1896 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 53290: loss = 1.1333 (2.127 sec/step)\n",
            "I0608 16:14:51.865675 139948276815744 learning.py:507] global step 53290: loss = 1.1333 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 53300: loss = 2.4663 (2.123 sec/step)\n",
            "I0608 16:15:13.128141 139948276815744 learning.py:507] global step 53300: loss = 2.4663 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 53310: loss = 1.0788 (2.122 sec/step)\n",
            "I0608 16:15:34.463115 139948276815744 learning.py:507] global step 53310: loss = 1.0788 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 53320: loss = 0.8091 (2.123 sec/step)\n",
            "I0608 16:15:55.800422 139948276815744 learning.py:507] global step 53320: loss = 0.8091 (2.123 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 16:16:10.997213 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 53327.\n",
            "I0608 16:16:13.030254 139946056320768 supervisor.py:1050] Recording summary at step 53327.\n",
            "INFO:tensorflow:global step 53330: loss = 1.4175 (2.128 sec/step)\n",
            "I0608 16:16:18.315773 139948276815744 learning.py:507] global step 53330: loss = 1.4175 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53340: loss = 0.5015 (2.133 sec/step)\n",
            "I0608 16:16:39.805804 139948276815744 learning.py:507] global step 53340: loss = 0.5015 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 53350: loss = 0.7417 (2.130 sec/step)\n",
            "I0608 16:17:01.221184 139948276815744 learning.py:507] global step 53350: loss = 0.7417 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 53360: loss = 0.6087 (2.140 sec/step)\n",
            "I0608 16:17:22.577012 139948276815744 learning.py:507] global step 53360: loss = 0.6087 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 53370: loss = 1.2763 (2.142 sec/step)\n",
            "I0608 16:17:43.934144 139948276815744 learning.py:507] global step 53370: loss = 1.2763 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 53380: loss = 0.7759 (2.153 sec/step)\n",
            "I0608 16:18:05.275397 139948276815744 learning.py:507] global step 53380: loss = 0.7759 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 53390: loss = 1.4628 (2.124 sec/step)\n",
            "I0608 16:18:26.574816 139948276815744 learning.py:507] global step 53390: loss = 1.4628 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 53400: loss = 0.9260 (2.120 sec/step)\n",
            "I0608 16:18:47.886339 139948276815744 learning.py:507] global step 53400: loss = 0.9260 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 53410: loss = 0.8438 (2.149 sec/step)\n",
            "I0608 16:19:09.310730 139948276815744 learning.py:507] global step 53410: loss = 0.8438 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 53420: loss = 0.6738 (2.143 sec/step)\n",
            "I0608 16:19:30.701431 139948276815744 learning.py:507] global step 53420: loss = 0.6738 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 53430: loss = 1.4407 (2.127 sec/step)\n",
            "I0608 16:19:52.071655 139948276815744 learning.py:507] global step 53430: loss = 1.4407 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 53440: loss = 0.9476 (2.144 sec/step)\n",
            "I0608 16:20:13.422454 139948276815744 learning.py:507] global step 53440: loss = 0.9476 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 53450: loss = 1.0686 (2.123 sec/step)\n",
            "I0608 16:20:34.769616 139948276815744 learning.py:507] global step 53450: loss = 1.0686 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 53460: loss = 0.8651 (2.117 sec/step)\n",
            "I0608 16:20:56.172748 139948276815744 learning.py:507] global step 53460: loss = 0.8651 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 53470: loss = 0.9998 (2.131 sec/step)\n",
            "I0608 16:21:17.582046 139948276815744 learning.py:507] global step 53470: loss = 0.9998 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 53480: loss = 0.9987 (2.129 sec/step)\n",
            "I0608 16:21:38.963010 139948276815744 learning.py:507] global step 53480: loss = 0.9987 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 53490: loss = 0.8778 (2.132 sec/step)\n",
            "I0608 16:22:00.322644 139948276815744 learning.py:507] global step 53490: loss = 0.8778 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 53500: loss = 0.7748 (2.139 sec/step)\n",
            "I0608 16:22:21.704012 139948276815744 learning.py:507] global step 53500: loss = 0.7748 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 53510: loss = 1.1143 (2.124 sec/step)\n",
            "I0608 16:22:43.094856 139948276815744 learning.py:507] global step 53510: loss = 1.1143 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 53520: loss = 0.6276 (2.130 sec/step)\n",
            "I0608 16:23:04.567870 139948276815744 learning.py:507] global step 53520: loss = 0.6276 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 53530: loss = 1.1581 (2.137 sec/step)\n",
            "I0608 16:23:25.977972 139948276815744 learning.py:507] global step 53530: loss = 1.1581 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 53540: loss = 0.7925 (2.123 sec/step)\n",
            "I0608 16:23:47.397188 139948276815744 learning.py:507] global step 53540: loss = 0.7925 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 53550: loss = 0.8834 (2.119 sec/step)\n",
            "I0608 16:24:08.775221 139948276815744 learning.py:507] global step 53550: loss = 0.8834 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 53560: loss = 0.5082 (2.139 sec/step)\n",
            "I0608 16:24:30.107342 139948276815744 learning.py:507] global step 53560: loss = 0.5082 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 53570: loss = 0.6351 (2.151 sec/step)\n",
            "I0608 16:24:51.450105 139948276815744 learning.py:507] global step 53570: loss = 0.6351 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 53580: loss = 1.2076 (2.146 sec/step)\n",
            "I0608 16:25:12.877016 139948276815744 learning.py:507] global step 53580: loss = 1.2076 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 53590: loss = 1.1722 (2.123 sec/step)\n",
            "I0608 16:25:34.294598 139948276815744 learning.py:507] global step 53590: loss = 1.1722 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 53600: loss = 0.5726 (2.131 sec/step)\n",
            "I0608 16:25:55.781439 139948276815744 learning.py:507] global step 53600: loss = 0.5726 (2.131 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 53607.\n",
            "I0608 16:26:12.423789 139946056320768 supervisor.py:1050] Recording summary at step 53607.\n",
            "INFO:tensorflow:global step 53610: loss = 2.9868 (2.146 sec/step)\n",
            "I0608 16:26:17.951867 139948276815744 learning.py:507] global step 53610: loss = 2.9868 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 53620: loss = 0.9706 (2.154 sec/step)\n",
            "I0608 16:26:39.387886 139948276815744 learning.py:507] global step 53620: loss = 0.9706 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 53630: loss = 0.8206 (2.145 sec/step)\n",
            "I0608 16:27:00.771669 139948276815744 learning.py:507] global step 53630: loss = 0.8206 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 53640: loss = 2.1174 (2.124 sec/step)\n",
            "I0608 16:27:22.191844 139948276815744 learning.py:507] global step 53640: loss = 2.1174 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 53650: loss = 1.7797 (2.146 sec/step)\n",
            "I0608 16:27:43.563358 139948276815744 learning.py:507] global step 53650: loss = 1.7797 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 53660: loss = 0.7780 (2.137 sec/step)\n",
            "I0608 16:28:05.002739 139948276815744 learning.py:507] global step 53660: loss = 0.7780 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 53670: loss = 0.7448 (2.142 sec/step)\n",
            "I0608 16:28:26.349780 139948276815744 learning.py:507] global step 53670: loss = 0.7448 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 53680: loss = 1.3102 (2.120 sec/step)\n",
            "I0608 16:28:47.617762 139948276815744 learning.py:507] global step 53680: loss = 1.3102 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 53690: loss = 2.2769 (2.147 sec/step)\n",
            "I0608 16:29:08.995846 139948276815744 learning.py:507] global step 53690: loss = 2.2769 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 53700: loss = 0.6104 (2.138 sec/step)\n",
            "I0608 16:29:30.359176 139948276815744 learning.py:507] global step 53700: loss = 0.6104 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 53710: loss = 0.6072 (2.172 sec/step)\n",
            "I0608 16:29:51.674854 139948276815744 learning.py:507] global step 53710: loss = 0.6072 (2.172 sec/step)\n",
            "INFO:tensorflow:global step 53720: loss = 1.1408 (2.121 sec/step)\n",
            "I0608 16:30:13.009152 139948276815744 learning.py:507] global step 53720: loss = 1.1408 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 53730: loss = 1.2068 (2.133 sec/step)\n",
            "I0608 16:30:34.332867 139948276815744 learning.py:507] global step 53730: loss = 1.2068 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 53740: loss = 0.8955 (2.186 sec/step)\n",
            "I0608 16:30:55.741100 139948276815744 learning.py:507] global step 53740: loss = 0.8955 (2.186 sec/step)\n",
            "INFO:tensorflow:global step 53750: loss = 1.4081 (2.117 sec/step)\n",
            "I0608 16:31:17.118561 139948276815744 learning.py:507] global step 53750: loss = 1.4081 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 53760: loss = 1.5681 (2.140 sec/step)\n",
            "I0608 16:31:38.621623 139948276815744 learning.py:507] global step 53760: loss = 1.5681 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 53770: loss = 1.1740 (2.176 sec/step)\n",
            "I0608 16:32:00.069557 139948276815744 learning.py:507] global step 53770: loss = 1.1740 (2.176 sec/step)\n",
            "INFO:tensorflow:global step 53780: loss = 0.8177 (2.188 sec/step)\n",
            "I0608 16:32:21.503607 139948276815744 learning.py:507] global step 53780: loss = 0.8177 (2.188 sec/step)\n",
            "INFO:tensorflow:global step 53790: loss = 0.5276 (2.128 sec/step)\n",
            "I0608 16:32:42.861153 139948276815744 learning.py:507] global step 53790: loss = 0.5276 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53800: loss = 0.9589 (2.127 sec/step)\n",
            "I0608 16:33:04.330894 139948276815744 learning.py:507] global step 53800: loss = 0.9589 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 53810: loss = 0.8191 (2.150 sec/step)\n",
            "I0608 16:33:25.723236 139948276815744 learning.py:507] global step 53810: loss = 0.8191 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 53820: loss = 0.8529 (2.147 sec/step)\n",
            "I0608 16:33:47.078807 139948276815744 learning.py:507] global step 53820: loss = 0.8529 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 53830: loss = 0.5762 (2.135 sec/step)\n",
            "I0608 16:34:08.448212 139948276815744 learning.py:507] global step 53830: loss = 0.5762 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 53840: loss = 0.5987 (2.115 sec/step)\n",
            "I0608 16:34:29.845890 139948276815744 learning.py:507] global step 53840: loss = 0.5987 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 53850: loss = 1.1619 (2.141 sec/step)\n",
            "I0608 16:34:51.171388 139948276815744 learning.py:507] global step 53850: loss = 1.1619 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 53860: loss = 1.1823 (2.148 sec/step)\n",
            "I0608 16:35:12.618086 139948276815744 learning.py:507] global step 53860: loss = 1.1823 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 53870: loss = 0.9574 (2.131 sec/step)\n",
            "I0608 16:35:33.995509 139948276815744 learning.py:507] global step 53870: loss = 0.9574 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 53880: loss = 0.7009 (2.146 sec/step)\n",
            "I0608 16:35:55.434163 139948276815744 learning.py:507] global step 53880: loss = 0.7009 (2.146 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 16:36:10.997106 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 53887.\n",
            "I0608 16:36:12.513708 139946056320768 supervisor.py:1050] Recording summary at step 53887.\n",
            "INFO:tensorflow:global step 53890: loss = 0.3193 (2.128 sec/step)\n",
            "I0608 16:36:17.927248 139948276815744 learning.py:507] global step 53890: loss = 0.3193 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53900: loss = 1.0152 (2.172 sec/step)\n",
            "I0608 16:36:39.437708 139948276815744 learning.py:507] global step 53900: loss = 1.0152 (2.172 sec/step)\n",
            "INFO:tensorflow:global step 53910: loss = 0.9991 (2.146 sec/step)\n",
            "I0608 16:37:00.877346 139948276815744 learning.py:507] global step 53910: loss = 0.9991 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 53920: loss = 1.0141 (2.165 sec/step)\n",
            "I0608 16:37:22.287678 139948276815744 learning.py:507] global step 53920: loss = 1.0141 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 53930: loss = 0.6003 (2.128 sec/step)\n",
            "I0608 16:37:43.609622 139948276815744 learning.py:507] global step 53930: loss = 0.6003 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 53940: loss = 0.8748 (2.135 sec/step)\n",
            "I0608 16:38:05.030023 139948276815744 learning.py:507] global step 53940: loss = 0.8748 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 53950: loss = 0.7263 (2.152 sec/step)\n",
            "I0608 16:38:26.446828 139948276815744 learning.py:507] global step 53950: loss = 0.7263 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 53960: loss = 1.2024 (2.161 sec/step)\n",
            "I0608 16:38:47.846297 139948276815744 learning.py:507] global step 53960: loss = 1.2024 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 53970: loss = 1.4877 (2.127 sec/step)\n",
            "I0608 16:39:09.177490 139948276815744 learning.py:507] global step 53970: loss = 1.4877 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 53980: loss = 1.1020 (2.147 sec/step)\n",
            "I0608 16:39:30.551357 139948276815744 learning.py:507] global step 53980: loss = 1.1020 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 53990: loss = 0.6519 (2.155 sec/step)\n",
            "I0608 16:39:51.950593 139948276815744 learning.py:507] global step 53990: loss = 0.6519 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 54000: loss = 0.9402 (2.139 sec/step)\n",
            "I0608 16:40:13.347681 139948276815744 learning.py:507] global step 54000: loss = 0.9402 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 54010: loss = 0.7521 (2.166 sec/step)\n",
            "I0608 16:40:34.742160 139948276815744 learning.py:507] global step 54010: loss = 0.7521 (2.166 sec/step)\n",
            "INFO:tensorflow:global step 54020: loss = 1.0836 (2.141 sec/step)\n",
            "I0608 16:40:56.093338 139948276815744 learning.py:507] global step 54020: loss = 1.0836 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 54030: loss = 1.3011 (2.138 sec/step)\n",
            "I0608 16:41:17.483103 139948276815744 learning.py:507] global step 54030: loss = 1.3011 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 54040: loss = 0.7968 (2.123 sec/step)\n",
            "I0608 16:41:38.824838 139948276815744 learning.py:507] global step 54040: loss = 0.7968 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 54050: loss = 0.5674 (2.109 sec/step)\n",
            "I0608 16:42:00.161670 139948276815744 learning.py:507] global step 54050: loss = 0.5674 (2.109 sec/step)\n",
            "INFO:tensorflow:global step 54060: loss = 1.4878 (2.153 sec/step)\n",
            "I0608 16:42:21.532707 139948276815744 learning.py:507] global step 54060: loss = 1.4878 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 54070: loss = 1.2751 (2.151 sec/step)\n",
            "I0608 16:42:42.876228 139948276815744 learning.py:507] global step 54070: loss = 1.2751 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 54080: loss = 0.5162 (2.151 sec/step)\n",
            "I0608 16:43:04.296796 139948276815744 learning.py:507] global step 54080: loss = 0.5162 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 54090: loss = 0.9729 (2.151 sec/step)\n",
            "I0608 16:43:25.815739 139948276815744 learning.py:507] global step 54090: loss = 0.9729 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 54100: loss = 1.0172 (2.129 sec/step)\n",
            "I0608 16:43:47.094868 139948276815744 learning.py:507] global step 54100: loss = 1.0172 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 54110: loss = 0.8396 (2.139 sec/step)\n",
            "I0608 16:44:08.532905 139948276815744 learning.py:507] global step 54110: loss = 0.8396 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 54120: loss = 0.4740 (2.135 sec/step)\n",
            "I0608 16:44:29.915724 139948276815744 learning.py:507] global step 54120: loss = 0.4740 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 54130: loss = 0.7529 (2.129 sec/step)\n",
            "I0608 16:44:51.279495 139948276815744 learning.py:507] global step 54130: loss = 0.7529 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 54140: loss = 1.3778 (2.122 sec/step)\n",
            "I0608 16:45:12.616441 139948276815744 learning.py:507] global step 54140: loss = 1.3778 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 54150: loss = 0.3997 (2.153 sec/step)\n",
            "I0608 16:45:33.983032 139948276815744 learning.py:507] global step 54150: loss = 0.3997 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 54160: loss = 1.0697 (2.114 sec/step)\n",
            "I0608 16:45:55.317746 139948276815744 learning.py:507] global step 54160: loss = 1.0697 (2.114 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 54167.\n",
            "I0608 16:46:12.576165 139946056320768 supervisor.py:1050] Recording summary at step 54167.\n",
            "INFO:tensorflow:global step 54170: loss = 2.0054 (2.133 sec/step)\n",
            "I0608 16:46:17.424359 139948276815744 learning.py:507] global step 54170: loss = 2.0054 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 54180: loss = 0.5751 (2.133 sec/step)\n",
            "I0608 16:46:38.886751 139948276815744 learning.py:507] global step 54180: loss = 0.5751 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 54190: loss = 1.0812 (2.125 sec/step)\n",
            "I0608 16:47:00.260526 139948276815744 learning.py:507] global step 54190: loss = 1.0812 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 54200: loss = 0.8851 (2.177 sec/step)\n",
            "I0608 16:47:21.611938 139948276815744 learning.py:507] global step 54200: loss = 0.8851 (2.177 sec/step)\n",
            "INFO:tensorflow:global step 54210: loss = 0.6601 (2.133 sec/step)\n",
            "I0608 16:47:42.955095 139948276815744 learning.py:507] global step 54210: loss = 0.6601 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 54220: loss = 0.9813 (2.132 sec/step)\n",
            "I0608 16:48:04.428300 139948276815744 learning.py:507] global step 54220: loss = 0.9813 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 54230: loss = 0.4441 (2.153 sec/step)\n",
            "I0608 16:48:25.861294 139948276815744 learning.py:507] global step 54230: loss = 0.4441 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 54240: loss = 0.4542 (2.167 sec/step)\n",
            "I0608 16:48:47.239100 139948276815744 learning.py:507] global step 54240: loss = 0.4542 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 54250: loss = 1.0207 (2.129 sec/step)\n",
            "I0608 16:49:08.686027 139948276815744 learning.py:507] global step 54250: loss = 1.0207 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 54260: loss = 1.4186 (2.165 sec/step)\n",
            "I0608 16:49:30.108760 139948276815744 learning.py:507] global step 54260: loss = 1.4186 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 54270: loss = 1.5021 (2.133 sec/step)\n",
            "I0608 16:49:51.480361 139948276815744 learning.py:507] global step 54270: loss = 1.5021 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 54280: loss = 0.6478 (2.176 sec/step)\n",
            "I0608 16:50:12.932091 139948276815744 learning.py:507] global step 54280: loss = 0.6478 (2.176 sec/step)\n",
            "INFO:tensorflow:global step 54290: loss = 1.8580 (2.128 sec/step)\n",
            "I0608 16:50:34.383990 139948276815744 learning.py:507] global step 54290: loss = 1.8580 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 54300: loss = 0.3860 (2.128 sec/step)\n",
            "I0608 16:50:55.805853 139948276815744 learning.py:507] global step 54300: loss = 0.3860 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 54310: loss = 0.8159 (2.138 sec/step)\n",
            "I0608 16:51:17.226764 139948276815744 learning.py:507] global step 54310: loss = 0.8159 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 54320: loss = 0.6526 (2.133 sec/step)\n",
            "I0608 16:51:38.595452 139948276815744 learning.py:507] global step 54320: loss = 0.6526 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 54330: loss = 0.9044 (2.128 sec/step)\n",
            "I0608 16:51:59.951509 139948276815744 learning.py:507] global step 54330: loss = 0.9044 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 54340: loss = 1.9739 (2.135 sec/step)\n",
            "I0608 16:52:21.307649 139948276815744 learning.py:507] global step 54340: loss = 1.9739 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 54350: loss = 0.8589 (2.135 sec/step)\n",
            "I0608 16:52:42.765426 139948276815744 learning.py:507] global step 54350: loss = 0.8589 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 54360: loss = 1.1890 (2.146 sec/step)\n",
            "I0608 16:53:04.148115 139948276815744 learning.py:507] global step 54360: loss = 1.1890 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 54370: loss = 0.9773 (2.132 sec/step)\n",
            "I0608 16:53:25.528145 139948276815744 learning.py:507] global step 54370: loss = 0.9773 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 54380: loss = 0.6982 (2.139 sec/step)\n",
            "I0608 16:53:46.916772 139948276815744 learning.py:507] global step 54380: loss = 0.6982 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 54390: loss = 2.0322 (2.143 sec/step)\n",
            "I0608 16:54:08.186218 139948276815744 learning.py:507] global step 54390: loss = 2.0322 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 54400: loss = 0.9674 (2.131 sec/step)\n",
            "I0608 16:54:29.618403 139948276815744 learning.py:507] global step 54400: loss = 0.9674 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54410: loss = 0.5088 (2.114 sec/step)\n",
            "I0608 16:54:50.947581 139948276815744 learning.py:507] global step 54410: loss = 0.5088 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 54420: loss = 0.5449 (2.121 sec/step)\n",
            "I0608 16:55:12.297118 139948276815744 learning.py:507] global step 54420: loss = 0.5449 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 54430: loss = 0.7371 (2.129 sec/step)\n",
            "I0608 16:55:33.793509 139948276815744 learning.py:507] global step 54430: loss = 0.7371 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 54440: loss = 0.4553 (2.166 sec/step)\n",
            "I0608 16:55:55.148465 139948276815744 learning.py:507] global step 54440: loss = 0.4553 (2.166 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 16:56:10.997055 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 54447.\n",
            "I0608 16:56:12.978206 139946056320768 supervisor.py:1050] Recording summary at step 54447.\n",
            "INFO:tensorflow:global step 54450: loss = 1.0969 (2.233 sec/step)\n",
            "I0608 16:56:17.799982 139948276815744 learning.py:507] global step 54450: loss = 1.0969 (2.233 sec/step)\n",
            "INFO:tensorflow:global step 54460: loss = 1.4556 (2.145 sec/step)\n",
            "I0608 16:56:39.356783 139948276815744 learning.py:507] global step 54460: loss = 1.4556 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 54470: loss = 1.0091 (2.131 sec/step)\n",
            "I0608 16:57:00.715785 139948276815744 learning.py:507] global step 54470: loss = 1.0091 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54480: loss = 0.6952 (2.183 sec/step)\n",
            "I0608 16:57:22.169242 139948276815744 learning.py:507] global step 54480: loss = 0.6952 (2.183 sec/step)\n",
            "INFO:tensorflow:global step 54490: loss = 0.5820 (2.152 sec/step)\n",
            "I0608 16:57:43.698455 139948276815744 learning.py:507] global step 54490: loss = 0.5820 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 54500: loss = 1.1722 (2.128 sec/step)\n",
            "I0608 16:58:05.184021 139948276815744 learning.py:507] global step 54500: loss = 1.1722 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 54510: loss = 0.9155 (2.144 sec/step)\n",
            "I0608 16:58:26.601235 139948276815744 learning.py:507] global step 54510: loss = 0.9155 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 54520: loss = 0.6987 (2.141 sec/step)\n",
            "I0608 16:58:48.067373 139948276815744 learning.py:507] global step 54520: loss = 0.6987 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 54530: loss = 0.6850 (2.136 sec/step)\n",
            "I0608 16:59:09.517259 139948276815744 learning.py:507] global step 54530: loss = 0.6850 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 54540: loss = 0.8273 (2.143 sec/step)\n",
            "I0608 16:59:30.920667 139948276815744 learning.py:507] global step 54540: loss = 0.8273 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 54550: loss = 0.9296 (2.148 sec/step)\n",
            "I0608 16:59:52.373023 139948276815744 learning.py:507] global step 54550: loss = 0.9296 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 54560: loss = 0.8138 (2.134 sec/step)\n",
            "I0608 17:00:13.697006 139948276815744 learning.py:507] global step 54560: loss = 0.8138 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 54570: loss = 0.9111 (2.130 sec/step)\n",
            "I0608 17:00:35.138507 139948276815744 learning.py:507] global step 54570: loss = 0.9111 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 54580: loss = 0.5825 (2.167 sec/step)\n",
            "I0608 17:00:56.584110 139948276815744 learning.py:507] global step 54580: loss = 0.5825 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 54590: loss = 1.8889 (2.116 sec/step)\n",
            "I0608 17:01:17.984398 139948276815744 learning.py:507] global step 54590: loss = 1.8889 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 54600: loss = 1.1984 (2.131 sec/step)\n",
            "I0608 17:01:39.381196 139948276815744 learning.py:507] global step 54600: loss = 1.1984 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54610: loss = 0.9672 (2.106 sec/step)\n",
            "I0608 17:02:00.719171 139948276815744 learning.py:507] global step 54610: loss = 0.9672 (2.106 sec/step)\n",
            "INFO:tensorflow:global step 54620: loss = 0.7195 (2.150 sec/step)\n",
            "I0608 17:02:22.115647 139948276815744 learning.py:507] global step 54620: loss = 0.7195 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 54630: loss = 1.3300 (2.122 sec/step)\n",
            "I0608 17:02:43.419150 139948276815744 learning.py:507] global step 54630: loss = 1.3300 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 54640: loss = 0.8609 (2.136 sec/step)\n",
            "I0608 17:03:04.700475 139948276815744 learning.py:507] global step 54640: loss = 0.8609 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 54650: loss = 1.4233 (2.139 sec/step)\n",
            "I0608 17:03:26.111270 139948276815744 learning.py:507] global step 54650: loss = 1.4233 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 54660: loss = 0.8715 (2.149 sec/step)\n",
            "I0608 17:03:47.544907 139948276815744 learning.py:507] global step 54660: loss = 0.8715 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 54670: loss = 0.7883 (2.134 sec/step)\n",
            "I0608 17:04:08.920888 139948276815744 learning.py:507] global step 54670: loss = 0.7883 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 54680: loss = 1.7242 (2.134 sec/step)\n",
            "I0608 17:04:30.307290 139948276815744 learning.py:507] global step 54680: loss = 1.7242 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 54690: loss = 0.7285 (2.121 sec/step)\n",
            "I0608 17:04:51.675500 139948276815744 learning.py:507] global step 54690: loss = 0.7285 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 54700: loss = 0.6926 (2.148 sec/step)\n",
            "I0608 17:05:13.070822 139948276815744 learning.py:507] global step 54700: loss = 0.6926 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 54710: loss = 1.1951 (2.131 sec/step)\n",
            "I0608 17:05:34.398908 139948276815744 learning.py:507] global step 54710: loss = 1.1951 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54720: loss = 0.6986 (2.139 sec/step)\n",
            "I0608 17:05:55.793296 139948276815744 learning.py:507] global step 54720: loss = 0.6986 (2.139 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 54727.\n",
            "I0608 17:06:12.375480 139946056320768 supervisor.py:1050] Recording summary at step 54727.\n",
            "INFO:tensorflow:global step 54730: loss = 1.2031 (2.175 sec/step)\n",
            "I0608 17:06:17.872866 139948276815744 learning.py:507] global step 54730: loss = 1.2031 (2.175 sec/step)\n",
            "INFO:tensorflow:global step 54740: loss = 0.5621 (2.136 sec/step)\n",
            "I0608 17:06:39.285131 139948276815744 learning.py:507] global step 54740: loss = 0.5621 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 54750: loss = 0.6480 (2.120 sec/step)\n",
            "I0608 17:07:00.618154 139948276815744 learning.py:507] global step 54750: loss = 0.6480 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 54760: loss = 0.9625 (2.112 sec/step)\n",
            "I0608 17:07:21.922742 139948276815744 learning.py:507] global step 54760: loss = 0.9625 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 54770: loss = 0.6450 (2.144 sec/step)\n",
            "I0608 17:07:43.361271 139948276815744 learning.py:507] global step 54770: loss = 0.6450 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 54780: loss = 0.9944 (2.132 sec/step)\n",
            "I0608 17:08:04.701273 139948276815744 learning.py:507] global step 54780: loss = 0.9944 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 54790: loss = 0.9829 (2.126 sec/step)\n",
            "I0608 17:08:26.042624 139948276815744 learning.py:507] global step 54790: loss = 0.9829 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 54800: loss = 1.0273 (2.151 sec/step)\n",
            "I0608 17:08:47.495750 139948276815744 learning.py:507] global step 54800: loss = 1.0273 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 54810: loss = 0.5974 (2.141 sec/step)\n",
            "I0608 17:09:08.854676 139948276815744 learning.py:507] global step 54810: loss = 0.5974 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 54820: loss = 0.4621 (2.131 sec/step)\n",
            "I0608 17:09:30.262495 139948276815744 learning.py:507] global step 54820: loss = 0.4621 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54830: loss = 0.7227 (2.136 sec/step)\n",
            "I0608 17:09:51.696157 139948276815744 learning.py:507] global step 54830: loss = 0.7227 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 54840: loss = 0.4713 (2.128 sec/step)\n",
            "I0608 17:10:13.092191 139948276815744 learning.py:507] global step 54840: loss = 0.4713 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 54850: loss = 0.6273 (2.134 sec/step)\n",
            "I0608 17:10:34.532942 139948276815744 learning.py:507] global step 54850: loss = 0.6273 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 54860: loss = 0.7513 (2.121 sec/step)\n",
            "I0608 17:10:55.945620 139948276815744 learning.py:507] global step 54860: loss = 0.7513 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 54870: loss = 0.7979 (2.126 sec/step)\n",
            "I0608 17:11:17.318769 139948276815744 learning.py:507] global step 54870: loss = 0.7979 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 54880: loss = 0.7743 (2.114 sec/step)\n",
            "I0608 17:11:38.626892 139948276815744 learning.py:507] global step 54880: loss = 0.7743 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 54890: loss = 0.7620 (2.127 sec/step)\n",
            "I0608 17:12:00.003334 139948276815744 learning.py:507] global step 54890: loss = 0.7620 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 54900: loss = 1.7675 (2.148 sec/step)\n",
            "I0608 17:12:21.396005 139948276815744 learning.py:507] global step 54900: loss = 1.7675 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 54910: loss = 0.9226 (2.149 sec/step)\n",
            "I0608 17:12:42.785375 139948276815744 learning.py:507] global step 54910: loss = 0.9226 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 54920: loss = 1.1532 (2.130 sec/step)\n",
            "I0608 17:13:04.151549 139948276815744 learning.py:507] global step 54920: loss = 1.1532 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 54930: loss = 0.4915 (2.126 sec/step)\n",
            "I0608 17:13:25.427573 139948276815744 learning.py:507] global step 54930: loss = 0.4915 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 54940: loss = 1.1276 (2.141 sec/step)\n",
            "I0608 17:13:46.779384 139948276815744 learning.py:507] global step 54940: loss = 1.1276 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 54950: loss = 0.9923 (2.116 sec/step)\n",
            "I0608 17:14:08.139710 139948276815744 learning.py:507] global step 54950: loss = 0.9923 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 54960: loss = 3.9638 (2.143 sec/step)\n",
            "I0608 17:14:29.520876 139948276815744 learning.py:507] global step 54960: loss = 3.9638 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 54970: loss = 1.1556 (2.131 sec/step)\n",
            "I0608 17:14:50.923597 139948276815744 learning.py:507] global step 54970: loss = 1.1556 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 54980: loss = 0.7697 (2.138 sec/step)\n",
            "I0608 17:15:12.304247 139948276815744 learning.py:507] global step 54980: loss = 0.7697 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 54990: loss = 0.4040 (2.160 sec/step)\n",
            "I0608 17:15:33.709840 139948276815744 learning.py:507] global step 54990: loss = 0.4040 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 55000: loss = 0.8279 (2.145 sec/step)\n",
            "I0608 17:15:55.076870 139948276815744 learning.py:507] global step 55000: loss = 0.8279 (2.145 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 17:16:10.997068 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 55007.\n",
            "I0608 17:16:12.435401 139946056320768 supervisor.py:1050] Recording summary at step 55007.\n",
            "INFO:tensorflow:global step 55010: loss = 0.3571 (2.131 sec/step)\n",
            "I0608 17:16:17.528462 139948276815744 learning.py:507] global step 55010: loss = 0.3571 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55020: loss = 1.0731 (2.110 sec/step)\n",
            "I0608 17:16:38.913936 139948276815744 learning.py:507] global step 55020: loss = 1.0731 (2.110 sec/step)\n",
            "INFO:tensorflow:global step 55030: loss = 1.1181 (2.140 sec/step)\n",
            "I0608 17:17:00.326621 139948276815744 learning.py:507] global step 55030: loss = 1.1181 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 55040: loss = 0.8324 (2.142 sec/step)\n",
            "I0608 17:17:21.660437 139948276815744 learning.py:507] global step 55040: loss = 0.8324 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 55050: loss = 0.8990 (2.120 sec/step)\n",
            "I0608 17:17:42.953499 139948276815744 learning.py:507] global step 55050: loss = 0.8990 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 55060: loss = 0.7702 (2.112 sec/step)\n",
            "I0608 17:18:04.314188 139948276815744 learning.py:507] global step 55060: loss = 0.7702 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 55070: loss = 1.5435 (2.111 sec/step)\n",
            "I0608 17:18:25.628502 139948276815744 learning.py:507] global step 55070: loss = 1.5435 (2.111 sec/step)\n",
            "INFO:tensorflow:global step 55080: loss = 1.0602 (2.147 sec/step)\n",
            "I0608 17:18:46.926980 139948276815744 learning.py:507] global step 55080: loss = 1.0602 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 55090: loss = 0.8444 (2.131 sec/step)\n",
            "I0608 17:19:08.243304 139948276815744 learning.py:507] global step 55090: loss = 0.8444 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55100: loss = 0.7330 (2.139 sec/step)\n",
            "I0608 17:19:29.572368 139948276815744 learning.py:507] global step 55100: loss = 0.7330 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 55110: loss = 0.7074 (2.133 sec/step)\n",
            "I0608 17:19:51.025439 139948276815744 learning.py:507] global step 55110: loss = 0.7074 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 55120: loss = 0.9041 (2.141 sec/step)\n",
            "I0608 17:20:12.343858 139948276815744 learning.py:507] global step 55120: loss = 0.9041 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 55130: loss = 0.4568 (2.131 sec/step)\n",
            "I0608 17:20:33.641574 139948276815744 learning.py:507] global step 55130: loss = 0.4568 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55140: loss = 1.0622 (2.117 sec/step)\n",
            "I0608 17:20:55.025029 139948276815744 learning.py:507] global step 55140: loss = 1.0622 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 55150: loss = 1.0156 (2.143 sec/step)\n",
            "I0608 17:21:16.370473 139948276815744 learning.py:507] global step 55150: loss = 1.0156 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 55160: loss = 1.1942 (2.125 sec/step)\n",
            "I0608 17:21:37.709256 139948276815744 learning.py:507] global step 55160: loss = 1.1942 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 55170: loss = 1.2224 (2.147 sec/step)\n",
            "I0608 17:21:59.120559 139948276815744 learning.py:507] global step 55170: loss = 1.2224 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 55180: loss = 0.8120 (2.121 sec/step)\n",
            "I0608 17:22:20.438849 139948276815744 learning.py:507] global step 55180: loss = 0.8120 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 55190: loss = 1.1959 (2.125 sec/step)\n",
            "I0608 17:22:41.809078 139948276815744 learning.py:507] global step 55190: loss = 1.1959 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 55200: loss = 0.5937 (2.134 sec/step)\n",
            "I0608 17:23:03.167924 139948276815744 learning.py:507] global step 55200: loss = 0.5937 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 55210: loss = 0.6556 (2.115 sec/step)\n",
            "I0608 17:23:24.488062 139948276815744 learning.py:507] global step 55210: loss = 0.6556 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 55220: loss = 0.8501 (2.118 sec/step)\n",
            "I0608 17:23:45.818657 139948276815744 learning.py:507] global step 55220: loss = 0.8501 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 55230: loss = 0.3210 (2.114 sec/step)\n",
            "I0608 17:24:07.169522 139948276815744 learning.py:507] global step 55230: loss = 0.3210 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 55240: loss = 0.9889 (2.134 sec/step)\n",
            "I0608 17:24:28.567879 139948276815744 learning.py:507] global step 55240: loss = 0.9889 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 55250: loss = 0.3706 (2.158 sec/step)\n",
            "I0608 17:24:49.875223 139948276815744 learning.py:507] global step 55250: loss = 0.3706 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 55260: loss = 1.0769 (2.125 sec/step)\n",
            "I0608 17:25:11.343356 139948276815744 learning.py:507] global step 55260: loss = 1.0769 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 55270: loss = 1.0227 (2.142 sec/step)\n",
            "I0608 17:25:32.811504 139948276815744 learning.py:507] global step 55270: loss = 1.0227 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 55280: loss = 0.4564 (2.204 sec/step)\n",
            "I0608 17:25:54.324741 139948276815744 learning.py:507] global step 55280: loss = 0.4564 (2.204 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 55288.\n",
            "I0608 17:26:12.342055 139946056320768 supervisor.py:1050] Recording summary at step 55288.\n",
            "INFO:tensorflow:global step 55290: loss = 2.1802 (2.108 sec/step)\n",
            "I0608 17:26:16.379729 139948276815744 learning.py:507] global step 55290: loss = 2.1802 (2.108 sec/step)\n",
            "INFO:tensorflow:global step 55300: loss = 0.8247 (2.166 sec/step)\n",
            "I0608 17:26:37.736013 139948276815744 learning.py:507] global step 55300: loss = 0.8247 (2.166 sec/step)\n",
            "INFO:tensorflow:global step 55310: loss = 1.1806 (2.141 sec/step)\n",
            "I0608 17:26:59.176929 139948276815744 learning.py:507] global step 55310: loss = 1.1806 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 55320: loss = 1.1250 (2.123 sec/step)\n",
            "I0608 17:27:20.528224 139948276815744 learning.py:507] global step 55320: loss = 1.1250 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 55330: loss = 1.7318 (2.109 sec/step)\n",
            "I0608 17:27:41.921577 139948276815744 learning.py:507] global step 55330: loss = 1.7318 (2.109 sec/step)\n",
            "INFO:tensorflow:global step 55340: loss = 1.3123 (2.134 sec/step)\n",
            "I0608 17:28:03.289457 139948276815744 learning.py:507] global step 55340: loss = 1.3123 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 55350: loss = 0.5592 (2.131 sec/step)\n",
            "I0608 17:28:24.609246 139948276815744 learning.py:507] global step 55350: loss = 0.5592 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55360: loss = 0.7310 (2.133 sec/step)\n",
            "I0608 17:28:45.971624 139948276815744 learning.py:507] global step 55360: loss = 0.7310 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 55370: loss = 1.0128 (2.130 sec/step)\n",
            "I0608 17:29:07.381914 139948276815744 learning.py:507] global step 55370: loss = 1.0128 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 55380: loss = 0.7474 (2.151 sec/step)\n",
            "I0608 17:29:28.664736 139948276815744 learning.py:507] global step 55380: loss = 0.7474 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 55390: loss = 1.1473 (2.153 sec/step)\n",
            "I0608 17:29:50.047801 139948276815744 learning.py:507] global step 55390: loss = 1.1473 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 55400: loss = 0.3874 (2.136 sec/step)\n",
            "I0608 17:30:11.555661 139948276815744 learning.py:507] global step 55400: loss = 0.3874 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 55410: loss = 1.2520 (2.120 sec/step)\n",
            "I0608 17:30:32.939979 139948276815744 learning.py:507] global step 55410: loss = 1.2520 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 55420: loss = 1.3783 (2.149 sec/step)\n",
            "I0608 17:30:54.350561 139948276815744 learning.py:507] global step 55420: loss = 1.3783 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 55430: loss = 0.8079 (2.140 sec/step)\n",
            "I0608 17:31:15.676882 139948276815744 learning.py:507] global step 55430: loss = 0.8079 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 55440: loss = 0.8191 (2.122 sec/step)\n",
            "I0608 17:31:37.073227 139948276815744 learning.py:507] global step 55440: loss = 0.8191 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 55450: loss = 1.4258 (2.143 sec/step)\n",
            "I0608 17:31:58.431602 139948276815744 learning.py:507] global step 55450: loss = 1.4258 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 55460: loss = 0.9869 (2.136 sec/step)\n",
            "I0608 17:32:19.840647 139948276815744 learning.py:507] global step 55460: loss = 0.9869 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 55470: loss = 0.5419 (2.114 sec/step)\n",
            "I0608 17:32:41.247473 139948276815744 learning.py:507] global step 55470: loss = 0.5419 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 55480: loss = 1.5164 (2.137 sec/step)\n",
            "I0608 17:33:02.634463 139948276815744 learning.py:507] global step 55480: loss = 1.5164 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 55490: loss = 0.7494 (2.138 sec/step)\n",
            "I0608 17:33:23.933838 139948276815744 learning.py:507] global step 55490: loss = 0.7494 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 55500: loss = 0.9729 (2.129 sec/step)\n",
            "I0608 17:33:45.398363 139948276815744 learning.py:507] global step 55500: loss = 0.9729 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 55510: loss = 1.2684 (2.142 sec/step)\n",
            "I0608 17:34:06.830555 139948276815744 learning.py:507] global step 55510: loss = 1.2684 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 55520: loss = 1.6444 (2.150 sec/step)\n",
            "I0608 17:34:28.199816 139948276815744 learning.py:507] global step 55520: loss = 1.6444 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 55530: loss = 0.9031 (2.136 sec/step)\n",
            "I0608 17:34:49.565494 139948276815744 learning.py:507] global step 55530: loss = 0.9031 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 55540: loss = 0.8517 (2.170 sec/step)\n",
            "I0608 17:35:11.007926 139948276815744 learning.py:507] global step 55540: loss = 0.8517 (2.170 sec/step)\n",
            "INFO:tensorflow:global step 55550: loss = 0.6700 (2.124 sec/step)\n",
            "I0608 17:35:32.399730 139948276815744 learning.py:507] global step 55550: loss = 0.6700 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 55560: loss = 1.1343 (2.121 sec/step)\n",
            "I0608 17:35:53.779392 139948276815744 learning.py:507] global step 55560: loss = 1.1343 (2.121 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 17:36:10.997625 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 55568.\n",
            "I0608 17:36:12.483058 139946056320768 supervisor.py:1050] Recording summary at step 55568.\n",
            "INFO:tensorflow:global step 55570: loss = 0.6371 (2.126 sec/step)\n",
            "I0608 17:36:16.261257 139948276815744 learning.py:507] global step 55570: loss = 0.6371 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 55580: loss = 1.4415 (2.123 sec/step)\n",
            "I0608 17:36:37.695692 139948276815744 learning.py:507] global step 55580: loss = 1.4415 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 55590: loss = 1.0363 (2.155 sec/step)\n",
            "I0608 17:36:59.101671 139948276815744 learning.py:507] global step 55590: loss = 1.0363 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 55600: loss = 1.1272 (2.132 sec/step)\n",
            "I0608 17:37:20.480156 139948276815744 learning.py:507] global step 55600: loss = 1.1272 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 55610: loss = 0.7247 (2.128 sec/step)\n",
            "I0608 17:37:41.894782 139948276815744 learning.py:507] global step 55610: loss = 0.7247 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 55620: loss = 1.5796 (2.138 sec/step)\n",
            "I0608 17:38:03.224412 139948276815744 learning.py:507] global step 55620: loss = 1.5796 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 55630: loss = 0.8434 (2.110 sec/step)\n",
            "I0608 17:38:24.576874 139948276815744 learning.py:507] global step 55630: loss = 0.8434 (2.110 sec/step)\n",
            "INFO:tensorflow:global step 55640: loss = 1.0523 (2.130 sec/step)\n",
            "I0608 17:38:45.881529 139948276815744 learning.py:507] global step 55640: loss = 1.0523 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 55650: loss = 1.4935 (2.126 sec/step)\n",
            "I0608 17:39:07.242359 139948276815744 learning.py:507] global step 55650: loss = 1.4935 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 55660: loss = 1.1219 (2.168 sec/step)\n",
            "I0608 17:39:28.690688 139948276815744 learning.py:507] global step 55660: loss = 1.1219 (2.168 sec/step)\n",
            "INFO:tensorflow:global step 55670: loss = 1.1877 (2.145 sec/step)\n",
            "I0608 17:39:50.155951 139948276815744 learning.py:507] global step 55670: loss = 1.1877 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 55680: loss = 1.8109 (2.138 sec/step)\n",
            "I0608 17:40:11.587653 139948276815744 learning.py:507] global step 55680: loss = 1.8109 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 55690: loss = 0.8723 (2.141 sec/step)\n",
            "I0608 17:40:32.990005 139948276815744 learning.py:507] global step 55690: loss = 0.8723 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 55700: loss = 1.1131 (2.137 sec/step)\n",
            "I0608 17:40:54.420549 139948276815744 learning.py:507] global step 55700: loss = 1.1131 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 55710: loss = 2.4895 (2.132 sec/step)\n",
            "I0608 17:41:15.772330 139948276815744 learning.py:507] global step 55710: loss = 2.4895 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 55720: loss = 0.9246 (2.129 sec/step)\n",
            "I0608 17:41:37.049604 139948276815744 learning.py:507] global step 55720: loss = 0.9246 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 55730: loss = 1.0279 (2.167 sec/step)\n",
            "I0608 17:41:58.427288 139948276815744 learning.py:507] global step 55730: loss = 1.0279 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 55740: loss = 0.7079 (2.124 sec/step)\n",
            "I0608 17:42:19.778642 139948276815744 learning.py:507] global step 55740: loss = 0.7079 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 55750: loss = 1.1036 (2.157 sec/step)\n",
            "I0608 17:42:41.186689 139948276815744 learning.py:507] global step 55750: loss = 1.1036 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 55760: loss = 0.5927 (2.135 sec/step)\n",
            "I0608 17:43:02.660305 139948276815744 learning.py:507] global step 55760: loss = 0.5927 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 55770: loss = 0.3972 (2.132 sec/step)\n",
            "I0608 17:43:24.031661 139948276815744 learning.py:507] global step 55770: loss = 0.3972 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 55780: loss = 0.7239 (2.124 sec/step)\n",
            "I0608 17:43:45.355674 139948276815744 learning.py:507] global step 55780: loss = 0.7239 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 55790: loss = 0.6181 (2.139 sec/step)\n",
            "I0608 17:44:06.776611 139948276815744 learning.py:507] global step 55790: loss = 0.6181 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 55800: loss = 0.5932 (2.114 sec/step)\n",
            "I0608 17:44:28.093847 139948276815744 learning.py:507] global step 55800: loss = 0.5932 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 55810: loss = 0.5522 (2.114 sec/step)\n",
            "I0608 17:44:49.535352 139948276815744 learning.py:507] global step 55810: loss = 0.5522 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 55820: loss = 1.0034 (2.131 sec/step)\n",
            "I0608 17:45:10.828077 139948276815744 learning.py:507] global step 55820: loss = 1.0034 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55830: loss = 1.1449 (2.133 sec/step)\n",
            "I0608 17:45:32.231723 139948276815744 learning.py:507] global step 55830: loss = 1.1449 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 55840: loss = 0.4311 (2.119 sec/step)\n",
            "I0608 17:45:53.540040 139948276815744 learning.py:507] global step 55840: loss = 0.4311 (2.119 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 55848.\n",
            "I0608 17:46:12.448411 139946056320768 supervisor.py:1050] Recording summary at step 55848.\n",
            "INFO:tensorflow:global step 55850: loss = 0.7869 (2.139 sec/step)\n",
            "I0608 17:46:15.624994 139948276815744 learning.py:507] global step 55850: loss = 0.7869 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 55860: loss = 1.4904 (2.123 sec/step)\n",
            "I0608 17:46:37.193745 139948276815744 learning.py:507] global step 55860: loss = 1.4904 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 55870: loss = 1.2632 (2.140 sec/step)\n",
            "I0608 17:46:58.522970 139948276815744 learning.py:507] global step 55870: loss = 1.2632 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 55880: loss = 1.0112 (2.142 sec/step)\n",
            "I0608 17:47:19.847188 139948276815744 learning.py:507] global step 55880: loss = 1.0112 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 55890: loss = 0.9021 (2.124 sec/step)\n",
            "I0608 17:47:41.212339 139948276815744 learning.py:507] global step 55890: loss = 0.9021 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 55900: loss = 0.4245 (2.133 sec/step)\n",
            "I0608 17:48:02.592808 139948276815744 learning.py:507] global step 55900: loss = 0.4245 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 55910: loss = 1.2281 (2.128 sec/step)\n",
            "I0608 17:48:23.924682 139948276815744 learning.py:507] global step 55910: loss = 1.2281 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 55920: loss = 0.7171 (2.119 sec/step)\n",
            "I0608 17:48:45.224980 139948276815744 learning.py:507] global step 55920: loss = 0.7171 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 55930: loss = 1.0147 (2.143 sec/step)\n",
            "I0608 17:49:06.621849 139948276815744 learning.py:507] global step 55930: loss = 1.0147 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 55940: loss = 0.6105 (2.117 sec/step)\n",
            "I0608 17:49:28.006739 139948276815744 learning.py:507] global step 55940: loss = 0.6105 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 55950: loss = 0.7355 (2.112 sec/step)\n",
            "I0608 17:49:49.421026 139948276815744 learning.py:507] global step 55950: loss = 0.7355 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 55960: loss = 0.7694 (2.132 sec/step)\n",
            "I0608 17:50:10.829304 139948276815744 learning.py:507] global step 55960: loss = 0.7694 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 55970: loss = 1.0175 (2.133 sec/step)\n",
            "I0608 17:50:32.205493 139948276815744 learning.py:507] global step 55970: loss = 1.0175 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 55980: loss = 0.7011 (2.131 sec/step)\n",
            "I0608 17:50:53.566759 139948276815744 learning.py:507] global step 55980: loss = 0.7011 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 55990: loss = 0.8356 (2.125 sec/step)\n",
            "I0608 17:51:14.926070 139948276815744 learning.py:507] global step 55990: loss = 0.8356 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 56000: loss = 1.0089 (2.137 sec/step)\n",
            "I0608 17:51:36.313234 139948276815744 learning.py:507] global step 56000: loss = 1.0089 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 56010: loss = 1.1583 (2.140 sec/step)\n",
            "I0608 17:51:57.651876 139948276815744 learning.py:507] global step 56010: loss = 1.1583 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 56020: loss = 0.8519 (2.122 sec/step)\n",
            "I0608 17:52:18.966777 139948276815744 learning.py:507] global step 56020: loss = 0.8519 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 56030: loss = 0.8751 (2.142 sec/step)\n",
            "I0608 17:52:40.283874 139948276815744 learning.py:507] global step 56030: loss = 0.8751 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 56040: loss = 0.8453 (2.124 sec/step)\n",
            "I0608 17:53:01.645208 139948276815744 learning.py:507] global step 56040: loss = 0.8453 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 56050: loss = 2.4866 (2.115 sec/step)\n",
            "I0608 17:53:22.943419 139948276815744 learning.py:507] global step 56050: loss = 2.4866 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 56060: loss = 1.0455 (2.114 sec/step)\n",
            "I0608 17:53:44.301354 139948276815744 learning.py:507] global step 56060: loss = 1.0455 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 56070: loss = 0.9597 (2.125 sec/step)\n",
            "I0608 17:54:05.627682 139948276815744 learning.py:507] global step 56070: loss = 0.9597 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 56080: loss = 1.2581 (2.120 sec/step)\n",
            "I0608 17:54:26.908693 139948276815744 learning.py:507] global step 56080: loss = 1.2581 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 56090: loss = 0.9156 (2.114 sec/step)\n",
            "I0608 17:54:48.171644 139948276815744 learning.py:507] global step 56090: loss = 0.9156 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 56100: loss = 2.0674 (2.127 sec/step)\n",
            "I0608 17:55:09.527147 139948276815744 learning.py:507] global step 56100: loss = 2.0674 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 56110: loss = 0.7009 (2.160 sec/step)\n",
            "I0608 17:55:30.896373 139948276815744 learning.py:507] global step 56110: loss = 0.7009 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 56120: loss = 0.8957 (2.157 sec/step)\n",
            "I0608 17:55:52.419450 139948276815744 learning.py:507] global step 56120: loss = 0.8957 (2.157 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 17:56:10.997775 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 56128.\n",
            "I0608 17:56:12.391929 139946056320768 supervisor.py:1050] Recording summary at step 56128.\n",
            "INFO:tensorflow:global step 56130: loss = 1.4247 (2.521 sec/step)\n",
            "I0608 17:56:14.967003 139948276815744 learning.py:507] global step 56130: loss = 1.4247 (2.521 sec/step)\n",
            "INFO:tensorflow:global step 56140: loss = 0.6787 (2.143 sec/step)\n",
            "I0608 17:56:36.518472 139948276815744 learning.py:507] global step 56140: loss = 0.6787 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 56150: loss = 1.0247 (2.147 sec/step)\n",
            "I0608 17:56:57.810481 139948276815744 learning.py:507] global step 56150: loss = 1.0247 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 56160: loss = 0.5027 (2.121 sec/step)\n",
            "I0608 17:57:19.142673 139948276815744 learning.py:507] global step 56160: loss = 0.5027 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 56170: loss = 0.4071 (2.141 sec/step)\n",
            "I0608 17:57:40.587559 139948276815744 learning.py:507] global step 56170: loss = 0.4071 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56180: loss = 0.8442 (2.130 sec/step)\n",
            "I0608 17:58:01.857958 139948276815744 learning.py:507] global step 56180: loss = 0.8442 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56190: loss = 2.4001 (2.157 sec/step)\n",
            "I0608 17:58:23.212848 139948276815744 learning.py:507] global step 56190: loss = 2.4001 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 56200: loss = 1.6137 (2.132 sec/step)\n",
            "I0608 17:58:44.669198 139948276815744 learning.py:507] global step 56200: loss = 1.6137 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 56210: loss = 0.3465 (2.141 sec/step)\n",
            "I0608 17:59:06.139464 139948276815744 learning.py:507] global step 56210: loss = 0.3465 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56220: loss = 1.4535 (2.130 sec/step)\n",
            "I0608 17:59:27.516768 139948276815744 learning.py:507] global step 56220: loss = 1.4535 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56230: loss = 0.9127 (2.126 sec/step)\n",
            "I0608 17:59:48.840671 139948276815744 learning.py:507] global step 56230: loss = 0.9127 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 56240: loss = 0.5014 (2.129 sec/step)\n",
            "I0608 18:00:10.166548 139948276815744 learning.py:507] global step 56240: loss = 0.5014 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 56250: loss = 1.4554 (2.160 sec/step)\n",
            "I0608 18:00:31.567551 139948276815744 learning.py:507] global step 56250: loss = 1.4554 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 56260: loss = 1.2687 (2.139 sec/step)\n",
            "I0608 18:00:52.877743 139948276815744 learning.py:507] global step 56260: loss = 1.2687 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 56270: loss = 0.6184 (2.113 sec/step)\n",
            "I0608 18:01:14.336813 139948276815744 learning.py:507] global step 56270: loss = 0.6184 (2.113 sec/step)\n",
            "INFO:tensorflow:global step 56280: loss = 0.6638 (2.143 sec/step)\n",
            "I0608 18:01:35.742999 139948276815744 learning.py:507] global step 56280: loss = 0.6638 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 56290: loss = 0.8527 (2.141 sec/step)\n",
            "I0608 18:01:57.153878 139948276815744 learning.py:507] global step 56290: loss = 0.8527 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56300: loss = 0.5470 (2.137 sec/step)\n",
            "I0608 18:02:18.571206 139948276815744 learning.py:507] global step 56300: loss = 0.5470 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 56310: loss = 1.9481 (2.138 sec/step)\n",
            "I0608 18:02:39.923329 139948276815744 learning.py:507] global step 56310: loss = 1.9481 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 56320: loss = 1.2889 (2.136 sec/step)\n",
            "I0608 18:03:01.286605 139948276815744 learning.py:507] global step 56320: loss = 1.2889 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 56330: loss = 1.0055 (2.139 sec/step)\n",
            "I0608 18:03:22.688536 139948276815744 learning.py:507] global step 56330: loss = 1.0055 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 56340: loss = 0.7252 (2.145 sec/step)\n",
            "I0608 18:03:44.102611 139948276815744 learning.py:507] global step 56340: loss = 0.7252 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 56350: loss = 0.6448 (2.152 sec/step)\n",
            "I0608 18:04:05.554959 139948276815744 learning.py:507] global step 56350: loss = 0.6448 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 56360: loss = 1.8417 (2.154 sec/step)\n",
            "I0608 18:04:26.871402 139948276815744 learning.py:507] global step 56360: loss = 1.8417 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 56370: loss = 1.1368 (2.130 sec/step)\n",
            "I0608 18:04:48.232396 139948276815744 learning.py:507] global step 56370: loss = 1.1368 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56380: loss = 1.3001 (2.130 sec/step)\n",
            "I0608 18:05:09.721713 139948276815744 learning.py:507] global step 56380: loss = 1.3001 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56390: loss = 0.8227 (2.119 sec/step)\n",
            "I0608 18:05:31.136887 139948276815744 learning.py:507] global step 56390: loss = 0.8227 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 56400: loss = 1.2341 (2.195 sec/step)\n",
            "I0608 18:05:52.721802 139948276815744 learning.py:507] global step 56400: loss = 1.2341 (2.195 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 56408.\n",
            "I0608 18:06:12.433869 139946056320768 supervisor.py:1050] Recording summary at step 56408.\n",
            "INFO:tensorflow:global step 56410: loss = 1.5993 (2.142 sec/step)\n",
            "I0608 18:06:14.982396 139948276815744 learning.py:507] global step 56410: loss = 1.5993 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 56420: loss = 1.2139 (2.132 sec/step)\n",
            "I0608 18:06:36.408444 139948276815744 learning.py:507] global step 56420: loss = 1.2139 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 56430: loss = 2.0188 (2.174 sec/step)\n",
            "I0608 18:06:57.920750 139948276815744 learning.py:507] global step 56430: loss = 2.0188 (2.174 sec/step)\n",
            "INFO:tensorflow:global step 56440: loss = 0.8352 (2.141 sec/step)\n",
            "I0608 18:07:19.419084 139948276815744 learning.py:507] global step 56440: loss = 0.8352 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56450: loss = 0.8566 (2.160 sec/step)\n",
            "I0608 18:07:40.923226 139948276815744 learning.py:507] global step 56450: loss = 0.8566 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 56460: loss = 1.2262 (2.159 sec/step)\n",
            "I0608 18:08:02.478411 139948276815744 learning.py:507] global step 56460: loss = 1.2262 (2.159 sec/step)\n",
            "INFO:tensorflow:global step 56470: loss = 0.4913 (2.123 sec/step)\n",
            "I0608 18:08:23.891022 139948276815744 learning.py:507] global step 56470: loss = 0.4913 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 56480: loss = 0.9153 (2.126 sec/step)\n",
            "I0608 18:08:45.327081 139948276815744 learning.py:507] global step 56480: loss = 0.9153 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 56490: loss = 2.1388 (2.156 sec/step)\n",
            "I0608 18:09:06.794512 139948276815744 learning.py:507] global step 56490: loss = 2.1388 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 56500: loss = 1.3701 (2.139 sec/step)\n",
            "I0608 18:09:28.199476 139948276815744 learning.py:507] global step 56500: loss = 1.3701 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 56510: loss = 1.3830 (2.152 sec/step)\n",
            "I0608 18:09:49.670601 139948276815744 learning.py:507] global step 56510: loss = 1.3830 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 56520: loss = 0.6355 (2.146 sec/step)\n",
            "I0608 18:10:11.143729 139948276815744 learning.py:507] global step 56520: loss = 0.6355 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 56530: loss = 1.6601 (2.145 sec/step)\n",
            "I0608 18:10:32.589221 139948276815744 learning.py:507] global step 56530: loss = 1.6601 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 56540: loss = 1.1554 (2.122 sec/step)\n",
            "I0608 18:10:54.062609 139948276815744 learning.py:507] global step 56540: loss = 1.1554 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 56550: loss = 1.4570 (2.139 sec/step)\n",
            "I0608 18:11:15.539526 139948276815744 learning.py:507] global step 56550: loss = 1.4570 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 56560: loss = 1.0918 (2.128 sec/step)\n",
            "I0608 18:11:36.993271 139948276815744 learning.py:507] global step 56560: loss = 1.0918 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 56570: loss = 0.4231 (2.169 sec/step)\n",
            "I0608 18:11:58.400505 139948276815744 learning.py:507] global step 56570: loss = 0.4231 (2.169 sec/step)\n",
            "INFO:tensorflow:global step 56580: loss = 0.8197 (2.156 sec/step)\n",
            "I0608 18:12:19.982830 139948276815744 learning.py:507] global step 56580: loss = 0.8197 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 56590: loss = 0.4957 (2.141 sec/step)\n",
            "I0608 18:12:41.510274 139948276815744 learning.py:507] global step 56590: loss = 0.4957 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56600: loss = 0.8360 (2.141 sec/step)\n",
            "I0608 18:13:03.014820 139948276815744 learning.py:507] global step 56600: loss = 0.8360 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 56610: loss = 0.4794 (2.126 sec/step)\n",
            "I0608 18:13:24.496893 139948276815744 learning.py:507] global step 56610: loss = 0.4794 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 56620: loss = 0.6551 (2.145 sec/step)\n",
            "I0608 18:13:45.941726 139948276815744 learning.py:507] global step 56620: loss = 0.6551 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 56630: loss = 1.2958 (2.175 sec/step)\n",
            "I0608 18:14:07.477466 139948276815744 learning.py:507] global step 56630: loss = 1.2958 (2.175 sec/step)\n",
            "INFO:tensorflow:global step 56640: loss = 0.6779 (2.132 sec/step)\n",
            "I0608 18:14:28.912124 139948276815744 learning.py:507] global step 56640: loss = 0.6779 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 56650: loss = 1.0815 (2.144 sec/step)\n",
            "I0608 18:14:50.393922 139948276815744 learning.py:507] global step 56650: loss = 1.0815 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 56660: loss = 1.5151 (2.165 sec/step)\n",
            "I0608 18:15:11.764434 139948276815744 learning.py:507] global step 56660: loss = 1.5151 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 56670: loss = 1.3676 (2.165 sec/step)\n",
            "I0608 18:15:33.170832 139948276815744 learning.py:507] global step 56670: loss = 1.3676 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 56680: loss = 0.9046 (2.148 sec/step)\n",
            "I0608 18:15:54.684554 139948276815744 learning.py:507] global step 56680: loss = 0.9046 (2.148 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 18:16:10.997675 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 56688.\n",
            "I0608 18:16:12.673253 139946056320768 supervisor.py:1050] Recording summary at step 56688.\n",
            "INFO:tensorflow:global step 56690: loss = 1.6865 (2.180 sec/step)\n",
            "I0608 18:16:17.244192 139948276815744 learning.py:507] global step 56690: loss = 1.6865 (2.180 sec/step)\n",
            "INFO:tensorflow:global step 56700: loss = 1.2373 (2.157 sec/step)\n",
            "I0608 18:16:38.836942 139948276815744 learning.py:507] global step 56700: loss = 1.2373 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 56710: loss = 1.0952 (2.133 sec/step)\n",
            "I0608 18:17:00.234308 139948276815744 learning.py:507] global step 56710: loss = 1.0952 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 56720: loss = 1.4570 (2.153 sec/step)\n",
            "I0608 18:17:21.686239 139948276815744 learning.py:507] global step 56720: loss = 1.4570 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 56730: loss = 0.7004 (2.138 sec/step)\n",
            "I0608 18:17:43.158030 139948276815744 learning.py:507] global step 56730: loss = 0.7004 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 56740: loss = 0.8594 (2.157 sec/step)\n",
            "I0608 18:18:04.660275 139948276815744 learning.py:507] global step 56740: loss = 0.8594 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 56750: loss = 0.7530 (2.131 sec/step)\n",
            "I0608 18:18:26.148723 139948276815744 learning.py:507] global step 56750: loss = 0.7530 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 56760: loss = 0.8662 (2.155 sec/step)\n",
            "I0608 18:18:47.637179 139948276815744 learning.py:507] global step 56760: loss = 0.8662 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 56770: loss = 1.0879 (2.149 sec/step)\n",
            "I0608 18:19:09.112393 139948276815744 learning.py:507] global step 56770: loss = 1.0879 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 56780: loss = 0.7361 (2.136 sec/step)\n",
            "I0608 18:19:30.459656 139948276815744 learning.py:507] global step 56780: loss = 0.7361 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 56790: loss = 1.2640 (2.156 sec/step)\n",
            "I0608 18:19:51.939382 139948276815744 learning.py:507] global step 56790: loss = 1.2640 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 56800: loss = 0.5319 (2.186 sec/step)\n",
            "I0608 18:20:13.568453 139948276815744 learning.py:507] global step 56800: loss = 0.5319 (2.186 sec/step)\n",
            "INFO:tensorflow:global step 56810: loss = 0.8076 (2.143 sec/step)\n",
            "I0608 18:20:35.018638 139948276815744 learning.py:507] global step 56810: loss = 0.8076 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 56820: loss = 0.3631 (2.133 sec/step)\n",
            "I0608 18:20:56.405248 139948276815744 learning.py:507] global step 56820: loss = 0.3631 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 56830: loss = 0.9438 (2.158 sec/step)\n",
            "I0608 18:21:17.897503 139948276815744 learning.py:507] global step 56830: loss = 0.9438 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 56840: loss = 0.7707 (2.164 sec/step)\n",
            "I0608 18:21:39.390435 139948276815744 learning.py:507] global step 56840: loss = 0.7707 (2.164 sec/step)\n",
            "INFO:tensorflow:global step 56850: loss = 0.7725 (2.147 sec/step)\n",
            "I0608 18:22:00.843074 139948276815744 learning.py:507] global step 56850: loss = 0.7725 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 56860: loss = 1.0092 (2.129 sec/step)\n",
            "I0608 18:22:22.255420 139948276815744 learning.py:507] global step 56860: loss = 1.0092 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 56870: loss = 0.9387 (2.126 sec/step)\n",
            "I0608 18:22:43.641163 139948276815744 learning.py:507] global step 56870: loss = 0.9387 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 56880: loss = 3.0243 (2.130 sec/step)\n",
            "I0608 18:23:05.316862 139948276815744 learning.py:507] global step 56880: loss = 3.0243 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56890: loss = 0.6898 (2.120 sec/step)\n",
            "I0608 18:23:26.726217 139948276815744 learning.py:507] global step 56890: loss = 0.6898 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 56900: loss = 0.7301 (2.132 sec/step)\n",
            "I0608 18:23:48.132749 139948276815744 learning.py:507] global step 56900: loss = 0.7301 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 56910: loss = 0.5330 (2.145 sec/step)\n",
            "I0608 18:24:09.485969 139948276815744 learning.py:507] global step 56910: loss = 0.5330 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 56920: loss = 1.1370 (2.130 sec/step)\n",
            "I0608 18:24:30.927986 139948276815744 learning.py:507] global step 56920: loss = 1.1370 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 56930: loss = 0.7752 (2.133 sec/step)\n",
            "I0608 18:24:52.346408 139948276815744 learning.py:507] global step 56930: loss = 0.7752 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 56940: loss = 0.5741 (2.144 sec/step)\n",
            "I0608 18:25:13.891505 139948276815744 learning.py:507] global step 56940: loss = 0.5741 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 56950: loss = 0.5633 (2.155 sec/step)\n",
            "I0608 18:25:35.364766 139948276815744 learning.py:507] global step 56950: loss = 0.5633 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 56960: loss = 0.4011 (2.118 sec/step)\n",
            "I0608 18:25:56.778277 139948276815744 learning.py:507] global step 56960: loss = 0.4011 (2.118 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 56966.\n",
            "I0608 18:26:12.479001 139946056320768 supervisor.py:1050] Recording summary at step 56966.\n",
            "INFO:tensorflow:global step 56970: loss = 0.8707 (2.121 sec/step)\n",
            "I0608 18:26:18.924705 139948276815744 learning.py:507] global step 56970: loss = 0.8707 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 56980: loss = 3.1367 (2.154 sec/step)\n",
            "I0608 18:26:40.598249 139948276815744 learning.py:507] global step 56980: loss = 3.1367 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 56990: loss = 0.9454 (2.152 sec/step)\n",
            "I0608 18:27:02.129826 139948276815744 learning.py:507] global step 56990: loss = 0.9454 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 57000: loss = 0.6011 (2.157 sec/step)\n",
            "I0608 18:27:23.597968 139948276815744 learning.py:507] global step 57000: loss = 0.6011 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 57010: loss = 0.8503 (2.158 sec/step)\n",
            "I0608 18:27:45.155877 139948276815744 learning.py:507] global step 57010: loss = 0.8503 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 57020: loss = 0.6002 (2.147 sec/step)\n",
            "I0608 18:28:06.586575 139948276815744 learning.py:507] global step 57020: loss = 0.6002 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 57030: loss = 1.3537 (2.127 sec/step)\n",
            "I0608 18:28:27.948836 139948276815744 learning.py:507] global step 57030: loss = 1.3537 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 57040: loss = 0.8179 (2.131 sec/step)\n",
            "I0608 18:28:49.415869 139948276815744 learning.py:507] global step 57040: loss = 0.8179 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 57050: loss = 0.7753 (2.165 sec/step)\n",
            "I0608 18:29:10.871546 139948276815744 learning.py:507] global step 57050: loss = 0.7753 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 57060: loss = 0.7046 (2.130 sec/step)\n",
            "I0608 18:29:32.233226 139948276815744 learning.py:507] global step 57060: loss = 0.7046 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 57070: loss = 1.3069 (2.144 sec/step)\n",
            "I0608 18:29:53.592156 139948276815744 learning.py:507] global step 57070: loss = 1.3069 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 57080: loss = 0.5755 (2.146 sec/step)\n",
            "I0608 18:30:15.048648 139948276815744 learning.py:507] global step 57080: loss = 0.5755 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 57090: loss = 1.2836 (2.134 sec/step)\n",
            "I0608 18:30:36.445319 139948276815744 learning.py:507] global step 57090: loss = 1.2836 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 57100: loss = 2.2136 (2.146 sec/step)\n",
            "I0608 18:30:57.909496 139948276815744 learning.py:507] global step 57100: loss = 2.2136 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 57110: loss = 1.4303 (2.148 sec/step)\n",
            "I0608 18:31:19.391101 139948276815744 learning.py:507] global step 57110: loss = 1.4303 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 57120: loss = 0.7428 (2.163 sec/step)\n",
            "I0608 18:31:40.908326 139948276815744 learning.py:507] global step 57120: loss = 0.7428 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 57130: loss = 2.4936 (2.146 sec/step)\n",
            "I0608 18:32:02.365794 139948276815744 learning.py:507] global step 57130: loss = 2.4936 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 57140: loss = 0.5544 (2.149 sec/step)\n",
            "I0608 18:32:23.766294 139948276815744 learning.py:507] global step 57140: loss = 0.5544 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 57150: loss = 0.6175 (2.112 sec/step)\n",
            "I0608 18:32:45.157462 139948276815744 learning.py:507] global step 57150: loss = 0.6175 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 57160: loss = 0.6309 (2.141 sec/step)\n",
            "I0608 18:33:06.699356 139948276815744 learning.py:507] global step 57160: loss = 0.6309 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 57170: loss = 0.6119 (2.172 sec/step)\n",
            "I0608 18:33:28.223571 139948276815744 learning.py:507] global step 57170: loss = 0.6119 (2.172 sec/step)\n",
            "INFO:tensorflow:global step 57180: loss = 0.9930 (2.143 sec/step)\n",
            "I0608 18:33:49.704091 139948276815744 learning.py:507] global step 57180: loss = 0.9930 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 57190: loss = 0.9614 (2.191 sec/step)\n",
            "I0608 18:34:11.191730 139948276815744 learning.py:507] global step 57190: loss = 0.9614 (2.191 sec/step)\n",
            "INFO:tensorflow:global step 57200: loss = 1.1315 (2.138 sec/step)\n",
            "I0608 18:34:32.628044 139948276815744 learning.py:507] global step 57200: loss = 1.1315 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 57210: loss = 1.0946 (2.144 sec/step)\n",
            "I0608 18:34:54.123868 139948276815744 learning.py:507] global step 57210: loss = 1.0946 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 57220: loss = 0.9683 (2.127 sec/step)\n",
            "I0608 18:35:15.603653 139948276815744 learning.py:507] global step 57220: loss = 0.9683 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 57230: loss = 0.8899 (2.143 sec/step)\n",
            "I0608 18:35:37.098614 139948276815744 learning.py:507] global step 57230: loss = 0.8899 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 57240: loss = 0.6374 (2.134 sec/step)\n",
            "I0608 18:35:58.627317 139948276815744 learning.py:507] global step 57240: loss = 0.6374 (2.134 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 18:36:10.997816 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 57246.\n",
            "I0608 18:36:12.477456 139946056320768 supervisor.py:1050] Recording summary at step 57246.\n",
            "INFO:tensorflow:global step 57250: loss = 0.6228 (2.227 sec/step)\n",
            "I0608 18:36:21.393230 139948276815744 learning.py:507] global step 57250: loss = 0.6228 (2.227 sec/step)\n",
            "INFO:tensorflow:global step 57260: loss = 1.1153 (2.114 sec/step)\n",
            "I0608 18:36:42.904020 139948276815744 learning.py:507] global step 57260: loss = 1.1153 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 57270: loss = 0.9142 (2.177 sec/step)\n",
            "I0608 18:37:04.397289 139948276815744 learning.py:507] global step 57270: loss = 0.9142 (2.177 sec/step)\n",
            "INFO:tensorflow:global step 57280: loss = 0.8021 (2.140 sec/step)\n",
            "I0608 18:37:25.914657 139948276815744 learning.py:507] global step 57280: loss = 0.8021 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 57290: loss = 0.8092 (2.120 sec/step)\n",
            "I0608 18:37:47.308291 139948276815744 learning.py:507] global step 57290: loss = 0.8092 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 57300: loss = 2.0479 (2.132 sec/step)\n",
            "I0608 18:38:08.797794 139948276815744 learning.py:507] global step 57300: loss = 2.0479 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 57310: loss = 0.8010 (2.158 sec/step)\n",
            "I0608 18:38:30.270452 139948276815744 learning.py:507] global step 57310: loss = 0.8010 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 57320: loss = 0.8512 (2.147 sec/step)\n",
            "I0608 18:38:51.792766 139948276815744 learning.py:507] global step 57320: loss = 0.8512 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 57330: loss = 1.5995 (2.153 sec/step)\n",
            "I0608 18:39:13.227558 139948276815744 learning.py:507] global step 57330: loss = 1.5995 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 57340: loss = 0.6561 (2.155 sec/step)\n",
            "I0608 18:39:34.690105 139948276815744 learning.py:507] global step 57340: loss = 0.6561 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 57350: loss = 0.7440 (2.122 sec/step)\n",
            "I0608 18:39:56.158278 139948276815744 learning.py:507] global step 57350: loss = 0.7440 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 57360: loss = 0.9337 (2.138 sec/step)\n",
            "I0608 18:40:17.688802 139948276815744 learning.py:507] global step 57360: loss = 0.9337 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 57370: loss = 0.7858 (2.138 sec/step)\n",
            "I0608 18:40:39.150316 139948276815744 learning.py:507] global step 57370: loss = 0.7858 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 57380: loss = 1.1101 (2.135 sec/step)\n",
            "I0608 18:41:00.517386 139948276815744 learning.py:507] global step 57380: loss = 1.1101 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 57390: loss = 0.8943 (2.164 sec/step)\n",
            "I0608 18:41:22.102301 139948276815744 learning.py:507] global step 57390: loss = 0.8943 (2.164 sec/step)\n",
            "INFO:tensorflow:global step 57400: loss = 0.6659 (2.146 sec/step)\n",
            "I0608 18:41:43.585917 139948276815744 learning.py:507] global step 57400: loss = 0.6659 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 57410: loss = 1.6985 (2.155 sec/step)\n",
            "I0608 18:42:05.137926 139948276815744 learning.py:507] global step 57410: loss = 1.6985 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 57420: loss = 1.0007 (2.149 sec/step)\n",
            "I0608 18:42:26.635898 139948276815744 learning.py:507] global step 57420: loss = 1.0007 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 57430: loss = 0.8540 (2.134 sec/step)\n",
            "I0608 18:42:48.182915 139948276815744 learning.py:507] global step 57430: loss = 0.8540 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 57440: loss = 1.2601 (2.153 sec/step)\n",
            "I0608 18:43:09.745193 139948276815744 learning.py:507] global step 57440: loss = 1.2601 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 57450: loss = 1.6715 (2.151 sec/step)\n",
            "I0608 18:43:31.275274 139948276815744 learning.py:507] global step 57450: loss = 1.6715 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 57460: loss = 0.7119 (2.133 sec/step)\n",
            "I0608 18:43:52.761416 139948276815744 learning.py:507] global step 57460: loss = 0.7119 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 57470: loss = 0.7156 (2.129 sec/step)\n",
            "I0608 18:44:14.183020 139948276815744 learning.py:507] global step 57470: loss = 0.7156 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 57480: loss = 0.8867 (2.162 sec/step)\n",
            "I0608 18:44:35.555334 139948276815744 learning.py:507] global step 57480: loss = 0.8867 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 57490: loss = 0.4656 (2.133 sec/step)\n",
            "I0608 18:44:56.941485 139948276815744 learning.py:507] global step 57490: loss = 0.4656 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 57500: loss = 0.7662 (2.144 sec/step)\n",
            "I0608 18:45:18.402097 139948276815744 learning.py:507] global step 57500: loss = 0.7662 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 57510: loss = 0.6998 (2.134 sec/step)\n",
            "I0608 18:45:39.873286 139948276815744 learning.py:507] global step 57510: loss = 0.6998 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 57520: loss = 0.8418 (2.146 sec/step)\n",
            "I0608 18:46:01.398029 139948276815744 learning.py:507] global step 57520: loss = 0.8418 (2.146 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 57524.\n",
            "I0608 18:46:12.563083 139946056320768 supervisor.py:1050] Recording summary at step 57524.\n",
            "INFO:tensorflow:global step 57530: loss = 0.7509 (2.153 sec/step)\n",
            "I0608 18:46:23.688043 139948276815744 learning.py:507] global step 57530: loss = 0.7509 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 57540: loss = 1.4194 (2.157 sec/step)\n",
            "I0608 18:46:45.308807 139948276815744 learning.py:507] global step 57540: loss = 1.4194 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 57550: loss = 0.8494 (2.141 sec/step)\n",
            "I0608 18:47:06.684836 139948276815744 learning.py:507] global step 57550: loss = 0.8494 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 57560: loss = 1.4301 (2.131 sec/step)\n",
            "I0608 18:47:28.158034 139948276815744 learning.py:507] global step 57560: loss = 1.4301 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 57570: loss = 0.8687 (2.161 sec/step)\n",
            "I0608 18:47:49.627863 139948276815744 learning.py:507] global step 57570: loss = 0.8687 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 57580: loss = 1.4501 (2.192 sec/step)\n",
            "I0608 18:48:11.083234 139948276815744 learning.py:507] global step 57580: loss = 1.4501 (2.192 sec/step)\n",
            "INFO:tensorflow:global step 57590: loss = 1.2285 (2.129 sec/step)\n",
            "I0608 18:48:32.496893 139948276815744 learning.py:507] global step 57590: loss = 1.2285 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 57600: loss = 1.2841 (2.124 sec/step)\n",
            "I0608 18:48:53.979751 139948276815744 learning.py:507] global step 57600: loss = 1.2841 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 57610: loss = 0.8635 (2.160 sec/step)\n",
            "I0608 18:49:15.434670 139948276815744 learning.py:507] global step 57610: loss = 0.8635 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 57620: loss = 1.0013 (2.153 sec/step)\n",
            "I0608 18:49:36.890663 139948276815744 learning.py:507] global step 57620: loss = 1.0013 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 57630: loss = 0.5881 (2.129 sec/step)\n",
            "I0608 18:49:58.409417 139948276815744 learning.py:507] global step 57630: loss = 0.5881 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 57640: loss = 0.6690 (2.135 sec/step)\n",
            "I0608 18:50:19.873247 139948276815744 learning.py:507] global step 57640: loss = 0.6690 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 57650: loss = 0.5188 (2.156 sec/step)\n",
            "I0608 18:50:41.310487 139948276815744 learning.py:507] global step 57650: loss = 0.5188 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 57660: loss = 1.2534 (2.133 sec/step)\n",
            "I0608 18:51:02.763879 139948276815744 learning.py:507] global step 57660: loss = 1.2534 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 57670: loss = 0.6941 (2.131 sec/step)\n",
            "I0608 18:51:24.167705 139948276815744 learning.py:507] global step 57670: loss = 0.6941 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 57680: loss = 0.5237 (2.136 sec/step)\n",
            "I0608 18:51:45.566350 139948276815744 learning.py:507] global step 57680: loss = 0.5237 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 57690: loss = 1.3941 (2.158 sec/step)\n",
            "I0608 18:52:07.036747 139948276815744 learning.py:507] global step 57690: loss = 1.3941 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 57700: loss = 0.7298 (2.160 sec/step)\n",
            "I0608 18:52:28.521647 139948276815744 learning.py:507] global step 57700: loss = 0.7298 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 57710: loss = 0.8543 (2.130 sec/step)\n",
            "I0608 18:52:49.982662 139948276815744 learning.py:507] global step 57710: loss = 0.8543 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 57720: loss = 0.9100 (2.152 sec/step)\n",
            "I0608 18:53:11.467269 139948276815744 learning.py:507] global step 57720: loss = 0.9100 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 57730: loss = 1.5011 (2.156 sec/step)\n",
            "I0608 18:53:32.941954 139948276815744 learning.py:507] global step 57730: loss = 1.5011 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 57740: loss = 0.7390 (2.152 sec/step)\n",
            "I0608 18:53:54.392554 139948276815744 learning.py:507] global step 57740: loss = 0.7390 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 57750: loss = 1.0097 (2.139 sec/step)\n",
            "I0608 18:54:15.927403 139948276815744 learning.py:507] global step 57750: loss = 1.0097 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 57760: loss = 0.4957 (2.143 sec/step)\n",
            "I0608 18:54:37.399686 139948276815744 learning.py:507] global step 57760: loss = 0.4957 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 57770: loss = 2.0185 (2.163 sec/step)\n",
            "I0608 18:54:58.900478 139948276815744 learning.py:507] global step 57770: loss = 2.0185 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 57780: loss = 2.4630 (2.152 sec/step)\n",
            "I0608 18:55:20.416831 139948276815744 learning.py:507] global step 57780: loss = 2.4630 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 57790: loss = 0.5840 (2.134 sec/step)\n",
            "I0608 18:55:41.871451 139948276815744 learning.py:507] global step 57790: loss = 0.5840 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 57800: loss = 0.4414 (2.142 sec/step)\n",
            "I0608 18:56:03.325727 139948276815744 learning.py:507] global step 57800: loss = 0.4414 (2.142 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 18:56:10.997148 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 57803.\n",
            "I0608 18:56:12.414217 139946056320768 supervisor.py:1050] Recording summary at step 57803.\n",
            "INFO:tensorflow:global step 57810: loss = 1.8555 (2.157 sec/step)\n",
            "I0608 18:56:26.036934 139948276815744 learning.py:507] global step 57810: loss = 1.8555 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 57820: loss = 0.7254 (2.146 sec/step)\n",
            "I0608 18:56:47.632398 139948276815744 learning.py:507] global step 57820: loss = 0.7254 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 57830: loss = 0.7309 (2.122 sec/step)\n",
            "I0608 18:57:09.222860 139948276815744 learning.py:507] global step 57830: loss = 0.7309 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 57840: loss = 1.5129 (2.131 sec/step)\n",
            "I0608 18:57:30.615932 139948276815744 learning.py:507] global step 57840: loss = 1.5129 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 57850: loss = 1.0495 (2.141 sec/step)\n",
            "I0608 18:57:52.015291 139948276815744 learning.py:507] global step 57850: loss = 1.0495 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 57860: loss = 1.5289 (2.120 sec/step)\n",
            "I0608 18:58:13.448503 139948276815744 learning.py:507] global step 57860: loss = 1.5289 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 57870: loss = 1.1201 (2.135 sec/step)\n",
            "I0608 18:58:34.772193 139948276815744 learning.py:507] global step 57870: loss = 1.1201 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 57880: loss = 0.9259 (2.152 sec/step)\n",
            "I0608 18:58:56.238243 139948276815744 learning.py:507] global step 57880: loss = 0.9259 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 57890: loss = 0.6635 (2.118 sec/step)\n",
            "I0608 18:59:17.598126 139948276815744 learning.py:507] global step 57890: loss = 0.6635 (2.118 sec/step)\n",
            "INFO:tensorflow:global step 57900: loss = 0.5503 (2.145 sec/step)\n",
            "I0608 18:59:38.946553 139948276815744 learning.py:507] global step 57900: loss = 0.5503 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 57910: loss = 0.6716 (2.141 sec/step)\n",
            "I0608 19:00:00.311990 139948276815744 learning.py:507] global step 57910: loss = 0.6716 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 57920: loss = 0.6647 (2.150 sec/step)\n",
            "I0608 19:00:21.831994 139948276815744 learning.py:507] global step 57920: loss = 0.6647 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 57930: loss = 0.8236 (2.127 sec/step)\n",
            "I0608 19:00:43.228915 139948276815744 learning.py:507] global step 57930: loss = 0.8236 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 57940: loss = 1.1478 (2.127 sec/step)\n",
            "I0608 19:01:04.598885 139948276815744 learning.py:507] global step 57940: loss = 1.1478 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 57950: loss = 1.1986 (2.136 sec/step)\n",
            "I0608 19:01:26.081495 139948276815744 learning.py:507] global step 57950: loss = 1.1986 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 57960: loss = 0.4472 (2.144 sec/step)\n",
            "I0608 19:01:47.554975 139948276815744 learning.py:507] global step 57960: loss = 0.4472 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 57970: loss = 0.8703 (2.119 sec/step)\n",
            "I0608 19:02:08.984228 139948276815744 learning.py:507] global step 57970: loss = 0.8703 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 57980: loss = 1.0396 (2.147 sec/step)\n",
            "I0608 19:02:30.360648 139948276815744 learning.py:507] global step 57980: loss = 1.0396 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 57990: loss = 0.4670 (2.137 sec/step)\n",
            "I0608 19:02:51.929996 139948276815744 learning.py:507] global step 57990: loss = 0.4670 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 58000: loss = 1.3241 (2.139 sec/step)\n",
            "I0608 19:03:13.469826 139948276815744 learning.py:507] global step 58000: loss = 1.3241 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 58010: loss = 0.8837 (2.121 sec/step)\n",
            "I0608 19:03:35.040659 139948276815744 learning.py:507] global step 58010: loss = 0.8837 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 58020: loss = 2.1238 (2.155 sec/step)\n",
            "I0608 19:03:56.534507 139948276815744 learning.py:507] global step 58020: loss = 2.1238 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 58030: loss = 0.3768 (2.149 sec/step)\n",
            "I0608 19:04:17.922145 139948276815744 learning.py:507] global step 58030: loss = 0.3768 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 58040: loss = 1.3946 (2.125 sec/step)\n",
            "I0608 19:04:39.345005 139948276815744 learning.py:507] global step 58040: loss = 1.3946 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 58050: loss = 1.0251 (2.132 sec/step)\n",
            "I0608 19:05:00.739453 139948276815744 learning.py:507] global step 58050: loss = 1.0251 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 58060: loss = 1.2375 (2.157 sec/step)\n",
            "I0608 19:05:22.101455 139948276815744 learning.py:507] global step 58060: loss = 1.2375 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 58070: loss = 0.5961 (2.123 sec/step)\n",
            "I0608 19:05:43.490343 139948276815744 learning.py:507] global step 58070: loss = 0.5961 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 58080: loss = 1.0168 (2.130 sec/step)\n",
            "I0608 19:06:04.866836 139948276815744 learning.py:507] global step 58080: loss = 1.0168 (2.130 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 58083.\n",
            "I0608 19:06:12.420064 139946056320768 supervisor.py:1050] Recording summary at step 58083.\n",
            "INFO:tensorflow:global step 58090: loss = 0.9698 (2.162 sec/step)\n",
            "I0608 19:06:27.117608 139948276815744 learning.py:507] global step 58090: loss = 0.9698 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 58100: loss = 0.4374 (2.134 sec/step)\n",
            "I0608 19:06:48.492512 139948276815744 learning.py:507] global step 58100: loss = 0.4374 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 58110: loss = 1.1801 (2.142 sec/step)\n",
            "I0608 19:07:09.943503 139948276815744 learning.py:507] global step 58110: loss = 1.1801 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 58120: loss = 0.6924 (2.126 sec/step)\n",
            "I0608 19:07:31.350969 139948276815744 learning.py:507] global step 58120: loss = 0.6924 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 58130: loss = 0.9339 (2.129 sec/step)\n",
            "I0608 19:07:52.812818 139948276815744 learning.py:507] global step 58130: loss = 0.9339 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 58140: loss = 1.5904 (2.125 sec/step)\n",
            "I0608 19:08:14.259377 139948276815744 learning.py:507] global step 58140: loss = 1.5904 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 58150: loss = 0.8523 (2.124 sec/step)\n",
            "I0608 19:08:35.679946 139948276815744 learning.py:507] global step 58150: loss = 0.8523 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 58160: loss = 0.8202 (2.142 sec/step)\n",
            "I0608 19:08:57.086945 139948276815744 learning.py:507] global step 58160: loss = 0.8202 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 58170: loss = 0.8319 (2.149 sec/step)\n",
            "I0608 19:09:18.505587 139948276815744 learning.py:507] global step 58170: loss = 0.8319 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 58180: loss = 0.8852 (2.146 sec/step)\n",
            "I0608 19:09:39.902869 139948276815744 learning.py:507] global step 58180: loss = 0.8852 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 58190: loss = 1.4291 (2.184 sec/step)\n",
            "I0608 19:10:01.461851 139948276815744 learning.py:507] global step 58190: loss = 1.4291 (2.184 sec/step)\n",
            "INFO:tensorflow:global step 58200: loss = 1.0408 (2.153 sec/step)\n",
            "I0608 19:10:23.098877 139948276815744 learning.py:507] global step 58200: loss = 1.0408 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 58210: loss = 0.8545 (2.140 sec/step)\n",
            "I0608 19:10:44.524575 139948276815744 learning.py:507] global step 58210: loss = 0.8545 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 58220: loss = 1.0102 (2.123 sec/step)\n",
            "I0608 19:11:05.944377 139948276815744 learning.py:507] global step 58220: loss = 1.0102 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 58230: loss = 0.8075 (2.124 sec/step)\n",
            "I0608 19:11:27.353906 139948276815744 learning.py:507] global step 58230: loss = 0.8075 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 58240: loss = 0.8638 (2.115 sec/step)\n",
            "I0608 19:11:48.741645 139948276815744 learning.py:507] global step 58240: loss = 0.8638 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 58250: loss = 0.6769 (2.152 sec/step)\n",
            "I0608 19:12:10.171167 139948276815744 learning.py:507] global step 58250: loss = 0.6769 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 58260: loss = 1.4492 (2.142 sec/step)\n",
            "I0608 19:12:31.573734 139948276815744 learning.py:507] global step 58260: loss = 1.4492 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 58270: loss = 0.9664 (2.133 sec/step)\n",
            "I0608 19:12:53.007773 139948276815744 learning.py:507] global step 58270: loss = 0.9664 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 58280: loss = 1.5976 (2.131 sec/step)\n",
            "I0608 19:13:14.468706 139948276815744 learning.py:507] global step 58280: loss = 1.5976 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 58290: loss = 0.9712 (2.163 sec/step)\n",
            "I0608 19:13:35.956186 139948276815744 learning.py:507] global step 58290: loss = 0.9712 (2.163 sec/step)\n",
            "INFO:tensorflow:global step 58300: loss = 1.2016 (2.137 sec/step)\n",
            "I0608 19:13:57.338408 139948276815744 learning.py:507] global step 58300: loss = 1.2016 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 58310: loss = 0.7774 (2.155 sec/step)\n",
            "I0608 19:14:18.835226 139948276815744 learning.py:507] global step 58310: loss = 0.7774 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 58320: loss = 0.7100 (2.156 sec/step)\n",
            "I0608 19:14:40.332819 139948276815744 learning.py:507] global step 58320: loss = 0.7100 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 58330: loss = 0.5854 (2.168 sec/step)\n",
            "I0608 19:15:01.815150 139948276815744 learning.py:507] global step 58330: loss = 0.5854 (2.168 sec/step)\n",
            "INFO:tensorflow:global step 58340: loss = 0.8194 (2.128 sec/step)\n",
            "I0608 19:15:23.173302 139948276815744 learning.py:507] global step 58340: loss = 0.8194 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 58350: loss = 0.5113 (2.170 sec/step)\n",
            "I0608 19:15:44.723579 139948276815744 learning.py:507] global step 58350: loss = 0.5113 (2.170 sec/step)\n",
            "INFO:tensorflow:global step 58360: loss = 0.8472 (2.125 sec/step)\n",
            "I0608 19:16:06.119740 139948276815744 learning.py:507] global step 58360: loss = 0.8472 (2.125 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 19:16:10.997785 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 58362.\n",
            "I0608 19:16:13.085375 139946056320768 supervisor.py:1050] Recording summary at step 58362.\n",
            "INFO:tensorflow:global step 58370: loss = 0.7613 (2.127 sec/step)\n",
            "I0608 19:16:28.854344 139948276815744 learning.py:507] global step 58370: loss = 0.7613 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 58380: loss = 0.8146 (2.133 sec/step)\n",
            "I0608 19:16:50.309060 139948276815744 learning.py:507] global step 58380: loss = 0.8146 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 58390: loss = 0.8405 (2.173 sec/step)\n",
            "I0608 19:17:11.716330 139948276815744 learning.py:507] global step 58390: loss = 0.8405 (2.173 sec/step)\n",
            "INFO:tensorflow:global step 58400: loss = 1.4100 (2.143 sec/step)\n",
            "I0608 19:17:33.131423 139948276815744 learning.py:507] global step 58400: loss = 1.4100 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 58410: loss = 0.8358 (2.132 sec/step)\n",
            "I0608 19:17:54.576916 139948276815744 learning.py:507] global step 58410: loss = 0.8358 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 58420: loss = 0.7529 (2.146 sec/step)\n",
            "I0608 19:18:16.085345 139948276815744 learning.py:507] global step 58420: loss = 0.7529 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 58430: loss = 0.4352 (2.181 sec/step)\n",
            "I0608 19:18:37.645507 139948276815744 learning.py:507] global step 58430: loss = 0.4352 (2.181 sec/step)\n",
            "INFO:tensorflow:global step 58440: loss = 0.6017 (2.154 sec/step)\n",
            "I0608 19:18:59.101164 139948276815744 learning.py:507] global step 58440: loss = 0.6017 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 58450: loss = 0.7761 (2.158 sec/step)\n",
            "I0608 19:19:20.505411 139948276815744 learning.py:507] global step 58450: loss = 0.7761 (2.158 sec/step)\n",
            "INFO:tensorflow:global step 58460: loss = 0.7945 (2.136 sec/step)\n",
            "I0608 19:19:41.960119 139948276815744 learning.py:507] global step 58460: loss = 0.7945 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 58470: loss = 0.6754 (2.168 sec/step)\n",
            "I0608 19:20:03.431768 139948276815744 learning.py:507] global step 58470: loss = 0.6754 (2.168 sec/step)\n",
            "INFO:tensorflow:global step 58480: loss = 0.9048 (2.134 sec/step)\n",
            "I0608 19:20:25.011921 139948276815744 learning.py:507] global step 58480: loss = 0.9048 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 58490: loss = 0.9437 (2.144 sec/step)\n",
            "I0608 19:20:46.577753 139948276815744 learning.py:507] global step 58490: loss = 0.9437 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 58500: loss = 0.4471 (2.179 sec/step)\n",
            "I0608 19:21:08.054885 139948276815744 learning.py:507] global step 58500: loss = 0.4471 (2.179 sec/step)\n",
            "INFO:tensorflow:global step 58510: loss = 1.0133 (2.133 sec/step)\n",
            "I0608 19:21:29.440740 139948276815744 learning.py:507] global step 58510: loss = 1.0133 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 58520: loss = 1.1921 (2.120 sec/step)\n",
            "I0608 19:21:50.857732 139948276815744 learning.py:507] global step 58520: loss = 1.1921 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 58530: loss = 1.5260 (2.141 sec/step)\n",
            "I0608 19:22:12.225472 139948276815744 learning.py:507] global step 58530: loss = 1.5260 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 58540: loss = 1.1634 (2.308 sec/step)\n",
            "I0608 19:22:33.873705 139948276815744 learning.py:507] global step 58540: loss = 1.1634 (2.308 sec/step)\n",
            "INFO:tensorflow:global step 58550: loss = 0.8140 (2.135 sec/step)\n",
            "I0608 19:22:55.388219 139948276815744 learning.py:507] global step 58550: loss = 0.8140 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 58560: loss = 0.8808 (2.130 sec/step)\n",
            "I0608 19:23:16.902736 139948276815744 learning.py:507] global step 58560: loss = 0.8808 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 58570: loss = 0.5906 (2.151 sec/step)\n",
            "I0608 19:23:38.307679 139948276815744 learning.py:507] global step 58570: loss = 0.5906 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 58580: loss = 0.7195 (2.156 sec/step)\n",
            "I0608 19:23:59.752757 139948276815744 learning.py:507] global step 58580: loss = 0.7195 (2.156 sec/step)\n",
            "INFO:tensorflow:global step 58590: loss = 0.8804 (2.134 sec/step)\n",
            "I0608 19:24:21.128888 139948276815744 learning.py:507] global step 58590: loss = 0.8804 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 58600: loss = 1.2932 (2.136 sec/step)\n",
            "I0608 19:24:42.480359 139948276815744 learning.py:507] global step 58600: loss = 1.2932 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 58610: loss = 0.9592 (2.137 sec/step)\n",
            "I0608 19:25:03.911398 139948276815744 learning.py:507] global step 58610: loss = 0.9592 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 58620: loss = 1.9219 (2.143 sec/step)\n",
            "I0608 19:25:25.521052 139948276815744 learning.py:507] global step 58620: loss = 1.9219 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 58630: loss = 0.5962 (2.130 sec/step)\n",
            "I0608 19:25:46.924879 139948276815744 learning.py:507] global step 58630: loss = 0.5962 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 58640: loss = 0.7890 (2.146 sec/step)\n",
            "I0608 19:26:08.355495 139948276815744 learning.py:507] global step 58640: loss = 0.7890 (2.146 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 58641.\n",
            "I0608 19:26:12.617277 139946056320768 supervisor.py:1050] Recording summary at step 58641.\n",
            "INFO:tensorflow:global step 58650: loss = 0.5194 (2.128 sec/step)\n",
            "I0608 19:26:30.551091 139948276815744 learning.py:507] global step 58650: loss = 0.5194 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 58660: loss = 1.0745 (2.136 sec/step)\n",
            "I0608 19:26:51.965856 139948276815744 learning.py:507] global step 58660: loss = 1.0745 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 58670: loss = 0.6737 (2.152 sec/step)\n",
            "I0608 19:27:13.449806 139948276815744 learning.py:507] global step 58670: loss = 0.6737 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 58680: loss = 1.6105 (2.129 sec/step)\n",
            "I0608 19:27:34.860705 139948276815744 learning.py:507] global step 58680: loss = 1.6105 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 58690: loss = 0.6619 (2.144 sec/step)\n",
            "I0608 19:27:56.258473 139948276815744 learning.py:507] global step 58690: loss = 0.6619 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 58700: loss = 1.2374 (2.123 sec/step)\n",
            "I0608 19:28:17.642671 139948276815744 learning.py:507] global step 58700: loss = 1.2374 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 58710: loss = 0.6541 (2.176 sec/step)\n",
            "I0608 19:28:38.983563 139948276815744 learning.py:507] global step 58710: loss = 0.6541 (2.176 sec/step)\n",
            "INFO:tensorflow:global step 58720: loss = 1.3628 (2.169 sec/step)\n",
            "I0608 19:29:00.547825 139948276815744 learning.py:507] global step 58720: loss = 1.3628 (2.169 sec/step)\n",
            "INFO:tensorflow:global step 58730: loss = 0.5149 (2.143 sec/step)\n",
            "I0608 19:29:22.083771 139948276815744 learning.py:507] global step 58730: loss = 0.5149 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 58740: loss = 0.7854 (2.146 sec/step)\n",
            "I0608 19:29:43.546534 139948276815744 learning.py:507] global step 58740: loss = 0.7854 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 58750: loss = 0.6665 (2.116 sec/step)\n",
            "I0608 19:30:04.856551 139948276815744 learning.py:507] global step 58750: loss = 0.6665 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 58760: loss = 0.7967 (2.162 sec/step)\n",
            "I0608 19:30:26.313541 139948276815744 learning.py:507] global step 58760: loss = 0.7967 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 58770: loss = 0.9551 (2.132 sec/step)\n",
            "I0608 19:30:47.811461 139948276815744 learning.py:507] global step 58770: loss = 0.9551 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 58780: loss = 2.4163 (2.134 sec/step)\n",
            "I0608 19:31:09.246320 139948276815744 learning.py:507] global step 58780: loss = 2.4163 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 58790: loss = 0.4388 (2.122 sec/step)\n",
            "I0608 19:31:30.690304 139948276815744 learning.py:507] global step 58790: loss = 0.4388 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 58800: loss = 1.2197 (2.161 sec/step)\n",
            "I0608 19:31:52.151746 139948276815744 learning.py:507] global step 58800: loss = 1.2197 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 58810: loss = 0.8774 (2.162 sec/step)\n",
            "I0608 19:32:13.593410 139948276815744 learning.py:507] global step 58810: loss = 0.8774 (2.162 sec/step)\n",
            "INFO:tensorflow:global step 58820: loss = 0.9386 (2.129 sec/step)\n",
            "I0608 19:32:34.998247 139948276815744 learning.py:507] global step 58820: loss = 0.9386 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 58830: loss = 0.6251 (2.143 sec/step)\n",
            "I0608 19:32:56.413070 139948276815744 learning.py:507] global step 58830: loss = 0.6251 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 58840: loss = 1.0936 (2.120 sec/step)\n",
            "I0608 19:33:17.850216 139948276815744 learning.py:507] global step 58840: loss = 1.0936 (2.120 sec/step)\n",
            "INFO:tensorflow:global step 58850: loss = 0.5848 (2.169 sec/step)\n",
            "I0608 19:33:39.291959 139948276815744 learning.py:507] global step 58850: loss = 0.5848 (2.169 sec/step)\n",
            "INFO:tensorflow:global step 58860: loss = 1.0665 (2.149 sec/step)\n",
            "I0608 19:34:00.654546 139948276815744 learning.py:507] global step 58860: loss = 1.0665 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 58870: loss = 0.8894 (2.132 sec/step)\n",
            "I0608 19:34:22.184278 139948276815744 learning.py:507] global step 58870: loss = 0.8894 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 58880: loss = 1.5256 (2.144 sec/step)\n",
            "I0608 19:34:43.647316 139948276815744 learning.py:507] global step 58880: loss = 1.5256 (2.144 sec/step)\n",
            "INFO:tensorflow:global step 58890: loss = 0.6614 (2.138 sec/step)\n",
            "I0608 19:35:05.040359 139948276815744 learning.py:507] global step 58890: loss = 0.6614 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 58900: loss = 2.1018 (2.123 sec/step)\n",
            "I0608 19:35:26.429664 139948276815744 learning.py:507] global step 58900: loss = 2.1018 (2.123 sec/step)\n",
            "INFO:tensorflow:global step 58910: loss = 0.8296 (2.160 sec/step)\n",
            "I0608 19:35:47.928643 139948276815744 learning.py:507] global step 58910: loss = 0.8296 (2.160 sec/step)\n",
            "INFO:tensorflow:global step 58920: loss = 0.6200 (2.139 sec/step)\n",
            "I0608 19:36:09.383529 139948276815744 learning.py:507] global step 58920: loss = 0.6200 (2.139 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 19:36:10.997070 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 58921.\n",
            "I0608 19:36:12.933277 139946056320768 supervisor.py:1050] Recording summary at step 58921.\n",
            "INFO:tensorflow:global step 58930: loss = 0.9455 (2.117 sec/step)\n",
            "I0608 19:36:32.145008 139948276815744 learning.py:507] global step 58930: loss = 0.9455 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 58940: loss = 0.5390 (2.114 sec/step)\n",
            "I0608 19:36:53.534842 139948276815744 learning.py:507] global step 58940: loss = 0.5390 (2.114 sec/step)\n",
            "INFO:tensorflow:global step 58950: loss = 1.5358 (2.138 sec/step)\n",
            "I0608 19:37:15.005505 139948276815744 learning.py:507] global step 58950: loss = 1.5358 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 58960: loss = 0.8497 (2.146 sec/step)\n",
            "I0608 19:37:36.477861 139948276815744 learning.py:507] global step 58960: loss = 0.8497 (2.146 sec/step)\n",
            "INFO:tensorflow:global step 58970: loss = 0.4295 (2.124 sec/step)\n",
            "I0608 19:37:57.919991 139948276815744 learning.py:507] global step 58970: loss = 0.4295 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 58980: loss = 1.0204 (2.137 sec/step)\n",
            "I0608 19:38:19.420972 139948276815744 learning.py:507] global step 58980: loss = 1.0204 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 58990: loss = 1.0021 (2.173 sec/step)\n",
            "I0608 19:38:40.878369 139948276815744 learning.py:507] global step 58990: loss = 1.0021 (2.173 sec/step)\n",
            "INFO:tensorflow:global step 59000: loss = 1.7841 (2.133 sec/step)\n",
            "I0608 19:39:02.281728 139948276815744 learning.py:507] global step 59000: loss = 1.7841 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 59010: loss = 0.7617 (2.203 sec/step)\n",
            "I0608 19:39:23.882490 139948276815744 learning.py:507] global step 59010: loss = 0.7617 (2.203 sec/step)\n",
            "INFO:tensorflow:global step 59020: loss = 0.8982 (2.127 sec/step)\n",
            "I0608 19:39:45.299283 139948276815744 learning.py:507] global step 59020: loss = 0.8982 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 59030: loss = 0.7523 (2.138 sec/step)\n",
            "I0608 19:40:06.759230 139948276815744 learning.py:507] global step 59030: loss = 0.7523 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 59040: loss = 0.3268 (2.168 sec/step)\n",
            "I0608 19:40:28.192248 139948276815744 learning.py:507] global step 59040: loss = 0.3268 (2.168 sec/step)\n",
            "INFO:tensorflow:global step 59050: loss = 0.6705 (2.167 sec/step)\n",
            "I0608 19:40:49.598572 139948276815744 learning.py:507] global step 59050: loss = 0.6705 (2.167 sec/step)\n",
            "INFO:tensorflow:global step 59060: loss = 0.5370 (2.152 sec/step)\n",
            "I0608 19:41:11.019017 139948276815744 learning.py:507] global step 59060: loss = 0.5370 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 59070: loss = 1.2371 (2.147 sec/step)\n",
            "I0608 19:41:32.384465 139948276815744 learning.py:507] global step 59070: loss = 1.2371 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 59080: loss = 0.6937 (2.125 sec/step)\n",
            "I0608 19:41:53.832564 139948276815744 learning.py:507] global step 59080: loss = 0.6937 (2.125 sec/step)\n",
            "INFO:tensorflow:global step 59090: loss = 0.7295 (2.134 sec/step)\n",
            "I0608 19:42:15.252001 139948276815744 learning.py:507] global step 59090: loss = 0.7295 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59100: loss = 0.6041 (2.143 sec/step)\n",
            "I0608 19:42:36.809661 139948276815744 learning.py:507] global step 59100: loss = 0.6041 (2.143 sec/step)\n",
            "INFO:tensorflow:global step 59110: loss = 0.6631 (2.129 sec/step)\n",
            "I0608 19:42:58.278547 139948276815744 learning.py:507] global step 59110: loss = 0.6631 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 59120: loss = 0.9025 (2.141 sec/step)\n",
            "I0608 19:43:19.726243 139948276815744 learning.py:507] global step 59120: loss = 0.9025 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 59130: loss = 0.5436 (2.150 sec/step)\n",
            "I0608 19:43:41.212562 139948276815744 learning.py:507] global step 59130: loss = 0.5436 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 59140: loss = 0.9854 (2.145 sec/step)\n",
            "I0608 19:44:02.650255 139948276815744 learning.py:507] global step 59140: loss = 0.9854 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 59150: loss = 0.8939 (2.161 sec/step)\n",
            "I0608 19:44:24.099206 139948276815744 learning.py:507] global step 59150: loss = 0.8939 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 59160: loss = 0.6673 (2.132 sec/step)\n",
            "I0608 19:44:45.626921 139948276815744 learning.py:507] global step 59160: loss = 0.6673 (2.132 sec/step)\n",
            "INFO:tensorflow:global step 59170: loss = 1.7641 (2.128 sec/step)\n",
            "I0608 19:45:07.014577 139948276815744 learning.py:507] global step 59170: loss = 1.7641 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 59180: loss = 1.5716 (2.140 sec/step)\n",
            "I0608 19:45:28.357319 139948276815744 learning.py:507] global step 59180: loss = 1.5716 (2.140 sec/step)\n",
            "INFO:tensorflow:global step 59190: loss = 1.0343 (2.136 sec/step)\n",
            "I0608 19:45:49.817540 139948276815744 learning.py:507] global step 59190: loss = 1.0343 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 59200: loss = 0.6760 (2.372 sec/step)\n",
            "I0608 19:46:11.492547 139948276815744 learning.py:507] global step 59200: loss = 0.6760 (2.372 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 59200.\n",
            "I0608 19:46:12.473352 139946056320768 supervisor.py:1050] Recording summary at step 59200.\n",
            "INFO:tensorflow:global step 59210: loss = 0.6262 (2.157 sec/step)\n",
            "I0608 19:46:33.492806 139948276815744 learning.py:507] global step 59210: loss = 0.6262 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 59220: loss = 1.3947 (2.126 sec/step)\n",
            "I0608 19:46:54.961246 139948276815744 learning.py:507] global step 59220: loss = 1.3947 (2.126 sec/step)\n",
            "INFO:tensorflow:global step 59230: loss = 0.6658 (2.136 sec/step)\n",
            "I0608 19:47:16.309562 139948276815744 learning.py:507] global step 59230: loss = 0.6658 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 59240: loss = 0.5609 (2.129 sec/step)\n",
            "I0608 19:47:37.709024 139948276815744 learning.py:507] global step 59240: loss = 0.5609 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 59250: loss = 1.2040 (2.147 sec/step)\n",
            "I0608 19:47:59.147705 139948276815744 learning.py:507] global step 59250: loss = 1.2040 (2.147 sec/step)\n",
            "INFO:tensorflow:global step 59260: loss = 0.3737 (2.166 sec/step)\n",
            "I0608 19:48:20.617786 139948276815744 learning.py:507] global step 59260: loss = 0.3737 (2.166 sec/step)\n",
            "INFO:tensorflow:global step 59270: loss = 1.9403 (2.148 sec/step)\n",
            "I0608 19:48:42.085367 139948276815744 learning.py:507] global step 59270: loss = 1.9403 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 59280: loss = 0.5618 (2.135 sec/step)\n",
            "I0608 19:49:03.637656 139948276815744 learning.py:507] global step 59280: loss = 0.5618 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 59290: loss = 0.9206 (2.149 sec/step)\n",
            "I0608 19:49:25.131499 139948276815744 learning.py:507] global step 59290: loss = 0.9206 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 59300: loss = 0.6191 (2.153 sec/step)\n",
            "I0608 19:49:46.662701 139948276815744 learning.py:507] global step 59300: loss = 0.6191 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 59310: loss = 0.7265 (2.129 sec/step)\n",
            "I0608 19:50:08.159560 139948276815744 learning.py:507] global step 59310: loss = 0.7265 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 59320: loss = 0.8279 (2.134 sec/step)\n",
            "I0608 19:50:29.650617 139948276815744 learning.py:507] global step 59320: loss = 0.8279 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59330: loss = 1.1320 (2.154 sec/step)\n",
            "I0608 19:50:51.153177 139948276815744 learning.py:507] global step 59330: loss = 1.1320 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 59340: loss = 0.9762 (2.145 sec/step)\n",
            "I0608 19:51:12.707940 139948276815744 learning.py:507] global step 59340: loss = 0.9762 (2.145 sec/step)\n",
            "INFO:tensorflow:global step 59350: loss = 0.9872 (2.181 sec/step)\n",
            "I0608 19:51:34.286427 139948276815744 learning.py:507] global step 59350: loss = 0.9872 (2.181 sec/step)\n",
            "INFO:tensorflow:global step 59360: loss = 0.7385 (2.161 sec/step)\n",
            "I0608 19:51:55.789719 139948276815744 learning.py:507] global step 59360: loss = 0.7385 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 59370: loss = 0.6616 (2.166 sec/step)\n",
            "I0608 19:52:17.322329 139948276815744 learning.py:507] global step 59370: loss = 0.6616 (2.166 sec/step)\n",
            "INFO:tensorflow:global step 59380: loss = 0.4256 (2.131 sec/step)\n",
            "I0608 19:52:38.815040 139948276815744 learning.py:507] global step 59380: loss = 0.4256 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 59390: loss = 0.7613 (2.133 sec/step)\n",
            "I0608 19:53:00.309929 139948276815744 learning.py:507] global step 59390: loss = 0.7613 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 59400: loss = 1.4718 (2.142 sec/step)\n",
            "I0608 19:53:21.812657 139948276815744 learning.py:507] global step 59400: loss = 1.4718 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 59410: loss = 0.5305 (2.159 sec/step)\n",
            "I0608 19:53:43.329164 139948276815744 learning.py:507] global step 59410: loss = 0.5305 (2.159 sec/step)\n",
            "INFO:tensorflow:global step 59420: loss = 0.7708 (2.136 sec/step)\n",
            "I0608 19:54:04.736259 139948276815744 learning.py:507] global step 59420: loss = 0.7708 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 59430: loss = 1.2795 (2.137 sec/step)\n",
            "I0608 19:54:26.157125 139948276815744 learning.py:507] global step 59430: loss = 1.2795 (2.137 sec/step)\n",
            "INFO:tensorflow:global step 59440: loss = 0.6897 (2.134 sec/step)\n",
            "I0608 19:54:47.671800 139948276815744 learning.py:507] global step 59440: loss = 0.6897 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59450: loss = 0.7364 (2.117 sec/step)\n",
            "I0608 19:55:09.144320 139948276815744 learning.py:507] global step 59450: loss = 0.7364 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 59460: loss = 0.4929 (2.149 sec/step)\n",
            "I0608 19:55:30.583681 139948276815744 learning.py:507] global step 59460: loss = 0.4929 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 59470: loss = 0.6601 (2.141 sec/step)\n",
            "I0608 19:55:52.037923 139948276815744 learning.py:507] global step 59470: loss = 0.6601 (2.141 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "I0608 19:56:10.997153 139946073106176 supervisor.py:1117] Saving checkpoint to path /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 59479.\n",
            "I0608 19:56:13.049131 139946056320768 supervisor.py:1050] Recording summary at step 59479.\n",
            "INFO:tensorflow:global step 59480: loss = 0.9768 (2.789 sec/step)\n",
            "I0608 19:56:14.696707 139948276815744 learning.py:507] global step 59480: loss = 0.9768 (2.789 sec/step)\n",
            "INFO:tensorflow:global step 59490: loss = 1.0172 (2.124 sec/step)\n",
            "I0608 19:56:36.298507 139948276815744 learning.py:507] global step 59490: loss = 1.0172 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 59500: loss = 0.4962 (2.138 sec/step)\n",
            "I0608 19:56:57.851382 139948276815744 learning.py:507] global step 59500: loss = 0.4962 (2.138 sec/step)\n",
            "INFO:tensorflow:global step 59510: loss = 0.9704 (2.149 sec/step)\n",
            "I0608 19:57:19.232078 139948276815744 learning.py:507] global step 59510: loss = 0.9704 (2.149 sec/step)\n",
            "INFO:tensorflow:global step 59520: loss = 0.4222 (2.139 sec/step)\n",
            "I0608 19:57:40.630836 139948276815744 learning.py:507] global step 59520: loss = 0.4222 (2.139 sec/step)\n",
            "INFO:tensorflow:global step 59530: loss = 0.4084 (2.171 sec/step)\n",
            "I0608 19:58:02.053055 139948276815744 learning.py:507] global step 59530: loss = 0.4084 (2.171 sec/step)\n",
            "INFO:tensorflow:global step 59540: loss = 1.1185 (2.131 sec/step)\n",
            "I0608 19:58:23.476498 139948276815744 learning.py:507] global step 59540: loss = 1.1185 (2.131 sec/step)\n",
            "INFO:tensorflow:global step 59550: loss = 0.5910 (2.165 sec/step)\n",
            "I0608 19:58:44.934053 139948276815744 learning.py:507] global step 59550: loss = 0.5910 (2.165 sec/step)\n",
            "INFO:tensorflow:global step 59560: loss = 1.0575 (2.159 sec/step)\n",
            "I0608 19:59:06.418856 139948276815744 learning.py:507] global step 59560: loss = 1.0575 (2.159 sec/step)\n",
            "INFO:tensorflow:global step 59570: loss = 0.8644 (2.136 sec/step)\n",
            "I0608 19:59:27.859761 139948276815744 learning.py:507] global step 59570: loss = 0.8644 (2.136 sec/step)\n",
            "INFO:tensorflow:global step 59580: loss = 0.7609 (2.134 sec/step)\n",
            "I0608 19:59:49.402264 139948276815744 learning.py:507] global step 59580: loss = 0.7609 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59590: loss = 1.1940 (2.161 sec/step)\n",
            "I0608 20:00:10.913572 139948276815744 learning.py:507] global step 59590: loss = 1.1940 (2.161 sec/step)\n",
            "INFO:tensorflow:global step 59600: loss = 1.4097 (2.150 sec/step)\n",
            "I0608 20:00:32.352431 139948276815744 learning.py:507] global step 59600: loss = 1.4097 (2.150 sec/step)\n",
            "INFO:tensorflow:global step 59610: loss = 0.8318 (2.117 sec/step)\n",
            "I0608 20:00:53.740483 139948276815744 learning.py:507] global step 59610: loss = 0.8318 (2.117 sec/step)\n",
            "INFO:tensorflow:global step 59620: loss = 0.8064 (2.122 sec/step)\n",
            "I0608 20:01:15.082196 139948276815744 learning.py:507] global step 59620: loss = 0.8064 (2.122 sec/step)\n",
            "INFO:tensorflow:global step 59630: loss = 1.3879 (2.159 sec/step)\n",
            "I0608 20:01:36.427252 139948276815744 learning.py:507] global step 59630: loss = 1.3879 (2.159 sec/step)\n",
            "INFO:tensorflow:global step 59640: loss = 0.8846 (2.168 sec/step)\n",
            "I0608 20:01:57.875386 139948276815744 learning.py:507] global step 59640: loss = 0.8846 (2.168 sec/step)\n",
            "INFO:tensorflow:global step 59650: loss = 1.1707 (2.124 sec/step)\n",
            "I0608 20:02:19.243794 139948276815744 learning.py:507] global step 59650: loss = 1.1707 (2.124 sec/step)\n",
            "INFO:tensorflow:global step 59660: loss = 0.6347 (2.151 sec/step)\n",
            "I0608 20:02:40.945214 139948276815744 learning.py:507] global step 59660: loss = 0.6347 (2.151 sec/step)\n",
            "INFO:tensorflow:global step 59670: loss = 0.6660 (2.152 sec/step)\n",
            "I0608 20:03:02.391239 139948276815744 learning.py:507] global step 59670: loss = 0.6660 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 59680: loss = 0.7208 (2.130 sec/step)\n",
            "I0608 20:03:23.793162 139948276815744 learning.py:507] global step 59680: loss = 0.7208 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 59690: loss = 0.9532 (2.121 sec/step)\n",
            "I0608 20:03:45.154401 139948276815744 learning.py:507] global step 59690: loss = 0.9532 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 59700: loss = 0.9278 (2.154 sec/step)\n",
            "I0608 20:04:06.546527 139948276815744 learning.py:507] global step 59700: loss = 0.9278 (2.154 sec/step)\n",
            "INFO:tensorflow:global step 59710: loss = 0.7235 (2.148 sec/step)\n",
            "I0608 20:04:27.934889 139948276815744 learning.py:507] global step 59710: loss = 0.7235 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 59720: loss = 0.4487 (2.130 sec/step)\n",
            "I0608 20:04:49.359580 139948276815744 learning.py:507] global step 59720: loss = 0.4487 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 59730: loss = 0.8629 (2.134 sec/step)\n",
            "I0608 20:05:10.841092 139948276815744 learning.py:507] global step 59730: loss = 0.8629 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59740: loss = 1.4785 (2.134 sec/step)\n",
            "I0608 20:05:32.314804 139948276815744 learning.py:507] global step 59740: loss = 1.4785 (2.134 sec/step)\n",
            "INFO:tensorflow:global step 59750: loss = 1.1140 (2.134 sec/step)\n",
            "I0608 20:05:53.784726 139948276815744 learning.py:507] global step 59750: loss = 1.1140 (2.134 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 59758.\n",
            "I0608 20:06:12.639172 139946056320768 supervisor.py:1050] Recording summary at step 59758.\n",
            "INFO:tensorflow:global step 59760: loss = 1.0966 (2.129 sec/step)\n",
            "I0608 20:06:16.054760 139948276815744 learning.py:507] global step 59760: loss = 1.0966 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 59770: loss = 0.3767 (2.152 sec/step)\n",
            "I0608 20:06:37.475892 139948276815744 learning.py:507] global step 59770: loss = 0.3767 (2.152 sec/step)\n",
            "INFO:tensorflow:global step 59780: loss = 0.9745 (2.121 sec/step)\n",
            "I0608 20:06:58.829775 139948276815744 learning.py:507] global step 59780: loss = 0.9745 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 59790: loss = 0.9072 (2.127 sec/step)\n",
            "I0608 20:07:20.247381 139948276815744 learning.py:507] global step 59790: loss = 0.9072 (2.127 sec/step)\n",
            "INFO:tensorflow:global step 59800: loss = 0.8839 (2.148 sec/step)\n",
            "I0608 20:07:41.637377 139948276815744 learning.py:507] global step 59800: loss = 0.8839 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 59810: loss = 0.7434 (2.175 sec/step)\n",
            "I0608 20:08:03.241959 139948276815744 learning.py:507] global step 59810: loss = 0.7434 (2.175 sec/step)\n",
            "INFO:tensorflow:global step 59820: loss = 1.0969 (2.153 sec/step)\n",
            "I0608 20:08:24.743003 139948276815744 learning.py:507] global step 59820: loss = 1.0969 (2.153 sec/step)\n",
            "INFO:tensorflow:global step 59830: loss = 1.1964 (2.157 sec/step)\n",
            "I0608 20:08:46.187819 139948276815744 learning.py:507] global step 59830: loss = 1.1964 (2.157 sec/step)\n",
            "INFO:tensorflow:global step 59840: loss = 1.1355 (2.128 sec/step)\n",
            "I0608 20:09:07.563637 139948276815744 learning.py:507] global step 59840: loss = 1.1355 (2.128 sec/step)\n",
            "INFO:tensorflow:global step 59850: loss = 2.4127 (2.121 sec/step)\n",
            "I0608 20:09:28.923277 139948276815744 learning.py:507] global step 59850: loss = 2.4127 (2.121 sec/step)\n",
            "INFO:tensorflow:global step 59860: loss = 1.3714 (2.141 sec/step)\n",
            "I0608 20:09:50.332144 139948276815744 learning.py:507] global step 59860: loss = 1.3714 (2.141 sec/step)\n",
            "INFO:tensorflow:global step 59870: loss = 1.0005 (2.155 sec/step)\n",
            "I0608 20:10:11.851423 139948276815744 learning.py:507] global step 59870: loss = 1.0005 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 59880: loss = 1.3657 (2.135 sec/step)\n",
            "I0608 20:10:33.284599 139948276815744 learning.py:507] global step 59880: loss = 1.3657 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 59890: loss = 0.8316 (2.115 sec/step)\n",
            "I0608 20:10:54.790286 139948276815744 learning.py:507] global step 59890: loss = 0.8316 (2.115 sec/step)\n",
            "INFO:tensorflow:global step 59900: loss = 0.5903 (2.148 sec/step)\n",
            "I0608 20:11:16.311796 139948276815744 learning.py:507] global step 59900: loss = 0.5903 (2.148 sec/step)\n",
            "INFO:tensorflow:global step 59910: loss = 1.0513 (2.142 sec/step)\n",
            "I0608 20:11:37.738048 139948276815744 learning.py:507] global step 59910: loss = 1.0513 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 59920: loss = 1.1901 (2.133 sec/step)\n",
            "I0608 20:11:59.199424 139948276815744 learning.py:507] global step 59920: loss = 1.1901 (2.133 sec/step)\n",
            "INFO:tensorflow:global step 59930: loss = 0.7574 (2.116 sec/step)\n",
            "I0608 20:12:20.637039 139948276815744 learning.py:507] global step 59930: loss = 0.7574 (2.116 sec/step)\n",
            "INFO:tensorflow:global step 59940: loss = 0.6411 (2.185 sec/step)\n",
            "I0608 20:12:42.099667 139948276815744 learning.py:507] global step 59940: loss = 0.6411 (2.185 sec/step)\n",
            "INFO:tensorflow:global step 59950: loss = 0.8752 (2.142 sec/step)\n",
            "I0608 20:13:03.594346 139948276815744 learning.py:507] global step 59950: loss = 0.8752 (2.142 sec/step)\n",
            "INFO:tensorflow:global step 59960: loss = 0.9743 (2.119 sec/step)\n",
            "I0608 20:13:24.958929 139948276815744 learning.py:507] global step 59960: loss = 0.9743 (2.119 sec/step)\n",
            "INFO:tensorflow:global step 59970: loss = 0.3175 (2.129 sec/step)\n",
            "I0608 20:13:46.307990 139948276815744 learning.py:507] global step 59970: loss = 0.3175 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 59980: loss = 1.8597 (2.135 sec/step)\n",
            "I0608 20:14:07.645888 139948276815744 learning.py:507] global step 59980: loss = 1.8597 (2.135 sec/step)\n",
            "INFO:tensorflow:global step 59990: loss = 1.3495 (2.129 sec/step)\n",
            "I0608 20:14:29.020064 139948276815744 learning.py:507] global step 59990: loss = 1.3495 (2.129 sec/step)\n",
            "INFO:tensorflow:global step 60000: loss = 0.5890 (2.137 sec/step)\n",
            "I0608 20:14:50.441253 139948276815744 learning.py:507] global step 60000: loss = 0.5890 (2.137 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0608 20:14:50.441917 139948276815744 learning.py:777] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0608 20:14:50.442202 139948276815744 learning.py:785] Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CZidwhhabn"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVh9oz0PiEGt"
      },
      "source": [
        "%mkdir {EVAL_RESULTS}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spE-V5iAhk5A",
        "outputId": "187a7516-be00-4d22-e628-fa1471bad111"
      },
      "source": [
        "!python deeplab/eval.py --logtostderr \\\n",
        "  --eval_split=\"val\" \\\n",
        "  --model_variant=\"mobilenet_v2\" \\\n",
        "  --eval_crop_size=\"1080,1080\" \\\n",
        "  --atrous_rates=6 \\\n",
        "  --atrous_rates=12 \\\n",
        "   --atrous_rates=18 \\\n",
        "   --output_stride=16 \\\n",
        "   --decoder_output_stride=4 \\\n",
        "   --dataset=\"lip\" \\\n",
        "   --checkpoint_dir=\"{CHECKPOINT}\" \\\n",
        "   --eval_logdir=\"{EVAL_RESULTS}\" \\\n",
        "   --dataset_dir=\"{TRAIN_VAL_TFRECORD}\" \\\n",
        "   --max_number_of_iterations=1 \\\n",
        "   --num_classes=\n",
        "   --eval_interval_secs=0"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:227: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:91: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0619 11:18:30.346894 139775215441792 module_wrapper.py:139] From deeplab/eval.py:91: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:91: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0619 11:18:30.347193 139775215441792 module_wrapper.py:139] From deeplab/eval.py:91: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:108: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0619 11:18:30.347478 139775215441792 module_wrapper.py:139] From deeplab/eval.py:108: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:109: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0619 11:18:30.348113 139775215441792 module_wrapper.py:139] From deeplab/eval.py:109: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Evaluating on val set\n",
            "I0619 11:18:30.348298 139775215441792 eval.py:109] Evaluating on val set\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:375: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0619 11:18:30.349205 139775215441792 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:375: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0619 11:18:30.505716 139775215441792 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0619 11:18:30.506894 139775215441792 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0619 11:18:31.448607 139775215441792 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:364: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0619 11:18:33.169783 139775215441792 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/datasets/data_generator.py:364: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "INFO:tensorflow:Performing single-scale test.\n",
            "I0619 11:18:33.188229 139775215441792 eval.py:127] Performing single-scale test.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0619 11:18:33.188604 139775215441792 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0619 11:18:33.189068 139775215441792 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0619 11:18:33.193504 139775215441792 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0619 11:18:34.908065 139775215441792 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0619 11:18:35.184020 139775215441792 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:150: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0619 11:18:35.374802 139775215441792 deprecation.py:323] From deeplab/eval.py:150: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From deeplab/eval.py:161: The name tf.metrics.mean_iou is deprecated. Please use tf.compat.v1.metrics.mean_iou instead.\n",
            "\n",
            "W0619 11:18:35.375732 139775215441792 module_wrapper.py:139] From deeplab/eval.py:161: The name tf.metrics.mean_iou is deprecated. Please use tf.compat.v1.metrics.mean_iou instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0619 11:18:35.448729 139775215441792 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From deeplab/eval.py:171: The name tf.metrics.true_positives is deprecated. Please use tf.compat.v1.metrics.true_positives instead.\n",
            "\n",
            "W0619 11:18:35.458760 139775215441792 module_wrapper.py:139] From deeplab/eval.py:171: The name tf.metrics.true_positives is deprecated. Please use tf.compat.v1.metrics.true_positives instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:174: The name tf.metrics.false_positives is deprecated. Please use tf.compat.v1.metrics.false_positives instead.\n",
            "\n",
            "W0619 11:18:35.480702 139775215441792 module_wrapper.py:139] From deeplab/eval.py:174: The name tf.metrics.false_positives is deprecated. Please use tf.compat.v1.metrics.false_positives instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:177: The name tf.metrics.false_negatives is deprecated. Please use tf.compat.v1.metrics.false_negatives instead.\n",
            "\n",
            "W0619 11:18:35.498596 139775215441792 module_wrapper.py:139] From deeplab/eval.py:177: The name tf.metrics.false_negatives is deprecated. Please use tf.compat.v1.metrics.false_negatives instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:191: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0619 11:18:36.694223 139775215441792 module_wrapper.py:139] From deeplab/eval.py:191: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:192: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
            "Instructions for updating:\n",
            "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
            "\n",
            "W0619 11:18:36.695605 139775215441792 deprecation.py:323] From deeplab/eval.py:192: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
            "Instructions for updating:\n",
            "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:195: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0619 11:18:36.726469 139775215441792 module_wrapper.py:139] From deeplab/eval.py:195: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:208: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0619 11:18:36.727777 139775215441792 module_wrapper.py:139] From deeplab/eval.py:208: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/eval.py:209: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0619 11:18:36.727977 139775215441792 deprecation.py:323] From deeplab/eval.py:209: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0619 11:18:36.729158 139775215441792 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "61 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          \n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/2.73m params)\n",
            "  MobilenetV2 (--/1.81m params)\n",
            "    MobilenetV2/Conv (--/928 params)\n",
            "      MobilenetV2/Conv/BatchNorm (--/64 params)\n",
            "        MobilenetV2/Conv/BatchNorm/beta (32, 32/32 params)\n",
            "        MobilenetV2/Conv/BatchNorm/gamma (32, 32/32 params)\n",
            "      MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "    MobilenetV2/expanded_conv (--/896 params)\n",
            "      MobilenetV2/expanded_conv/depthwise (--/352 params)\n",
            "        MobilenetV2/expanded_conv/depthwise/BatchNorm (--/64 params)\n",
            "          MobilenetV2/expanded_conv/depthwise/BatchNorm/beta (32, 32/32 params)\n",
            "          MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma (32, 32/32 params)\n",
            "        MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      MobilenetV2/expanded_conv/project (--/544 params)\n",
            "        MobilenetV2/expanded_conv/project/BatchNorm (--/32 params)\n",
            "          MobilenetV2/expanded_conv/project/BatchNorm/beta (16, 16/16 params)\n",
            "          MobilenetV2/expanded_conv/project/BatchNorm/gamma (16, 16/16 params)\n",
            "        MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "    MobilenetV2/expanded_conv_1 (--/5.14k params)\n",
            "      MobilenetV2/expanded_conv_1/depthwise (--/1.06k params)\n",
            "        MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/192 params)\n",
            "          MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta (96, 96/96 params)\n",
            "          MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma (96, 96/96 params)\n",
            "        MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "      MobilenetV2/expanded_conv_1/expand (--/1.73k params)\n",
            "        MobilenetV2/expanded_conv_1/expand/BatchNorm (--/192 params)\n",
            "          MobilenetV2/expanded_conv_1/expand/BatchNorm/beta (96, 96/96 params)\n",
            "          MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma (96, 96/96 params)\n",
            "        MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "      MobilenetV2/expanded_conv_1/project (--/2.35k params)\n",
            "        MobilenetV2/expanded_conv_1/project/BatchNorm (--/48 params)\n",
            "          MobilenetV2/expanded_conv_1/project/BatchNorm/beta (24, 24/24 params)\n",
            "          MobilenetV2/expanded_conv_1/project/BatchNorm/gamma (24, 24/24 params)\n",
            "        MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "    MobilenetV2/expanded_conv_10 (--/66.62k params)\n",
            "      MobilenetV2/expanded_conv_10/depthwise (--/4.22k params)\n",
            "        MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_10/expand (--/25.34k params)\n",
            "        MobilenetV2/expanded_conv_10/expand/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_10/expand/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "      MobilenetV2/expanded_conv_10/project (--/37.06k params)\n",
            "        MobilenetV2/expanded_conv_10/project/BatchNorm (--/192 params)\n",
            "          MobilenetV2/expanded_conv_10/project/BatchNorm/beta (96, 96/96 params)\n",
            "          MobilenetV2/expanded_conv_10/project/BatchNorm/gamma (96, 96/96 params)\n",
            "        MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "    MobilenetV2/expanded_conv_11 (--/118.27k params)\n",
            "      MobilenetV2/expanded_conv_11/depthwise (--/6.34k params)\n",
            "        MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "      MobilenetV2/expanded_conv_11/expand (--/56.45k params)\n",
            "        MobilenetV2/expanded_conv_11/expand/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_11/expand/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "      MobilenetV2/expanded_conv_11/project (--/55.49k params)\n",
            "        MobilenetV2/expanded_conv_11/project/BatchNorm (--/192 params)\n",
            "          MobilenetV2/expanded_conv_11/project/BatchNorm/beta (96, 96/96 params)\n",
            "          MobilenetV2/expanded_conv_11/project/BatchNorm/gamma (96, 96/96 params)\n",
            "        MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "    MobilenetV2/expanded_conv_12 (--/118.27k params)\n",
            "      MobilenetV2/expanded_conv_12/depthwise (--/6.34k params)\n",
            "        MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "      MobilenetV2/expanded_conv_12/expand (--/56.45k params)\n",
            "        MobilenetV2/expanded_conv_12/expand/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_12/expand/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "      MobilenetV2/expanded_conv_12/project (--/55.49k params)\n",
            "        MobilenetV2/expanded_conv_12/project/BatchNorm (--/192 params)\n",
            "          MobilenetV2/expanded_conv_12/project/BatchNorm/beta (96, 96/96 params)\n",
            "          MobilenetV2/expanded_conv_12/project/BatchNorm/gamma (96, 96/96 params)\n",
            "        MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "    MobilenetV2/expanded_conv_13 (--/155.26k params)\n",
            "      MobilenetV2/expanded_conv_13/depthwise (--/6.34k params)\n",
            "        MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "      MobilenetV2/expanded_conv_13/expand (--/56.45k params)\n",
            "        MobilenetV2/expanded_conv_13/expand/BatchNorm (--/1.15k params)\n",
            "          MobilenetV2/expanded_conv_13/expand/BatchNorm/beta (576, 576/576 params)\n",
            "          MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma (576, 576/576 params)\n",
            "        MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "      MobilenetV2/expanded_conv_13/project (--/92.48k params)\n",
            "        MobilenetV2/expanded_conv_13/project/BatchNorm (--/320 params)\n",
            "          MobilenetV2/expanded_conv_13/project/BatchNorm/beta (160, 160/160 params)\n",
            "          MobilenetV2/expanded_conv_13/project/BatchNorm/gamma (160, 160/160 params)\n",
            "        MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "    MobilenetV2/expanded_conv_14 (--/320.00k params)\n",
            "      MobilenetV2/expanded_conv_14/depthwise (--/10.56k params)\n",
            "        MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "      MobilenetV2/expanded_conv_14/expand (--/155.52k params)\n",
            "        MobilenetV2/expanded_conv_14/expand/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_14/expand/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "      MobilenetV2/expanded_conv_14/project (--/153.92k params)\n",
            "        MobilenetV2/expanded_conv_14/project/BatchNorm (--/320 params)\n",
            "          MobilenetV2/expanded_conv_14/project/BatchNorm/beta (160, 160/160 params)\n",
            "          MobilenetV2/expanded_conv_14/project/BatchNorm/gamma (160, 160/160 params)\n",
            "        MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "    MobilenetV2/expanded_conv_15 (--/320.00k params)\n",
            "      MobilenetV2/expanded_conv_15/depthwise (--/10.56k params)\n",
            "        MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "      MobilenetV2/expanded_conv_15/expand (--/155.52k params)\n",
            "        MobilenetV2/expanded_conv_15/expand/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_15/expand/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "      MobilenetV2/expanded_conv_15/project (--/153.92k params)\n",
            "        MobilenetV2/expanded_conv_15/project/BatchNorm (--/320 params)\n",
            "          MobilenetV2/expanded_conv_15/project/BatchNorm/beta (160, 160/160 params)\n",
            "          MobilenetV2/expanded_conv_15/project/BatchNorm/gamma (160, 160/160 params)\n",
            "        MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "    MobilenetV2/expanded_conv_16 (--/473.92k params)\n",
            "      MobilenetV2/expanded_conv_16/depthwise (--/10.56k params)\n",
            "        MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "      MobilenetV2/expanded_conv_16/expand (--/155.52k params)\n",
            "        MobilenetV2/expanded_conv_16/expand/BatchNorm (--/1.92k params)\n",
            "          MobilenetV2/expanded_conv_16/expand/BatchNorm/beta (960, 960/960 params)\n",
            "          MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma (960, 960/960 params)\n",
            "        MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "      MobilenetV2/expanded_conv_16/project (--/307.84k params)\n",
            "        MobilenetV2/expanded_conv_16/project/BatchNorm (--/640 params)\n",
            "          MobilenetV2/expanded_conv_16/project/BatchNorm/beta (320, 320/320 params)\n",
            "          MobilenetV2/expanded_conv_16/project/BatchNorm/gamma (320, 320/320 params)\n",
            "        MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "    MobilenetV2/expanded_conv_2 (--/8.83k params)\n",
            "      MobilenetV2/expanded_conv_2/depthwise (--/1.58k params)\n",
            "        MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/288 params)\n",
            "          MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta (144, 144/144 params)\n",
            "          MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma (144, 144/144 params)\n",
            "        MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "      MobilenetV2/expanded_conv_2/expand (--/3.74k params)\n",
            "        MobilenetV2/expanded_conv_2/expand/BatchNorm (--/288 params)\n",
            "          MobilenetV2/expanded_conv_2/expand/BatchNorm/beta (144, 144/144 params)\n",
            "          MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma (144, 144/144 params)\n",
            "        MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_2/project (--/3.50k params)\n",
            "        MobilenetV2/expanded_conv_2/project/BatchNorm (--/48 params)\n",
            "          MobilenetV2/expanded_conv_2/project/BatchNorm/beta (24, 24/24 params)\n",
            "          MobilenetV2/expanded_conv_2/project/BatchNorm/gamma (24, 24/24 params)\n",
            "        MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "    MobilenetV2/expanded_conv_3 (--/10.00k params)\n",
            "      MobilenetV2/expanded_conv_3/depthwise (--/1.58k params)\n",
            "        MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/288 params)\n",
            "          MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta (144, 144/144 params)\n",
            "          MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma (144, 144/144 params)\n",
            "        MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "      MobilenetV2/expanded_conv_3/expand (--/3.74k params)\n",
            "        MobilenetV2/expanded_conv_3/expand/BatchNorm (--/288 params)\n",
            "          MobilenetV2/expanded_conv_3/expand/BatchNorm/beta (144, 144/144 params)\n",
            "          MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma (144, 144/144 params)\n",
            "        MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_3/project (--/4.67k params)\n",
            "        MobilenetV2/expanded_conv_3/project/BatchNorm (--/64 params)\n",
            "          MobilenetV2/expanded_conv_3/project/BatchNorm/beta (32, 32/32 params)\n",
            "          MobilenetV2/expanded_conv_3/project/BatchNorm/gamma (32, 32/32 params)\n",
            "        MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "    MobilenetV2/expanded_conv_4 (--/14.85k params)\n",
            "      MobilenetV2/expanded_conv_4/depthwise (--/2.11k params)\n",
            "        MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "      MobilenetV2/expanded_conv_4/expand (--/6.53k params)\n",
            "        MobilenetV2/expanded_conv_4/expand/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_4/expand/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "      MobilenetV2/expanded_conv_4/project (--/6.21k params)\n",
            "        MobilenetV2/expanded_conv_4/project/BatchNorm (--/64 params)\n",
            "          MobilenetV2/expanded_conv_4/project/BatchNorm/beta (32, 32/32 params)\n",
            "          MobilenetV2/expanded_conv_4/project/BatchNorm/gamma (32, 32/32 params)\n",
            "        MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "    MobilenetV2/expanded_conv_5 (--/14.85k params)\n",
            "      MobilenetV2/expanded_conv_5/depthwise (--/2.11k params)\n",
            "        MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "      MobilenetV2/expanded_conv_5/expand (--/6.53k params)\n",
            "        MobilenetV2/expanded_conv_5/expand/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_5/expand/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "      MobilenetV2/expanded_conv_5/project (--/6.21k params)\n",
            "        MobilenetV2/expanded_conv_5/project/BatchNorm (--/64 params)\n",
            "          MobilenetV2/expanded_conv_5/project/BatchNorm/beta (32, 32/32 params)\n",
            "          MobilenetV2/expanded_conv_5/project/BatchNorm/gamma (32, 32/32 params)\n",
            "        MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "    MobilenetV2/expanded_conv_6 (--/21.06k params)\n",
            "      MobilenetV2/expanded_conv_6/depthwise (--/2.11k params)\n",
            "        MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "      MobilenetV2/expanded_conv_6/expand (--/6.53k params)\n",
            "        MobilenetV2/expanded_conv_6/expand/BatchNorm (--/384 params)\n",
            "          MobilenetV2/expanded_conv_6/expand/BatchNorm/beta (192, 192/192 params)\n",
            "          MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma (192, 192/192 params)\n",
            "        MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "      MobilenetV2/expanded_conv_6/project (--/12.42k params)\n",
            "        MobilenetV2/expanded_conv_6/project/BatchNorm (--/128 params)\n",
            "          MobilenetV2/expanded_conv_6/project/BatchNorm/beta (64, 64/64 params)\n",
            "          MobilenetV2/expanded_conv_6/project/BatchNorm/gamma (64, 64/64 params)\n",
            "        MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "    MobilenetV2/expanded_conv_7 (--/54.27k params)\n",
            "      MobilenetV2/expanded_conv_7/depthwise (--/4.22k params)\n",
            "        MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_7/expand (--/25.34k params)\n",
            "        MobilenetV2/expanded_conv_7/expand/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_7/expand/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "      MobilenetV2/expanded_conv_7/project (--/24.70k params)\n",
            "        MobilenetV2/expanded_conv_7/project/BatchNorm (--/128 params)\n",
            "          MobilenetV2/expanded_conv_7/project/BatchNorm/beta (64, 64/64 params)\n",
            "          MobilenetV2/expanded_conv_7/project/BatchNorm/gamma (64, 64/64 params)\n",
            "        MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "    MobilenetV2/expanded_conv_8 (--/54.27k params)\n",
            "      MobilenetV2/expanded_conv_8/depthwise (--/4.22k params)\n",
            "        MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_8/expand (--/25.34k params)\n",
            "        MobilenetV2/expanded_conv_8/expand/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_8/expand/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "      MobilenetV2/expanded_conv_8/project (--/24.70k params)\n",
            "        MobilenetV2/expanded_conv_8/project/BatchNorm (--/128 params)\n",
            "          MobilenetV2/expanded_conv_8/project/BatchNorm/beta (64, 64/64 params)\n",
            "          MobilenetV2/expanded_conv_8/project/BatchNorm/gamma (64, 64/64 params)\n",
            "        MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "    MobilenetV2/expanded_conv_9 (--/54.27k params)\n",
            "      MobilenetV2/expanded_conv_9/depthwise (--/4.22k params)\n",
            "        MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "      MobilenetV2/expanded_conv_9/expand (--/25.34k params)\n",
            "        MobilenetV2/expanded_conv_9/expand/BatchNorm (--/768 params)\n",
            "          MobilenetV2/expanded_conv_9/expand/BatchNorm/beta (384, 384/384 params)\n",
            "          MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma (384, 384/384 params)\n",
            "        MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "      MobilenetV2/expanded_conv_9/project (--/24.70k params)\n",
            "        MobilenetV2/expanded_conv_9/project/BatchNorm (--/128 params)\n",
            "          MobilenetV2/expanded_conv_9/project/BatchNorm/beta (64, 64/64 params)\n",
            "          MobilenetV2/expanded_conv_9/project/BatchNorm/gamma (64, 64/64 params)\n",
            "        MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "  aspp0 (--/82.43k params)\n",
            "    aspp0/BatchNorm (--/512 params)\n",
            "      aspp0/BatchNorm/beta (256, 256/256 params)\n",
            "      aspp0/BatchNorm/gamma (256, 256/256 params)\n",
            "    aspp0/weights (1x1x320x256, 81.92k/81.92k params)\n",
            "  aspp1_depthwise (--/3.52k params)\n",
            "    aspp1_depthwise/BatchNorm (--/640 params)\n",
            "      aspp1_depthwise/BatchNorm/beta (320, 320/320 params)\n",
            "      aspp1_depthwise/BatchNorm/gamma (320, 320/320 params)\n",
            "    aspp1_depthwise/depthwise_weights (3x3x320x1, 2.88k/2.88k params)\n",
            "  aspp1_pointwise (--/82.43k params)\n",
            "    aspp1_pointwise/BatchNorm (--/512 params)\n",
            "      aspp1_pointwise/BatchNorm/beta (256, 256/256 params)\n",
            "      aspp1_pointwise/BatchNorm/gamma (256, 256/256 params)\n",
            "    aspp1_pointwise/weights (1x1x320x256, 81.92k/81.92k params)\n",
            "  aspp2_depthwise (--/3.52k params)\n",
            "    aspp2_depthwise/BatchNorm (--/640 params)\n",
            "      aspp2_depthwise/BatchNorm/beta (320, 320/320 params)\n",
            "      aspp2_depthwise/BatchNorm/gamma (320, 320/320 params)\n",
            "    aspp2_depthwise/depthwise_weights (3x3x320x1, 2.88k/2.88k params)\n",
            "  aspp2_pointwise (--/82.43k params)\n",
            "    aspp2_pointwise/BatchNorm (--/512 params)\n",
            "      aspp2_pointwise/BatchNorm/beta (256, 256/256 params)\n",
            "      aspp2_pointwise/BatchNorm/gamma (256, 256/256 params)\n",
            "    aspp2_pointwise/weights (1x1x320x256, 81.92k/81.92k params)\n",
            "  aspp3_depthwise (--/3.52k params)\n",
            "    aspp3_depthwise/BatchNorm (--/640 params)\n",
            "      aspp3_depthwise/BatchNorm/beta (320, 320/320 params)\n",
            "      aspp3_depthwise/BatchNorm/gamma (320, 320/320 params)\n",
            "    aspp3_depthwise/depthwise_weights (3x3x320x1, 2.88k/2.88k params)\n",
            "  aspp3_pointwise (--/82.43k params)\n",
            "    aspp3_pointwise/BatchNorm (--/512 params)\n",
            "      aspp3_pointwise/BatchNorm/beta (256, 256/256 params)\n",
            "      aspp3_pointwise/BatchNorm/gamma (256, 256/256 params)\n",
            "    aspp3_pointwise/weights (1x1x320x256, 81.92k/81.92k params)\n",
            "  concat_projection (--/328.19k params)\n",
            "    concat_projection/BatchNorm (--/512 params)\n",
            "      concat_projection/BatchNorm/beta (256, 256/256 params)\n",
            "      concat_projection/BatchNorm/gamma (256, 256/256 params)\n",
            "    concat_projection/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "  decoder (--/157.55k params)\n",
            "    decoder/decoder_conv0_depthwise (--/3.34k params)\n",
            "      decoder/decoder_conv0_depthwise/BatchNorm (--/608 params)\n",
            "        decoder/decoder_conv0_depthwise/BatchNorm/beta (304, 304/304 params)\n",
            "        decoder/decoder_conv0_depthwise/BatchNorm/gamma (304, 304/304 params)\n",
            "      decoder/decoder_conv0_depthwise/depthwise_weights (3x3x304x1, 2.74k/2.74k params)\n",
            "    decoder/decoder_conv0_pointwise (--/78.34k params)\n",
            "      decoder/decoder_conv0_pointwise/BatchNorm (--/512 params)\n",
            "        decoder/decoder_conv0_pointwise/BatchNorm/beta (256, 256/256 params)\n",
            "        decoder/decoder_conv0_pointwise/BatchNorm/gamma (256, 256/256 params)\n",
            "      decoder/decoder_conv0_pointwise/weights (1x1x304x256, 77.82k/77.82k params)\n",
            "    decoder/decoder_conv1_depthwise (--/2.82k params)\n",
            "      decoder/decoder_conv1_depthwise/BatchNorm (--/512 params)\n",
            "        decoder/decoder_conv1_depthwise/BatchNorm/beta (256, 256/256 params)\n",
            "        decoder/decoder_conv1_depthwise/BatchNorm/gamma (256, 256/256 params)\n",
            "      decoder/decoder_conv1_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    decoder/decoder_conv1_pointwise (--/66.05k params)\n",
            "      decoder/decoder_conv1_pointwise/BatchNorm (--/512 params)\n",
            "        decoder/decoder_conv1_pointwise/BatchNorm/beta (256, 256/256 params)\n",
            "        decoder/decoder_conv1_pointwise/BatchNorm/gamma (256, 256/256 params)\n",
            "      decoder/decoder_conv1_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "    decoder/feature_projection0 (--/7.01k params)\n",
            "      decoder/feature_projection0/BatchNorm (--/96 params)\n",
            "        decoder/feature_projection0/BatchNorm/beta (48, 48/48 params)\n",
            "        decoder/feature_projection0/BatchNorm/gamma (48, 48/48 params)\n",
            "      decoder/feature_projection0/weights (1x1x144x48, 6.91k/6.91k params)\n",
            "  image_pooling (--/82.43k params)\n",
            "    image_pooling/BatchNorm (--/512 params)\n",
            "      image_pooling/BatchNorm/beta (256, 256/256 params)\n",
            "      image_pooling/BatchNorm/gamma (256, 256/256 params)\n",
            "    image_pooling/weights (1x1x320x256, 81.92k/81.92k params)\n",
            "  logits (--/4.88k params)\n",
            "    logits/semantic (--/4.88k params)\n",
            "      logits/semantic/biases (19, 19/19 params)\n",
            "      logits/semantic/weights (1x1x256x19, 4.86k/4.86k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "61 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          \n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/51.28b flops)\n",
            "  decoder/decoder_conv0_pointwise/Conv2D (11.35b/11.35b flops)\n",
            "  decoder/decoder_conv1_pointwise/Conv2D (9.56b/9.56b flops)\n",
            "  concat_projection/Conv2D (3.03b/3.03b flops)\n",
            "  MobilenetV2/expanded_conv_16/project/Conv2D (2.84b/2.84b flops)\n",
            "  MobilenetV2/expanded_conv_16/expand/Conv2D (1.42b/1.42b flops)\n",
            "  MobilenetV2/expanded_conv_15/project/Conv2D (1.42b/1.42b flops)\n",
            "  MobilenetV2/expanded_conv_14/expand/Conv2D (1.42b/1.42b flops)\n",
            "  MobilenetV2/expanded_conv_14/project/Conv2D (1.42b/1.42b flops)\n",
            "  MobilenetV2/expanded_conv_15/expand/Conv2D (1.42b/1.42b flops)\n",
            "  decoder/feature_projection0/Conv2D (1.01b/1.01b flops)\n",
            "  MobilenetV2/expanded_conv_1/expand/Conv2D (895.80m/895.80m flops)\n",
            "  MobilenetV2/expanded_conv_13/project/Conv2D (852.30m/852.30m flops)\n",
            "  aspp3_pointwise/Conv2D (757.60m/757.60m flops)\n",
            "  aspp2_pointwise/Conv2D (757.60m/757.60m flops)\n",
            "  aspp1_pointwise/Conv2D (757.60m/757.60m flops)\n",
            "  aspp0/Conv2D (757.60m/757.60m flops)\n",
            "  logits/semantic/Conv2D (709.17m/709.17m flops)\n",
            "  MobilenetV2/expanded_conv_13/expand/Conv2D (511.38m/511.38m flops)\n",
            "  MobilenetV2/expanded_conv_11/expand/Conv2D (511.38m/511.38m flops)\n",
            "  MobilenetV2/expanded_conv_11/project/Conv2D (511.38m/511.38m flops)\n",
            "  MobilenetV2/expanded_conv_12/project/Conv2D (511.38m/511.38m flops)\n",
            "  MobilenetV2/expanded_conv_12/expand/Conv2D (511.38m/511.38m flops)\n",
            "  MobilenetV2/expanded_conv_3/expand/Conv2D (503.88m/503.88m flops)\n",
            "  MobilenetV2/expanded_conv_2/project/Conv2D (503.88m/503.88m flops)\n",
            "  MobilenetV2/expanded_conv_2/expand/Conv2D (503.88m/503.88m flops)\n",
            "  MobilenetV2/Conv/Conv2D (503.88m/503.88m flops)\n",
            "  decoder/decoder_conv0_depthwise/depthwise (398.91m/398.91m flops)\n",
            "  MobilenetV2/expanded_conv_10/project/Conv2D (340.92m/340.92m flops)\n",
            "  decoder/decoder_conv1_depthwise/depthwise (335.92m/335.92m flops)\n",
            "  MobilenetV2/expanded_conv_1/project/Conv2D (335.92m/335.92m flops)\n",
            "  MobilenetV2/expanded_conv/project/Conv2D (298.60m/298.60m flops)\n",
            "  MobilenetV2/expanded_conv_7/project/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_10/expand/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_9/project/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_9/expand/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_8/project/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_8/expand/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_7/expand/Conv2D (227.28m/227.28m flops)\n",
            "  MobilenetV2/expanded_conv_4/expand/Conv2D (223.95m/223.95m flops)\n",
            "  MobilenetV2/expanded_conv_6/expand/Conv2D (223.95m/223.95m flops)\n",
            "  MobilenetV2/expanded_conv_5/project/Conv2D (223.95m/223.95m flops)\n",
            "  MobilenetV2/expanded_conv_5/expand/Conv2D (223.95m/223.95m flops)\n",
            "  MobilenetV2/expanded_conv_4/project/Conv2D (223.95m/223.95m flops)\n",
            "  MobilenetV2/expanded_conv_2/depthwise/depthwise (188.96m/188.96m flops)\n",
            "  MobilenetV2/expanded_conv/depthwise/depthwise (167.96m/167.96m flops)\n",
            "  MobilenetV2/expanded_conv_3/project/Conv2D (167.96m/167.96m flops)\n",
            "  MobilenetV2/expanded_conv_1/depthwise/depthwise (125.97m/125.97m flops)\n",
            "  MobilenetV2/expanded_conv_6/project/Conv2D (113.64m/113.64m flops)\n",
            "  Softmax (110.81m/110.81m flops)\n",
            "  MobilenetV2/expanded_conv_14/depthwise/depthwise (79.90m/79.90m flops)\n",
            "  MobilenetV2/expanded_conv_15/depthwise/depthwise (79.90m/79.90m flops)\n",
            "  MobilenetV2/expanded_conv_16/depthwise/depthwise (79.90m/79.90m flops)\n",
            "  MobilenetV2/expanded_conv_4/depthwise/depthwise (62.99m/62.99m flops)\n",
            "  MobilenetV2/expanded_conv_5/depthwise/depthwise (62.99m/62.99m flops)\n",
            "  MobilenetV2/expanded_conv_12/depthwise/depthwise (47.94m/47.94m flops)\n",
            "  MobilenetV2/expanded_conv_11/depthwise/depthwise (47.94m/47.94m flops)\n",
            "  MobilenetV2/expanded_conv_13/depthwise/depthwise (47.94m/47.94m flops)\n",
            "  MobilenetV2/expanded_conv_3/depthwise/depthwise (47.24m/47.24m flops)\n",
            "  MobilenetV2/expanded_conv_9/depthwise/depthwise (31.96m/31.96m flops)\n",
            "  MobilenetV2/expanded_conv_10/depthwise/depthwise (31.96m/31.96m flops)\n",
            "  MobilenetV2/expanded_conv_7/depthwise/depthwise (31.96m/31.96m flops)\n",
            "  MobilenetV2/expanded_conv_8/depthwise/depthwise (31.96m/31.96m flops)\n",
            "  aspp1_depthwise/depthwise (29.86m/29.86m flops)\n",
            "  aspp2_depthwise/depthwise (29.86m/29.86m flops)\n",
            "  aspp3_depthwise/depthwise (29.86m/29.86m flops)\n",
            "  ArgMax (21.00m/21.00m flops)\n",
            "  MobilenetV2/expanded_conv_6/depthwise/depthwise (15.98m/15.98m flops)\n",
            "  mul (3.50m/3.50m flops)\n",
            "  sub (3.50m/3.50m flops)\n",
            "  AvgPool2D/AvgPool (1.48m/1.48m flops)\n",
            "  logits/semantic/BiasAdd (1.39m/1.39m flops)\n",
            "  true_positives_3/Mul (1.17m/1.17m flops)\n",
            "  true_positives/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_16/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_16/Mul (1.17m/1.17m flops)\n",
            "  true_positives_5/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_17/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_11/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_4/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_18/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_18/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_2/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_4/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_2/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_3/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_5/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_3/Mul (1.17m/1.17m flops)\n",
            "  true_positives_11/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_4/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_4/Mul (1.17m/1.17m flops)\n",
            "  true_positives_3/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_5/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_5/Mul (1.17m/1.17m flops)\n",
            "  true_positives_2/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_6/Equal_1 (1.17m/1.17m flops)\n",
            "  mean_iou/confusion_matrix/assert_non_negative_1/assert_less_equal/LessEqual (1.17m/1.17m flops)\n",
            "  false_negatives_6/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_7/Equal_1 (1.17m/1.17m flops)\n",
            "  mean_iou/confusion_matrix/assert_less_1/Less (1.17m/1.17m flops)\n",
            "  false_negatives_11/Mul (1.17m/1.17m flops)\n",
            "  true_positives_10/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_9/Mul (1.17m/1.17m flops)\n",
            "  true_positives_9/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives/Mul (1.17m/1.17m flops)\n",
            "  true_positives_8/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_1/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_8/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_1/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_10/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_7/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_10/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_11/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_7/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_8/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_1/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_12/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_12/Mul (1.17m/1.17m flops)\n",
            "  true_positives_6/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_13/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_10/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_13/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_14/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_6/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_14/Mul (1.17m/1.17m flops)\n",
            "  true_positives_1/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_15/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_15/Mul (1.17m/1.17m flops)\n",
            "  false_positives_2/Mul (1.17m/1.17m flops)\n",
            "  false_positives_8/Mul (1.17m/1.17m flops)\n",
            "  false_positives_15/Mul (1.17m/1.17m flops)\n",
            "  false_positives_16/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_16/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_16/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_17/Mul (1.17m/1.17m flops)\n",
            "  false_positives_17/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_17/Mul (1.17m/1.17m flops)\n",
            "  true_positives_15/Mul (1.17m/1.17m flops)\n",
            "  false_positives_18/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_18/Mul (1.17m/1.17m flops)\n",
            "  true_positives_15/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_2/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_13/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_15/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_3/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_8/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_3/Mul (1.17m/1.17m flops)\n",
            "  false_positives_4/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_14/Mul (1.17m/1.17m flops)\n",
            "  false_positives_4/Mul (1.17m/1.17m flops)\n",
            "  false_positives_7/Mul (1.17m/1.17m flops)\n",
            "  false_positives_5/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_5/Mul (1.17m/1.17m flops)\n",
            "  true_positives_14/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_6/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_6/Mul (1.17m/1.17m flops)\n",
            "  true_positives_13/Mul (1.17m/1.17m flops)\n",
            "  false_positives_10/Mul (1.17m/1.17m flops)\n",
            "  false_positives_7/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_2/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_8/Mul (1.17m/1.17m flops)\n",
            "  true_positives_12/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_9/Equal_1 (1.17m/1.17m flops)\n",
            "  false_negatives_9/Mul (1.17m/1.17m flops)\n",
            "  true_positives_18/Mul (1.17m/1.17m flops)\n",
            "  false_positives/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives/Mul (1.17m/1.17m flops)\n",
            "  true_positives_18/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_1/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_1/Mul (1.17m/1.17m flops)\n",
            "  false_positives_10/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_17/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_7/Mul (1.17m/1.17m flops)\n",
            "  false_positives_11/Equal_1 (1.17m/1.17m flops)\n",
            "  true_positives_17/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_11/Mul (1.17m/1.17m flops)\n",
            "  false_positives_9/Mul (1.17m/1.17m flops)\n",
            "  false_positives_12/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_12/Mul (1.17m/1.17m flops)\n",
            "  true_positives_12/Mul (1.17m/1.17m flops)\n",
            "  false_positives_13/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_13/Mul (1.17m/1.17m flops)\n",
            "  true_positives_16/Mul (1.17m/1.17m flops)\n",
            "  false_positives_14/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_9/Equal_1 (1.17m/1.17m flops)\n",
            "  false_positives_14/Mul (1.17m/1.17m flops)\n",
            "  false_negatives_5/Sum (1.17m/1.17m flops)\n",
            "  false_positives_11/Sum (1.17m/1.17m flops)\n",
            "  false_positives_10/Sum (1.17m/1.17m flops)\n",
            "  false_positives_1/Sum (1.17m/1.17m flops)\n",
            "  false_positives/Sum (1.17m/1.17m flops)\n",
            "  true_positives_9/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_9/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_8/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_7/Sum (1.17m/1.17m flops)\n",
            "  true_positives_4/Sum (1.17m/1.17m flops)\n",
            "  true_positives_8/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_4/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_3/Sum (1.17m/1.17m flops)\n",
            "  true_positives/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_2/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_18/Sum (1.17m/1.17m flops)\n",
            "  true_positives_1/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_17/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_16/Sum (1.17m/1.17m flops)\n",
            "  true_positives_7/Sum (1.17m/1.17m flops)\n",
            "  false_positives_4/Sum (1.17m/1.17m flops)\n",
            "  false_positives_3/Sum (1.17m/1.17m flops)\n",
            "  true_positives_6/Sum (1.17m/1.17m flops)\n",
            "  false_positives_2/Sum (1.17m/1.17m flops)\n",
            "  false_positives_18/Sum (1.17m/1.17m flops)\n",
            "  false_positives_5/Sum (1.17m/1.17m flops)\n",
            "  false_positives_17/Sum (1.17m/1.17m flops)\n",
            "  false_positives_16/Sum (1.17m/1.17m flops)\n",
            "  false_positives_6/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_6/Sum (1.17m/1.17m flops)\n",
            "  false_positives_15/Sum (1.17m/1.17m flops)\n",
            "  true_positives_5/Sum (1.17m/1.17m flops)\n",
            "  false_positives_14/Sum (1.17m/1.17m flops)\n",
            "  false_positives_7/Sum (1.17m/1.17m flops)\n",
            "  false_positives_13/Sum (1.17m/1.17m flops)\n",
            "  false_positives_8/Sum (1.17m/1.17m flops)\n",
            "  false_positives_12/Sum (1.17m/1.17m flops)\n",
            "  false_positives_9/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_13/Sum (1.17m/1.17m flops)\n",
            "  true_positives_2/Sum (1.17m/1.17m flops)\n",
            "  true_positives_14/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_11/Sum (1.17m/1.17m flops)\n",
            "  true_positives_13/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_10/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_12/Sum (1.17m/1.17m flops)\n",
            "  true_positives_12/Sum (1.17m/1.17m flops)\n",
            "  true_positives_15/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_1/Sum (1.17m/1.17m flops)\n",
            "  true_positives_11/Sum (1.17m/1.17m flops)\n",
            "  true_positives_16/Sum (1.17m/1.17m flops)\n",
            "  true_positives_17/Sum (1.17m/1.17m flops)\n",
            "  false_negatives/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_14/Sum (1.17m/1.17m flops)\n",
            "  true_positives_3/Sum (1.17m/1.17m flops)\n",
            "  false_negatives_15/Sum (1.17m/1.17m flops)\n",
            "  true_positives_18/Sum (1.17m/1.17m flops)\n",
            "  true_positives_10/Sum (1.17m/1.17m flops)\n",
            "  concat_projection/kernel/Regularizer/l2_regularizer (1/983.04k flops)\n",
            "    concat_projection/kernel/Regularizer/l2_regularizer/L2Loss (983.04k/983.04k flops)\n",
            "  MobilenetV2/expanded_conv_16/project/kernel/Regularizer/l2_regularizer (1/921.60k flops)\n",
            "    MobilenetV2/expanded_conv_16/project/kernel/Regularizer/l2_regularizer/L2Loss (921.60k/921.60k flops)\n",
            "  concat_projection/weights/Initializer/random_uniform (327.68k/655.36k flops)\n",
            "    concat_projection/weights/Initializer/random_uniform/mul (327.68k/327.68k flops)\n",
            "    concat_projection/weights/Initializer/random_uniform/sub (1/1 flops)\n",
            "  MobilenetV2/expanded_conv_16/project/weights/Initializer/truncated_normal (307.20k/614.40k flops)\n",
            "    MobilenetV2/expanded_conv_16/project/weights/Initializer/truncated_normal/mul (307.20k/307.20k flops)\n",
            "  MobilenetV2/expanded_conv_15/expand/kernel/Regularizer/l2_regularizer (1/460.80k flops)\n",
            "    MobilenetV2/expanded_conv_15/expand/kernel/Regularizer/l2_regularizer/L2Loss (460.80k/460.80k flops)\n",
            "  MobilenetV2/expanded_conv_15/project/kernel/Regularizer/l2_regularizer (1/460.80k flops)\n",
            "    MobilenetV2/expanded_conv_15/project/kernel/Regularizer/l2_regularizer/L2Loss (460.80k/460.80k flops)\n",
            "  MobilenetV2/expanded_conv_14/expand/kernel/Regularizer/l2_regularizer (1/460.80k flops)\n",
            "    MobilenetV2/expanded_conv_14/expand/kernel/Regularizer/l2_regularizer/L2Loss (460.80k/460.80k flops)\n",
            "  MobilenetV2/expanded_conv_14/project/kernel/Regularizer/l2_regularizer (1/460.80k flops)\n",
            "    MobilenetV2/expanded_conv_14/project/kernel/Regularizer/l2_regularizer/L2Loss (460.80k/460.80k flops)\n",
            "  MobilenetV2/expanded_conv_16/expand/kernel/Regularizer/l2_regularizer (1/460.80k flops)\n",
            "    MobilenetV2/expanded_conv_16/expand/kernel/Regularizer/l2_regularizer/L2Loss (460.80k/460.80k flops)\n",
            "  MobilenetV2/expanded_conv_14/expand/weights/Initializer/truncated_normal (153.60k/307.20k flops)\n",
            "    MobilenetV2/expanded_conv_14/expand/weights/Initializer/truncated_normal/mul (153.60k/153.60k flops)\n",
            "  MobilenetV2/expanded_conv_14/project/weights/Initializer/truncated_normal (153.60k/307.20k flops)\n",
            "    MobilenetV2/expanded_conv_14/project/weights/Initializer/truncated_normal/mul (153.60k/153.60k flops)\n",
            "  MobilenetV2/expanded_conv_16/expand/weights/Initializer/truncated_normal (153.60k/307.20k flops)\n",
            "    MobilenetV2/expanded_conv_16/expand/weights/Initializer/truncated_normal/mul (153.60k/153.60k flops)\n",
            "  MobilenetV2/expanded_conv_15/project/weights/Initializer/truncated_normal (153.60k/307.20k flops)\n",
            "    MobilenetV2/expanded_conv_15/project/weights/Initializer/truncated_normal/mul (153.60k/153.60k flops)\n",
            "  MobilenetV2/expanded_conv_15/expand/weights/Initializer/truncated_normal (153.60k/307.20k flops)\n",
            "    MobilenetV2/expanded_conv_15/expand/weights/Initializer/truncated_normal/mul (153.60k/153.60k flops)\n",
            "  MobilenetV2/expanded_conv_13/project/kernel/Regularizer/l2_regularizer (1/276.48k flops)\n",
            "    MobilenetV2/expanded_conv_13/project/kernel/Regularizer/l2_regularizer/L2Loss (276.48k/276.48k flops)\n",
            "  aspp0/kernel/Regularizer/l2_regularizer (1/245.76k flops)\n",
            "    aspp0/kernel/Regularizer/l2_regularizer/L2Loss (245.76k/245.76k flops)\n",
            "  image_pooling/kernel/Regularizer/l2_regularizer (1/245.76k flops)\n",
            "    image_pooling/kernel/Regularizer/l2_regularizer/L2Loss (245.76k/245.76k flops)\n",
            "  aspp1_pointwise/kernel/Regularizer/l2_regularizer (1/245.76k flops)\n",
            "    aspp1_pointwise/kernel/Regularizer/l2_regularizer/L2Loss (245.76k/245.76k flops)\n",
            "  aspp3_pointwise/kernel/Regularizer/l2_regularizer (1/245.76k flops)\n",
            "    aspp3_pointwise/kernel/Regularizer/l2_regularizer/L2Loss (245.76k/245.76k flops)\n",
            "  aspp2_pointwise/kernel/Regularizer/l2_regularizer (1/245.76k flops)\n",
            "    aspp2_pointwise/kernel/Regularizer/l2_regularizer/L2Loss (245.76k/245.76k flops)\n",
            "  decoder/decoder_conv0_pointwise/kernel/Regularizer/l2_regularizer (1/233.47k flops)\n",
            "    decoder/decoder_conv0_pointwise/kernel/Regularizer/l2_regularizer/L2Loss (233.47k/233.47k flops)\n",
            "  decoder/decoder_conv1_pointwise/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
            "    decoder/decoder_conv1_pointwise/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
            "  MobilenetV2/expanded_conv_13/project/weights/Initializer/truncated_normal (92.16k/184.32k flops)\n",
            "    MobilenetV2/expanded_conv_13/project/weights/Initializer/truncated_normal/mul (92.16k/92.16k flops)\n",
            "  MobilenetV2/expanded_conv_11/expand/kernel/Regularizer/l2_regularizer (1/165.89k flops)\n",
            "    MobilenetV2/expanded_conv_11/expand/kernel/Regularizer/l2_regularizer/L2Loss (165.89k/165.89k flops)\n",
            "  MobilenetV2/expanded_conv_12/expand/kernel/Regularizer/l2_regularizer (1/165.89k flops)\n",
            "    MobilenetV2/expanded_conv_12/expand/kernel/Regularizer/l2_regularizer/L2Loss (165.89k/165.89k flops)\n",
            "  MobilenetV2/expanded_conv_13/expand/kernel/Regularizer/l2_regularizer (1/165.89k flops)\n",
            "    MobilenetV2/expanded_conv_13/expand/kernel/Regularizer/l2_regularizer/L2Loss (165.89k/165.89k flops)\n",
            "  MobilenetV2/expanded_conv_11/project/kernel/Regularizer/l2_regularizer (1/165.89k flops)\n",
            "    MobilenetV2/expanded_conv_11/project/kernel/Regularizer/l2_regularizer/L2Loss (165.89k/165.89k flops)\n",
            "  MobilenetV2/expanded_conv_12/project/kernel/Regularizer/l2_regularizer (1/165.89k flops)\n",
            "    MobilenetV2/expanded_conv_12/project/kernel/Regularizer/l2_regularizer/L2Loss (165.89k/165.89k flops)\n",
            "  aspp0/weights/Initializer/random_uniform (81.92k/163.84k flops)\n",
            "    aspp0/weights/Initializer/random_uniform/mul (81.92k/81.92k flops)\n",
            "    aspp0/weights/Initializer/random_uniform/sub (1/1 flops)\n",
            "  image_pooling/weights/Initializer/random_uniform (81.92k/163.84k flops)\n",
            "    image_pooling/weights/Initializer/random_uniform/mul (81.92k/81.92k flops)\n",
            "    image_pooling/weights/Initializer/random_uniform/sub (1/1 flops)\n",
            "  aspp2_pointwise/weights/Initializer/truncated_normal (81.92k/163.84k flops)\n",
            "    aspp2_pointwise/weights/Initializer/truncated_normal/mul (81.92k/81.92k flops)\n",
            "  aspp3_pointwise/weights/Initializer/truncated_normal (81.92k/163.84k flops)\n",
            "    aspp3_pointwise/weights/Initializer/truncated_normal/mul (81.92k/81.92k flops)\n",
            "  aspp1_pointwise/weights/Initializer/truncated_normal (81.92k/163.84k flops)\n",
            "    aspp1_pointwise/weights/Initializer/truncated_normal/mul (81.92k/81.92k flops)\n",
            "  image_pooling/Conv2D (163.84k/163.84k flops)\n",
            "  decoder/decoder_conv0_pointwise/weights/Initializer/truncated_normal (77.82k/155.65k flops)\n",
            "    decoder/decoder_conv0_pointwise/weights/Initializer/truncated_normal/mul (77.82k/77.82k flops)\n",
            "  decoder/decoder_conv1_pointwise/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
            "    decoder/decoder_conv1_pointwise/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
            "  MobilenetV2/expanded_conv_13/expand/weights/Initializer/truncated_normal (55.30k/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_13/expand/weights/Initializer/truncated_normal/mul (55.30k/55.30k flops)\n",
            "  MobilenetV2/expanded_conv_12/project/weights/Initializer/truncated_normal (55.30k/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_12/project/weights/Initializer/truncated_normal/mul (55.30k/55.30k flops)\n",
            "  MobilenetV2/expanded_conv_12/expand/weights/Initializer/truncated_normal (55.30k/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_12/expand/weights/Initializer/truncated_normal/mul (55.30k/55.30k flops)\n",
            "  MobilenetV2/expanded_conv_11/project/weights/Initializer/truncated_normal (55.30k/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_11/project/weights/Initializer/truncated_normal/mul (55.30k/55.30k flops)\n",
            "  MobilenetV2/expanded_conv_10/project/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_10/project/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
            "  MobilenetV2/expanded_conv_11/expand/weights/Initializer/truncated_normal (55.30k/110.59k flops)\n",
            "    MobilenetV2/expanded_conv_11/expand/weights/Initializer/truncated_normal/mul (55.30k/55.30k flops)\n",
            "  MobilenetV2/expanded_conv_9/project/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_9/project/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_9/expand/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_9/expand/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_10/project/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_10/project/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
            "  MobilenetV2/expanded_conv_8/project/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_8/project/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_8/expand/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_8/expand/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_7/project/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_7/project/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_7/expand/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_7/expand/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_10/expand/kernel/Regularizer/l2_regularizer (1/73.73k flops)\n",
            "    MobilenetV2/expanded_conv_10/expand/kernel/Regularizer/l2_regularizer/L2Loss (73.73k/73.73k flops)\n",
            "  MobilenetV2/expanded_conv_9/project/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_9/project/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_9/expand/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_9/expand/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_8/project/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_8/project/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_8/expand/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_8/expand/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_10/expand/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_10/expand/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_7/project/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_7/project/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_7/expand/weights/Initializer/truncated_normal (24.58k/49.15k flops)\n",
            "    MobilenetV2/expanded_conv_7/expand/weights/Initializer/truncated_normal/mul (24.58k/24.58k flops)\n",
            "  MobilenetV2/expanded_conv_6/project/kernel/Regularizer/l2_regularizer (1/36.86k flops)\n",
            "    MobilenetV2/expanded_conv_6/project/kernel/Regularizer/l2_regularizer/L2Loss (36.86k/36.86k flops)\n",
            "  MobilenetV2/expanded_conv_6/project/weights/Initializer/truncated_normal (12.29k/24.58k flops)\n",
            "    MobilenetV2/expanded_conv_6/project/weights/Initializer/truncated_normal/mul (12.29k/12.29k flops)\n",
            "  decoder/feature_projection0/kernel/Regularizer/l2_regularizer (1/20.74k flops)\n",
            "    decoder/feature_projection0/kernel/Regularizer/l2_regularizer/L2Loss (20.73k/20.73k flops)\n",
            "  MobilenetV2/expanded_conv_4/expand/kernel/Regularizer/l2_regularizer (1/18.43k flops)\n",
            "    MobilenetV2/expanded_conv_4/expand/kernel/Regularizer/l2_regularizer/L2Loss (18.43k/18.43k flops)\n",
            "  MobilenetV2/expanded_conv_6/expand/kernel/Regularizer/l2_regularizer (1/18.43k flops)\n",
            "    MobilenetV2/expanded_conv_6/expand/kernel/Regularizer/l2_regularizer/L2Loss (18.43k/18.43k flops)\n",
            "  MobilenetV2/expanded_conv_4/project/kernel/Regularizer/l2_regularizer (1/18.43k flops)\n",
            "    MobilenetV2/expanded_conv_4/project/kernel/Regularizer/l2_regularizer/L2Loss (18.43k/18.43k flops)\n",
            "  MobilenetV2/expanded_conv_5/project/kernel/Regularizer/l2_regularizer (1/18.43k flops)\n",
            "    MobilenetV2/expanded_conv_5/project/kernel/Regularizer/l2_regularizer/L2Loss (18.43k/18.43k flops)\n",
            "  MobilenetV2/expanded_conv_5/expand/kernel/Regularizer/l2_regularizer (1/18.43k flops)\n",
            "    MobilenetV2/expanded_conv_5/expand/kernel/Regularizer/l2_regularizer/L2Loss (18.43k/18.43k flops)\n",
            "  MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/Initializer/truncated_normal (8.64k/17.28k flops)\n",
            "    MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/Initializer/truncated_normal/mul (8.64k/8.64k flops)\n",
            "  MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/Initializer/truncated_normal (8.64k/17.28k flops)\n",
            "    MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/Initializer/truncated_normal/mul (8.64k/8.64k flops)\n",
            "  MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/Initializer/truncated_normal (8.64k/17.28k flops)\n",
            "    MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/Initializer/truncated_normal/mul (8.64k/8.64k flops)\n",
            "  logits/semantic/kernel/Regularizer/l2_regularizer (1/14.59k flops)\n",
            "    logits/semantic/kernel/Regularizer/l2_regularizer/L2Loss (14.59k/14.59k flops)\n",
            "  decoder/feature_projection0/weights/Initializer/random_uniform (6.91k/13.82k flops)\n",
            "    decoder/feature_projection0/weights/Initializer/random_uniform/mul (6.91k/6.91k flops)\n",
            "    decoder/feature_projection0/weights/Initializer/random_uniform/sub (1/1 flops)\n",
            "  MobilenetV2/expanded_conv_3/project/kernel/Regularizer/l2_regularizer (1/13.82k flops)\n",
            "    MobilenetV2/expanded_conv_3/project/kernel/Regularizer/l2_regularizer/L2Loss (13.82k/13.82k flops)\n",
            "  MobilenetV2/expanded_conv_4/project/weights/Initializer/truncated_normal (6.14k/12.29k flops)\n",
            "    MobilenetV2/expanded_conv_4/project/weights/Initializer/truncated_normal/mul (6.14k/6.14k flops)\n",
            "  MobilenetV2/expanded_conv_5/expand/weights/Initializer/truncated_normal (6.14k/12.29k flops)\n",
            "    MobilenetV2/expanded_conv_5/expand/weights/Initializer/truncated_normal/mul (6.14k/6.14k flops)\n",
            "  MobilenetV2/expanded_conv_5/project/weights/Initializer/truncated_normal (6.14k/12.29k flops)\n",
            "    MobilenetV2/expanded_conv_5/project/weights/Initializer/truncated_normal/mul (6.14k/6.14k flops)\n",
            "  MobilenetV2/expanded_conv_4/expand/weights/Initializer/truncated_normal (6.14k/12.29k flops)\n",
            "    MobilenetV2/expanded_conv_4/expand/weights/Initializer/truncated_normal/mul (6.14k/6.14k flops)\n",
            "  MobilenetV2/expanded_conv_6/expand/weights/Initializer/truncated_normal (6.14k/12.29k flops)\n",
            "    MobilenetV2/expanded_conv_6/expand/weights/Initializer/truncated_normal/mul (6.14k/6.14k flops)\n",
            "  MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/Initializer/truncated_normal (5.18k/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/Initializer/truncated_normal/mul (5.18k/5.18k flops)\n",
            "  MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/Initializer/truncated_normal (5.18k/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/Initializer/truncated_normal/mul (5.18k/5.18k flops)\n",
            "  MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/Initializer/truncated_normal (5.18k/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/Initializer/truncated_normal/mul (5.18k/5.18k flops)\n",
            "  MobilenetV2/expanded_conv_2/project/kernel/Regularizer/l2_regularizer (1/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_2/project/kernel/Regularizer/l2_regularizer/L2Loss (10.37k/10.37k flops)\n",
            "  MobilenetV2/expanded_conv_3/expand/kernel/Regularizer/l2_regularizer (1/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_3/expand/kernel/Regularizer/l2_regularizer/L2Loss (10.37k/10.37k flops)\n",
            "  MobilenetV2/expanded_conv_2/expand/kernel/Regularizer/l2_regularizer (1/10.37k flops)\n",
            "    MobilenetV2/expanded_conv_2/expand/kernel/Regularizer/l2_regularizer/L2Loss (10.37k/10.37k flops)\n",
            "  logits/semantic/weights/Initializer/truncated_normal (4.86k/9.73k flops)\n",
            "    logits/semantic/weights/Initializer/truncated_normal/mul (4.86k/4.86k flops)\n",
            "  MobilenetV2/expanded_conv_3/project/weights/Initializer/truncated_normal (4.61k/9.22k flops)\n",
            "    MobilenetV2/expanded_conv_3/project/weights/Initializer/truncated_normal/mul (4.61k/4.61k flops)\n",
            "  MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_3/expand/weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_3/expand/weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_1/project/kernel/Regularizer/l2_regularizer (1/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_1/project/kernel/Regularizer/l2_regularizer/L2Loss (6.91k/6.91k flops)\n",
            "  MobilenetV2/expanded_conv_2/project/weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_2/project/weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_2/expand/weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_2/expand/weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/Initializer/truncated_normal (3.46k/6.91k flops)\n",
            "    MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/Initializer/truncated_normal/mul (3.46k/3.46k flops)\n",
            "  aspp3_depthwise/depthwise_weights/Initializer/truncated_normal (2.88k/5.76k flops)\n",
            "    aspp3_depthwise/depthwise_weights/Initializer/truncated_normal/mul (2.88k/2.88k flops)\n",
            "  aspp2_depthwise/depthwise_weights/Initializer/truncated_normal (2.88k/5.76k flops)\n",
            "    aspp2_depthwise/depthwise_weights/Initializer/truncated_normal/mul (2.88k/2.88k flops)\n",
            "  aspp1_depthwise/depthwise_weights/Initializer/truncated_normal (2.88k/5.76k flops)\n",
            "    aspp1_depthwise/depthwise_weights/Initializer/truncated_normal/mul (2.88k/2.88k flops)\n",
            "  decoder/decoder_conv0_depthwise/depthwise_weights/Initializer/truncated_normal (2.74k/5.47k flops)\n",
            "    decoder/decoder_conv0_depthwise/depthwise_weights/Initializer/truncated_normal/mul (2.74k/2.74k flops)\n",
            "  MobilenetV2/expanded_conv_1/project/weights/Initializer/truncated_normal (2.30k/4.61k flops)\n",
            "    MobilenetV2/expanded_conv_1/project/weights/Initializer/truncated_normal/mul (2.30k/2.30k flops)\n",
            "  MobilenetV2/expanded_conv_1/expand/kernel/Regularizer/l2_regularizer (1/4.61k flops)\n",
            "    MobilenetV2/expanded_conv_1/expand/kernel/Regularizer/l2_regularizer/L2Loss (4.61k/4.61k flops)\n",
            "  decoder/decoder_conv1_depthwise/depthwise_weights/Initializer/truncated_normal (2.30k/4.61k flops)\n",
            "    decoder/decoder_conv1_depthwise/depthwise_weights/Initializer/truncated_normal/mul (2.30k/2.30k flops)\n",
            "  MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/Initializer/truncated_normal (1.73k/3.46k flops)\n",
            "    MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/Initializer/truncated_normal/mul (1.73k/1.73k flops)\n",
            "  MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/Initializer/truncated_normal (1.73k/3.46k flops)\n",
            "    MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/Initializer/truncated_normal/mul (1.73k/1.73k flops)\n",
            "  MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/Initializer/truncated_normal (1.73k/3.46k flops)\n",
            "    MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/Initializer/truncated_normal/mul (1.73k/1.73k flops)\n",
            "  MobilenetV2/expanded_conv_1/expand/weights/Initializer/truncated_normal (1.54k/3.07k flops)\n",
            "    MobilenetV2/expanded_conv_1/expand/weights/Initializer/truncated_normal/mul (1.54k/1.54k flops)\n",
            "  MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/Initializer/truncated_normal (1.30k/2.59k flops)\n",
            "    MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/Initializer/truncated_normal/mul (1.30k/1.30k flops)\n",
            "  MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/Initializer/truncated_normal (1.30k/2.59k flops)\n",
            "    MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/Initializer/truncated_normal/mul (1.30k/1.30k flops)\n",
            "  MobilenetV2/Conv/kernel/Regularizer/l2_regularizer (1/2.59k flops)\n",
            "    MobilenetV2/Conv/kernel/Regularizer/l2_regularizer/L2Loss (2.59k/2.59k flops)\n",
            "  MobilenetV2/Conv/weights/Initializer/truncated_normal (864/1.73k flops)\n",
            "    MobilenetV2/Conv/weights/Initializer/truncated_normal/mul (864/864 flops)\n",
            "  MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/Initializer/truncated_normal (864/1.73k flops)\n",
            "    MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/Initializer/truncated_normal/mul (864/864 flops)\n",
            "  MobilenetV2/expanded_conv/project/kernel/Regularizer/l2_regularizer (1/1.54k flops)\n",
            "    MobilenetV2/expanded_conv/project/kernel/Regularizer/l2_regularizer/L2Loss (1.53k/1.53k flops)\n",
            "  MobilenetV2/expanded_conv/project/weights/Initializer/truncated_normal (512/1.02k flops)\n",
            "    MobilenetV2/expanded_conv/project/weights/Initializer/truncated_normal/mul (512/512 flops)\n",
            "  MobilenetV2/expanded_conv/depthwise/depthwise_weights/Initializer/truncated_normal (288/576 flops)\n",
            "    MobilenetV2/expanded_conv/depthwise/depthwise_weights/Initializer/truncated_normal/mul (288/288 flops)\n",
            "  mean_iou/AssignAdd (361/361 flops)\n",
            "  mean_iou/Sum (342/342 flops)\n",
            "  mean_iou/Sum_1 (342/342 flops)\n",
            "  mean_iou/NotEqual (19/19 flops)\n",
            "  mean_iou/div (19/19 flops)\n",
            "  mean_iou/sub (19/19 flops)\n",
            "  mean_iou/Greater (19/19 flops)\n",
            "  mean_iou/Sum_2 (18/18 flops)\n",
            "  mean_iou/mean_iou (18/18 flops)\n",
            "  Greater_7 (1/1 flops)\n",
            "  truediv_3 (1/1 flops)\n",
            "  truediv_8 (1/1 flops)\n",
            "  Greater_3 (1/1 flops)\n",
            "  true_positives_2/AssignAdd (1/1 flops)\n",
            "  Greater_6 (1/1 flops)\n",
            "  Greater_5 (1/1 flops)\n",
            "  truediv_4 (1/1 flops)\n",
            "  truediv_7 (1/1 flops)\n",
            "  Greater_4 (1/1 flops)\n",
            "  truediv_6 (1/1 flops)\n",
            "  Greater_18 (1/1 flops)\n",
            "  truediv_5 (1/1 flops)\n",
            "  true_positives_3/AssignAdd (1/1 flops)\n",
            "  truediv (1/1 flops)\n",
            "  Greater_14 (1/1 flops)\n",
            "  true_positives_7/AssignAdd (1/1 flops)\n",
            "  Greater_13 (1/1 flops)\n",
            "  true_positives_6/AssignAdd (1/1 flops)\n",
            "  Greater_12 (1/1 flops)\n",
            "  truediv_9 (1/1 flops)\n",
            "  true_positives_8/AssignAdd (1/1 flops)\n",
            "  Greater_16 (1/1 flops)\n",
            "  Greater_11 (1/1 flops)\n",
            "  Greater_17 (1/1 flops)\n",
            "  Greater_10 (1/1 flops)\n",
            "  true_positives_9/AssignAdd (1/1 flops)\n",
            "  Greater_1 (1/1 flops)\n",
            "  Greater (1/1 flops)\n",
            "  truediv_2 (1/1 flops)\n",
            "  true_positives_5/AssignAdd (1/1 flops)\n",
            "  truediv_1 (1/1 flops)\n",
            "  truediv_10 (1/1 flops)\n",
            "  truediv_11 (1/1 flops)\n",
            "  Greater_15 (1/1 flops)\n",
            "  truediv_12 (1/1 flops)\n",
            "  truediv_13 (1/1 flops)\n",
            "  Greater_2 (1/1 flops)\n",
            "  truediv_14 (1/1 flops)\n",
            "  truediv_15 (1/1 flops)\n",
            "  true_positives_4/AssignAdd (1/1 flops)\n",
            "  truediv_16 (1/1 flops)\n",
            "  truediv_17 (1/1 flops)\n",
            "  truediv_18 (1/1 flops)\n",
            "  false_negatives_3/AssignAdd (1/1 flops)\n",
            "  false_positives_14/AssignAdd (1/1 flops)\n",
            "  false_positives_13/AssignAdd (1/1 flops)\n",
            "  false_positives_12/AssignAdd (1/1 flops)\n",
            "  false_positives_11/AssignAdd (1/1 flops)\n",
            "  false_positives_10/AssignAdd (1/1 flops)\n",
            "  false_positives_1/AssignAdd (1/1 flops)\n",
            "  false_positives/AssignAdd (1/1 flops)\n",
            "  false_negatives_9/AssignAdd (1/1 flops)\n",
            "  false_negatives_8/AssignAdd (1/1 flops)\n",
            "  false_negatives_7/AssignAdd (1/1 flops)\n",
            "  false_negatives_6/AssignAdd (1/1 flops)\n",
            "  false_negatives_5/AssignAdd (1/1 flops)\n",
            "  false_negatives_4/AssignAdd (1/1 flops)\n",
            "  false_positives_15/AssignAdd (1/1 flops)\n",
            "  false_negatives_2/AssignAdd (1/1 flops)\n",
            "  false_negatives_18/AssignAdd (1/1 flops)\n",
            "  false_negatives_17/AssignAdd (1/1 flops)\n",
            "  false_negatives_16/AssignAdd (1/1 flops)\n",
            "  false_negatives_15/AssignAdd (1/1 flops)\n",
            "  false_negatives_14/AssignAdd (1/1 flops)\n",
            "  false_negatives_13/AssignAdd (1/1 flops)\n",
            "  false_negatives_12/AssignAdd (1/1 flops)\n",
            "  false_negatives_11/AssignAdd (1/1 flops)\n",
            "  false_negatives_10/AssignAdd (1/1 flops)\n",
            "  false_negatives_1/AssignAdd (1/1 flops)\n",
            "  false_negatives/AssignAdd (1/1 flops)\n",
            "  mean_iou/truediv (1/1 flops)\n",
            "  true_positives_18/AssignAdd (1/1 flops)\n",
            "  Greater_9 (1/1 flops)\n",
            "  true_positives_17/AssignAdd (1/1 flops)\n",
            "  true_positives_16/AssignAdd (1/1 flops)\n",
            "  true_positives_15/AssignAdd (1/1 flops)\n",
            "  true_positives_14/AssignAdd (1/1 flops)\n",
            "  true_positives_13/AssignAdd (1/1 flops)\n",
            "  true_positives_12/AssignAdd (1/1 flops)\n",
            "  true_positives_11/AssignAdd (1/1 flops)\n",
            "  true_positives_10/AssignAdd (1/1 flops)\n",
            "  true_positives_1/AssignAdd (1/1 flops)\n",
            "  true_positives/AssignAdd (1/1 flops)\n",
            "  Greater_8 (1/1 flops)\n",
            "  mean_iou/Greater_1 (1/1 flops)\n",
            "  false_positives_9/AssignAdd (1/1 flops)\n",
            "  false_positives_8/AssignAdd (1/1 flops)\n",
            "  false_positives_7/AssignAdd (1/1 flops)\n",
            "  false_positives_6/AssignAdd (1/1 flops)\n",
            "  false_positives_5/AssignAdd (1/1 flops)\n",
            "  false_positives_4/AssignAdd (1/1 flops)\n",
            "  false_positives_3/AssignAdd (1/1 flops)\n",
            "  false_positives_2/AssignAdd (1/1 flops)\n",
            "  false_positives_18/AssignAdd (1/1 flops)\n",
            "  false_positives_17/AssignAdd (1/1 flops)\n",
            "  false_positives_16/AssignAdd (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet\n",
            "I0619 11:18:37.829500 139775215441792 evaluation.py:189] Waiting for new checkpoint at /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet\n",
            "INFO:tensorflow:Found new checkpoint at /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "I0619 11:18:37.833568 139775215441792 evaluation.py:198] Found new checkpoint at /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0619 11:18:38.628902 139775215441792 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "I0619 11:18:38.639585 139775215441792 saver.py:1284] Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0619 11:18:39.603137 139775215441792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0619 11:18:39.775774 139775215441792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-19-11:18:40\n",
            "I0619 11:18:40.908267 139775215441792 evaluation.py:450] Starting evaluation at 2021-06-19-11:18:40\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [19]\n",
            "\t [[{{node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"deeplab/eval.py\", line 227, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"deeplab/eval.py\", line 220, in main\n",
            "    eval_interval_secs=FLAGS.eval_interval_secs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/training/python/training/evaluation.py\", line 453, in evaluate_repeatedly\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [19]\n",
            "\t [[node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\n",
            "Original stack trace for 'mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert':\n",
            "  File \"deeplab/eval.py\", line 227, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"deeplab/eval.py\", line 163, in main\n",
            "    weights=weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/metrics_impl.py\", line 1155, in mean_iou\n",
            "    num_classes, weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/metrics_impl.py\", line 275, in _streaming_confusion_matrix\n",
            "    labels, predictions, num_classes, weights=weights, dtype=dtypes.float64)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/confusion_matrix.py\", line 176, in confusion_matrix\n",
            "    labels, num_classes_int64, message='`labels` out of bound')],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/check_ops.py\", line 879, in assert_less\n",
            "    summarize, message, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/check_ops.py\", line 371, in _binary_assert\n",
            "    return control_flow_ops.Assert(condition, data, summarize=summarize)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/tf_should_use.py\", line 198, in wrapped\n",
            "    return _add_should_use_warning(fn(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 173, in Assert\n",
            "    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1235, in cond\n",
            "    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1061, in BuildCondBranch\n",
            "    original_result = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 171, in true_assert\n",
            "    condition, data, summarize, name=\"Assert\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_logging_ops.py\", line 74, in _assert\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMUAU0PyO-qI"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdBl1l1qrBot"
      },
      "source": [
        "%mkdir {VIS_RESULTS}"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5tRom91BBOP"
      },
      "source": [
        "!python deeplab/vis.py --logtostderr \\\n",
        "  --vis_split=\"val\" \\\n",
        "  --model_variant=\"mobilenet_v2\" \\\n",
        "  --vis_crop_size=\"1080,1080\" \\\n",
        "  --atrous_rates=6 \\\n",
        "  --atrous_rates=12 \\\n",
        "   --atrous_rates=18 \\\n",
        "   --output_stride=16 \\\n",
        "   --decoder_output_stride=4 \\\n",
        "   --dataset=\"lip\" \\\n",
        "   --checkpoint_dir=\"{CHECKPOINT}\" \\\n",
        "   --vis_logdir=\"{VIS_RESULTS}\" \\\n",
        "   --dataset_dir=\"{TRAIN_VAL_TFRECORD}\" \\\n",
        "   --max_number_of_iterations=1 \\\n",
        "   --eval_interval_secs=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYv-chdk1c3E"
      },
      "source": [
        "## Export trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU4hl8PLikYK"
      },
      "source": [
        "%mkdir /content/drive/MyDrive/TFM/model_19_60k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmM54g5S7Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bef22b-19e8-4fe2-f1cd-4901c9796604"
      },
      "source": [
        "!python deeplab/export_model.py \\\n",
        "    --logtostderr \\\n",
        "    --checkpoint_path=\"/content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\" \\\n",
        "    --export_path=\"/content/drive/MyDrive/TFM/model_19_60k/frozen_inference_graph.pb\"  \\\n",
        "    --model_variant=\"mobilenet_v2\"  \\\n",
        "    --dataset=\"lip\" \\\n",
        "    --atrous_rates=6  \\\n",
        "    --atrous_rates=12  \\\n",
        "    --atrous_rates=18   \\\n",
        "    --output_stride=16  \\\n",
        "    --crop_size=1080 \\\n",
        "    --crop_size=1080 \\\n",
        "    --decoder_output_stride=4  \\\n",
        "    --num_classes=19 \\\n",
        "    --inference_scales=1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:201: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:117: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0614 20:59:29.659634 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:117: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:117: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0614 20:59:29.659866 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:117: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:118: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0614 20:59:29.660038 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:118: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Prepare to export model to: /content/drive/MyDrive/TFM/model_19_60k/frozen_inference_graph.pb\n",
            "I0614 20:59:29.660170 139818064660352 export_model.py:118] Prepare to export model to: /content/drive/MyDrive/TFM/model_19_60k/frozen_inference_graph.pb\n",
            "WARNING:tensorflow:From deeplab/export_model.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0614 20:59:29.660999 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Exported model performs single-scale inference.\n",
            "I0614 20:59:29.710431 139818064660352 export_model.py:130] Exported model performs single-scale inference.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0614 20:59:29.710946 139818064660352 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0614 20:59:29.711641 139818064660352 deprecation.py:323] From /content/drive/MyDrive/TFM/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0614 20:59:29.716188 139818064660352 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0614 20:59:31.612152 139818064660352 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0614 20:59:31.914961 139818064660352 module_wrapper.py:139] From /content/drive/MyDrive/TFM/models/research/deeplab/model.py:702: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:162: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0614 20:59:32.113300 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:162: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0614 20:59:32.117471 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:178: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "W0614 20:59:32.117697 139818064660352 deprecation.py:323] From deeplab/export_model.py:178: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "WARNING:tensorflow:From deeplab/export_model.py:181: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0614 20:59:32.394234 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:181: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:182: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0614 20:59:32.395524 139818064660352 module_wrapper.py:139] From deeplab/export_model.py:182: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0614 20:59:32.514571 139818064660352 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "I0614 20:59:32.905106 139818064660352 saver.py:1284] Restoring parameters from /content/drive/MyDrive/TFM/checkpoint_lip_mobilenet/model.ckpt-60000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0614 20:59:33.493556 139818064660352 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0614 20:59:33.493820 139818064660352 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 327 variables.\n",
            "I0614 20:59:33.809930 139818064660352 graph_util_impl.py:334] Froze 327 variables.\n",
            "INFO:tensorflow:Converted 327 variables to const ops.\n",
            "I0614 20:59:33.890214 139818064660352 graph_util_impl.py:394] Converted 327 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tXC80QX6Y72"
      },
      "source": [
        "import PIL\n",
        "\n",
        "image_list = os.listdir('/content/drive/MyDrive/TFM/lip_trainval_images/TrainVal_images/train_images/')\n",
        "\n",
        "higher = 0\n",
        "\n",
        "for image in image_list:\n",
        "  image = PIL.Image.open(image)\n",
        "  width, height = image.size\n",
        "  if max(width, height) > higher:\n",
        "    higher = max(width, height)\n",
        "\n",
        "higher"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}